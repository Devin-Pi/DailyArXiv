# Daily Papers
The project automatically fetches the latest papers from arXiv based on keywords.

The subheadings in the README file represent the search keywords.

Only the most recent articles for each keyword are retained, up to a maximum of 100 papers.

You can click the 'Watch' button to receive daily email notifications.

Last update: 2025-06-27

## Geoscience
| **Title** | **Date** | **KiMi** | **Abstract** | **Comment** |
| --- | --- | --- | --- | --- |
| **[GeoRSMLLM: A Multimodal Large Language Model for Vision-Language Tasks in Geoscience and Remote Sensing](http://arxiv.org/abs/2503.12490v1)** | 2025-03-16 | [papers-cool](https://papers.cool/arxiv/2503.12490v1) | <details><summary>Show</summary><p>The application of Vision-Language Models (VLMs) in remote sensing (RS) has demonstrated significant potential in traditional tasks such as scene classification, object detection, and image captioning. However, current models, which excel in Referring Expression Comprehension (REC), struggle with tasks involving complex instructions (e.g., exists multiple conditions) or pixel-level operations like segmentation and change detection. In this white paper, we provide a comprehensive hierarchical summary of vision-language tasks in RS, categorized by the varying levels of cognitive capability required. We introduce the Remote Sensing Vision-Language Task Set (RSVLTS), which includes Open-Vocabulary Tasks (OVT), Referring Expression Tasks (RET), and Described Object Tasks (DOT) with increased difficulty, and Visual Question Answering (VQA) aloneside. Moreover, we propose a novel unified data representation using a set-of-points approach for RSVLTS, along with a condition parser and a self-augmentation strategy based on cyclic referring. These features are integrated into the GeoRSMLLM model, and this enhanced model is designed to handle a broad range of tasks of RSVLTS, paving the way for a more generalized solution for vision-language tasks in geoscience and remote sensing.</p></details> |  |
| **[When Geoscience Meets Foundation Models: Towards General Geoscience Artificial Intelligence System](http://arxiv.org/abs/2309.06799v5)** | 2024-11-12 | [papers-cool](https://papers.cool/arxiv/2309.06799v5) | <details><summary>Show</summary><p>Artificial intelligence (AI) has significantly advanced Earth sciences, yet its full potential in to comprehensively modeling Earth's complex dynamics remains unrealized. Geoscience foundation models (GFMs) emerge as a paradigm-shifting solution, integrating extensive cross-disciplinary data to enhance the simulation and understanding of Earth system dynamics. These data-centric AI models extract insights from petabytes of structured and unstructured data, effectively addressing the complexities of Earth systems that traditional models struggle to capture. The unique strengths of GFMs include flexible task specification, diverse input-output capabilities, and multi-modal knowledge representation, enabling analyses that surpass those of individual data sources or traditional AI methods. This review not only highlights the key advantages of GFMs, but also presents essential techniques for their construction, with a focus on transformers, pre-training, and adaptation strategies. Subsequently, we examine recent advancements in GFMs, including large language models, vision models, and vision-language models, particularly emphasizing the potential applications in remote sensing. Additionally, the review concludes with a comprehensive analysis of the challenges and future trends in GFMs, addressing five critical aspects: data integration, model complexity, uncertainty quantification, interdisciplinary collaboration, and concerns related to privacy, trust, and security. This review offers a comprehensive overview of emerging geoscientific research paradigms, emphasizing the untapped opportunities at the intersection of advanced AI techniques and geoscience. It examines major methodologies, showcases advances in large-scale models, and discusses the challenges and prospects that will shape the future landscape of GFMs.</p></details> | <details><summary>accpe...</summary><p>accpeted by IEEE Geoscience and Remote Sensing Magazine</p></details> |
| **[Prototype-Based Methods in Explainable AI and Emerging Opportunities in the Geosciences](http://arxiv.org/abs/2410.19856v1)** | 2024-10-22 | [papers-cool](https://papers.cool/arxiv/2410.19856v1) | <details><summary>Show</summary><p>Prototype-based methods are intrinsically interpretable XAI methods that produce predictions and explanations by comparing input data with a set of learned prototypical examples that are representative of the training data. In this work, we discuss a series of developments in the field of prototype-based XAI that show potential for scientific learning tasks, with a focus on the geosciences. We organize the prototype-based XAI literature into three themes: the development and visualization of prototypes, types of prototypes, and the use of prototypes in various learning tasks. We discuss how the authors use prototype-based methods, their novel contributions, and any limitations or challenges that may arise when adapting these methods for geoscientific learning tasks. We highlight differences between geoscientific data sets and the standard benchmarks used to develop XAI methods, and discuss how specific geoscientific applications may benefit from using or modifying existing prototype-based XAI techniques.</p></details> | <details><summary>Accep...</summary><p>Accepted at AI for Science Workshop-Oral (Attention Track), Proceedings of 41st International Conference on Machine Learning (ICML) 2024</p></details> |
| **[Interpretable Geoscience Artificial Intelligence (XGeoS-AI): Application to Demystify Image Recognition](http://arxiv.org/abs/2311.04940v2)** | 2024-05-07 | [papers-cool](https://papers.cool/arxiv/2311.04940v2) | <details><summary>Show</summary><p>As Earth science enters the era of big data, artificial intelligence (AI) not only offers great potential for solving geoscience problems, but also plays a critical role in accelerating the understanding of the complex, interactive, and multiscale processes of Earth's behavior. As geoscience AI models are progressively utilized for significant predictions in crucial situations, geoscience researchers are increasingly demanding their interpretability and versatility. This study proposes an interpretable geoscience artificial intelligence (XGeoS-AI) framework to unravel the mystery of image recognition in the Earth sciences, and its effectiveness and versatility is demonstrated by taking computed tomography (CT) image recognition as an example. Inspired by the mechanism of human vision, the proposed XGeoS-AI framework generates a threshold value from a local region within the whole image to complete the recognition. Different kinds of artificial intelligence (AI) methods, such as Support Vector Regression (SVR), Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), can be adopted as the AI engines of the proposed XGeoS-AI framework to efficiently complete geoscience image recognition tasks. Experimental results demonstrate that the effectiveness, versatility, and heuristics of the proposed framework have great potential in solving geoscience image recognition problems. Interpretable AI should receive more and more attention in the field of the Earth sciences, which is the key to promoting more rational and wider applications of AI in the field of Earth sciences. In addition, the proposed interpretable framework may be the forerunner of technological innovation in the Earth sciences.</p></details> | <details><summary>there...</summary><p>there are some erros in the results, and a newer revision is still preparing</p></details> |
| **[GeoGalactica: A Scientific Large Language Model in Geoscience](http://arxiv.org/abs/2401.00434v2)** | 2024-04-13 | [papers-cool](https://papers.cool/arxiv/2401.00434v2) | <details><summary>Show</summary><p>Large language models (LLMs) have achieved huge success for their general knowledge and ability to solve a wide spectrum of tasks in natural language processing (NLP). Due to their impressive abilities, LLMs have shed light on potential inter-discipline applications to foster scientific discoveries of a specific domain by using artificial intelligence (AI for science, AI4S). In the meantime, utilizing NLP techniques in geoscience research and practice is wide and convoluted, contributing from knowledge extraction and document classification to question answering and knowledge discovery. In this work, we take the initial step to leverage LLM for science, through a rather straightforward approach. We try to specialize an LLM into geoscience, by further pre-training the model with a vast amount of texts in geoscience, as well as supervised fine-tuning (SFT) the resulting model with our custom collected instruction tuning dataset. These efforts result in a model GeoGalactica consisting of 30 billion parameters. To our best knowledge, it is the largest language model for the geoscience domain. More specifically, GeoGalactica is from further pre-training of Galactica. We train GeoGalactica over a geoscience-related text corpus containing 65 billion tokens, preserving as the largest geoscience-specific text corpus. Then we fine-tune the model with 1 million pairs of instruction-tuning data consisting of questions that demand professional geoscience knowledge to answer. In this technical report, we will illustrate in detail all aspects of GeoGalactica, including data collection, data cleaning, base model selection, pre-training, SFT, and evaluation. We open-source our data curation tools and the checkpoints of GeoGalactica during the first 3/4 of pre-training.</p></details> |  |
| **[A novel approach for estimating functions in the multivariate setting based on an adaptive knot selection for B-splines with an application to a chemical system used in geoscience](http://arxiv.org/abs/2306.00686v3)** | 2024-01-25 | [papers-cool](https://papers.cool/arxiv/2306.00686v3) | <details><summary>Show</summary><p>In this paper, we will outline a novel data-driven method for estimating functions in a multivariate nonparametric regression model based on an adaptive knot selection for B-splines. The underlying idea of our approach for selecting knots is to apply the generalized lasso, since the knots of the B-spline basis can be seen as changes in the derivatives of the function to be estimated. This method was then extended to functions depending on several variables by processing each dimension independently, thus reducing the problem to a univariate setting. The regularization parameters were chosen by means of a criterion based on EBIC. The nonparametric estimator was obtained using a multivariate B-spline regression with the corresponding selected knots. Our procedure was validated through numerical experiments by varying the number of observations and the level of noise to investigate its robustness. The influence of observation sampling was also assessed and our method was applied to a chemical system commonly used in geoscience. For each different framework considered in this paper, our approach performed better than state-of-the-art methods. Our completely data-driven method is implemented in the glober R package which is available on the Comprehensive R Archive Network (CRAN).</p></details> | 29 pages, 27 figures |
| **[When Geoscience Meets Generative AI and Large Language Models: Foundations, Trends, and Future Challenges](http://arxiv.org/abs/2402.03349v1)** | 2024-01-25 | [papers-cool](https://papers.cool/arxiv/2402.03349v1) | <details><summary>Show</summary><p>Generative Artificial Intelligence (GAI) represents an emerging field that promises the creation of synthetic data and outputs in different modalities. GAI has recently shown impressive results across a large spectrum of applications ranging from biology, medicine, education, legislation, computer science, and finance. As one strives for enhanced safety, efficiency, and sustainability, generative AI indeed emerges as a key differentiator and promises a paradigm shift in the field. This paper explores the potential applications of generative AI and large language models in geoscience. The recent developments in the field of machine learning and deep learning have enabled the generative model's utility for tackling diverse prediction problems, simulation, and multi-criteria decision-making challenges related to geoscience and Earth system dynamics. This survey discusses several GAI models that have been used in geoscience comprising generative adversarial networks (GANs), physics-informed neural networks (PINNs), and generative pre-trained transformer (GPT)-based structures. These tools have helped the geoscience community in several applications, including (but not limited to) data generation/augmentation, super-resolution, panchromatic sharpening, haze removal, restoration, and land surface changing. Some challenges still remain such as ensuring physical interpretation, nefarious use cases, and trustworthiness. Beyond that, GAI models show promises to the geoscience community, especially with the support to climate change, urban science, atmospheric science, marine science, and planetary science through their extraordinary ability to data-driven modeling and uncertainty quantification.</p></details> |  |
| **[Differentiable modeling to unify machine learning and physical models and advance Geosciences](http://arxiv.org/abs/2301.04027v2)** | 2023-12-27 | [papers-cool](https://papers.cool/arxiv/2301.04027v2) | <details><summary>Show</summary><p>Process-Based Modeling (PBM) and Machine Learning (ML) are often perceived as distinct paradigms in the geosciences. Here we present differentiable geoscientific modeling as a powerful pathway toward dissolving the perceived barrier between them and ushering in a paradigm shift. For decades, PBM offered benefits in interpretability and physical consistency but struggled to efficiently leverage large datasets. ML methods, especially deep networks, presented strong predictive skills yet lacked the ability to answer specific scientific questions. While various methods have been proposed for ML-physics integration, an important underlying theme -- differentiable modeling -- is not sufficiently recognized. Here we outline the concepts, applicability, and significance of differentiable geoscientific modeling (DG). "Differentiable" refers to accurately and efficiently calculating gradients with respect to model variables, critically enabling the learning of high-dimensional unknown relationships. DG refers to a range of methods connecting varying amounts of prior knowledge to neural networks and training them together, capturing a different scope than physics-guided machine learning and emphasizing first principles. Preliminary evidence suggests DG offers better interpretability and causality than ML, improved generalizability and extrapolation capability, and strong potential for knowledge discovery, while approaching the performance of purely data-driven ML. DG models require less training data while scaling favorably in performance and efficiency with increasing amounts of data. With DG, geoscientists may be better able to frame and investigate questions, test hypotheses, and discover unrecognized linkages.</p></details> |  |
| **[K2: A Foundation Language Model for Geoscience Knowledge Understanding and Utilization](http://arxiv.org/abs/2306.05064v2)** | 2023-09-13 | [papers-cool](https://papers.cool/arxiv/2306.05064v2) | <details><summary>Show</summary><p>Large language models (LLMs) have achieved great success in general domains of natural language processing. In this paper, we bring LLMs to the realm of geoscience with the objective of advancing research and applications in this field. To this end, we present the first-ever LLM in geoscience, K2, alongside a suite of resources developed to further promote LLM research within geoscience. For instance, we have curated the first geoscience instruction tuning dataset, GeoSignal, which aims to align LLM responses to geoscience-related user queries. Additionally, we have established the first geoscience benchmark, GeoBench, to evaluate LLMs in the context of geoscience. In this work, we experiment with a complete recipe to adapt a pre-trained general-domain LLM to the geoscience domain. Specifically, we further train the LLaMA-7B model on 5.5B tokens of geoscience text corpus, including over 1 million pieces of geoscience literature, and utilize GeoSignal's supervised data to fine-tune the model. Moreover, we share a protocol that can efficiently gather domain-specific data and construct domain-supervised data, even in situations where manpower is scarce. Meanwhile, we equip K2 with the abilities of using tools to be a naive geoscience aide. Experiments conducted on the GeoBench demonstrate the effectiveness of our approach and datasets on geoscience knowledge understanding and utilization.We open-source all the training data and K2 model checkpoints at https://github.com/davendw49/k2.</p></details> |  |
| **[AI Security for Geoscience and Remote Sensing: Challenges and Future Trends](http://arxiv.org/abs/2212.09360v2)** | 2023-06-22 | [papers-cool](https://papers.cool/arxiv/2212.09360v2) | <details><summary>Show</summary><p>Recent advances in artificial intelligence (AI) have significantly intensified research in the geoscience and remote sensing (RS) field. AI algorithms, especially deep learning-based ones, have been developed and applied widely to RS data analysis. The successful application of AI covers almost all aspects of Earth observation (EO) missions, from low-level vision tasks like super-resolution, denoising and inpainting, to high-level vision tasks like scene classification, object detection and semantic segmentation. While AI techniques enable researchers to observe and understand the Earth more accurately, the vulnerability and uncertainty of AI models deserve further attention, considering that many geoscience and RS tasks are highly safety-critical. This paper reviews the current development of AI security in the geoscience and RS field, covering the following five important aspects: adversarial attack, backdoor attack, federated learning, uncertainty and explainability. Moreover, the potential opportunities and trends are discussed to provide insights for future research. To the best of the authors' knowledge, this paper is the first attempt to provide a systematic review of AI security-related research in the geoscience and RS community. Available code and datasets are also listed in the paper to move this vibrant field of research forward.</p></details> |  |
| **[Coarse-to-fine Task-driven Inpainting for Geoscience Images](http://arxiv.org/abs/2211.11059v3)** | 2022-12-06 | [papers-cool](https://papers.cool/arxiv/2211.11059v3) | <details><summary>Show</summary><p>The processing and recognition of geoscience images have wide applications. Most of existing researches focus on understanding the high-quality geoscience images by assuming that all the images are clear. However, in many real-world cases, the geoscience images might contain occlusions during the image acquisition. This problem actually implies the image inpainting problem in computer vision and multimedia. To the best of our knowledge, all the existing image inpainting algorithms learn to repair the occluded regions for a better visualization quality, they are excellent for natural images but not good enough for geoscience images by ignoring the geoscience related tasks. This paper aims to repair the occluded regions for a better geoscience task performance with the advanced visualization quality simultaneously, without changing the current deployed deep learning based geoscience models. Because of the complex context of geoscience images, we propose a coarse-to-fine encoder-decoder network with coarse-to-fine adversarial context discriminators to reconstruct the occluded image regions. Due to the limited data of geoscience images, we use a MaskMix based data augmentation method to exploit more information from limited geoscience image data. The experimental results on three public geoscience datasets for remote sensing scene recognition, cross-view geolocation and semantic segmentation tasks respectively show the effectiveness and accuracy of the proposed method.</p></details> |  |
| **[Investigating the fidelity of explainable artificial intelligence methods for applications of convolutional neural networks in geoscience](http://arxiv.org/abs/2202.03407v2)** | 2022-09-05 | [papers-cool](https://papers.cool/arxiv/2202.03407v2) | <details><summary>Show</summary><p>Convolutional neural networks (CNNs) have recently attracted great attention in geoscience due to their ability to capture non-linear system behavior and extract predictive spatiotemporal patterns. Given their black-box nature however, and the importance of prediction explainability, methods of explainable artificial intelligence (XAI) are gaining popularity as a means to explain the CNN decision-making strategy. Here, we establish an intercomparison of some of the most popular XAI methods and investigate their fidelity in explaining CNN decisions for geoscientific applications. Our goal is to raise awareness of the theoretical limitations of these methods and gain insight into the relative strengths and weaknesses to help guide best practices. The considered XAI methods are first applied to an idealized attribution benchmark, where the ground truth of explanation of the network is known a priori, to help objectively assess their performance. Secondly, we apply XAI to a climate-related prediction setting, namely to explain a CNN that is trained to predict the number of atmospheric rivers in daily snapshots of climate simulations. Our results highlight several important issues of XAI methods (e.g., gradient shattering, inability to distinguish the sign of attribution, ignorance to zero input) that have previously been overlooked in our field and, if not considered cautiously, may lead to a distorted picture of the CNN decision-making strategy. We envision that our analysis will motivate further investigation into XAI fidelity and will help towards a cautious implementation of XAI in geoscience, which can lead to further exploitation of CNNs and deep learning for prediction problems.</p></details> |  |
| **[Data Centred Intelligent Geosciences: Research Agenda and Opportunities, Position Paper](http://arxiv.org/abs/2209.02384v1)** | 2022-08-20 | [papers-cool](https://papers.cool/arxiv/2209.02384v1) | <details><summary>Show</summary><p>This paper describes and discusses our vision to develop and reason about best practices and novel ways of curating data-centric geosciences knowledge (data, experiments, models, methods, conclusions, and interpretations). This knowledge is produced from applying statistical modelling, Machine Learning, and modern data analytics methods on geo-data collections. The problems address open methodological questions in model building, models' assessment, prediction, and forecasting workflows.</p></details> |  |
| **[Beyond Visuals : Examining the Experiences of Geoscience Professionals With Vision Disabilities in Accessing Data Visualizations](http://arxiv.org/abs/2207.13220v1)** | 2022-07-27 | [papers-cool](https://papers.cool/arxiv/2207.13220v1) | <details><summary>Show</summary><p>Data visualizations are ubiquitous in all disciplines and have become the primary means of analysing data and communicating insights. However, the predominant reliance on visual encoding of data continues to create accessibility barriers for people who are blind/vision impaired resulting in their under representation in Science, Technology, Engineering and Mathematics (STEM) disciplines. This research study seeks to understand the experiences of professionals who are blind/vision impaired in one such STEM discipline (geosciences) in accessing data visualizations. In-depth, semi-structured interviews with seven professionals were conducted to examine the accessibility barriers and areas for improvement to inform accessibility research pertaining to data visualizations through a socio-technical lens. A reflexive thematic analysis revealed the negative impact of visualizations in influencing their career path, lack of data exploration tools for research, barriers in accessing works of peers and mismatched pace of visualization and accessibility research. The article also includes recommendations from the participants to address some of these accessibility barriers.</p></details> |  |
| **[Neural Network Attribution Methods for Problems in Geoscience: A Novel Synthetic Benchmark Dataset](http://arxiv.org/abs/2103.10005v2)** | 2022-06-10 | [papers-cool](https://papers.cool/arxiv/2103.10005v2) | <details><summary>Show</summary><p>Despite the increasingly successful application of neural networks to many problems in the geosciences, their complex and nonlinear structure makes the interpretation of their predictions difficult, which limits model trust and does not allow scientists to gain physical insights about the problem at hand. Many different methods have been introduced in the emerging field of eXplainable Artificial Intelligence (XAI), which aim at attributing the network s prediction to specific features in the input domain. XAI methods are usually assessed by using benchmark datasets (like MNIST or ImageNet for image classification). However, an objective, theoretically derived ground truth for the attribution is lacking for most of these datasets, making the assessment of XAI in many cases subjective. Also, benchmark datasets specifically designed for problems in geosciences are rare. Here, we provide a framework, based on the use of additively separable functions, to generate attribution benchmark datasets for regression problems for which the ground truth of the attribution is known a priori. We generate a large benchmark dataset and train a fully connected network to learn the underlying function that was used for simulation. We then compare estimated heatmaps from different XAI methods to the ground truth in order to identify examples where specific XAI methods perform well or poorly. We believe that attribution benchmarks as the ones introduced herein are of great importance for further application of neural networks in the geosciences, and for more objective assessment and accurate implementation of XAI methods, which will increase model trust and assist in discovering new science.</p></details> | <details><summary>This ...</summary><p>This is an updated preprint version of the manuscript. This work has been published (open access) in the journal Environmental Data Science with doi: https://doi.org/10.1017/eds.2022.7. Please cite the published version. The dataset of this work is published at: https://mlhub.earth/data/csu_synthetic_attribution</p></details> |
| **[Advanced analysis of temporal data using Fisher-Shannon information: theoretical development and application in geosciences](http://arxiv.org/abs/1912.02452v2)** | 2021-01-12 | [papers-cool](https://papers.cool/arxiv/1912.02452v2) | <details><summary>Show</summary><p>Complex non-linear time series are ubiquitous in geosciences. Quantifying complexity and non-stationarity of these data is a challenging task, and advanced complexity-based exploratory tool are required for understanding and visualizing such data. This paper discusses the Fisher-Shannon method, from which one can obtain a complexity measure and detect non-stationarity, as an efficient data exploration tool. The state-of-the-art studies related to the Fisher-Shannon measures are collected, and new analytical formulas for positive unimodal skewed distributions are proposed. Case studies on both synthetic and real data illustrate the usefulness of the Fisher-Shannon method, which can find application in different domains including time series discrimination and generation of times series features for clustering, modeling and forecasting. The paper is accompanied with Python and R libraries for the non-parametric estimation of the proposed measures.</p></details> | 18 pages, 5 figures |
| **[Causal Inference in Geoscience and Remote Sensing from Observational Data](http://arxiv.org/abs/2012.05150v1)** | 2020-12-07 | [papers-cool](https://papers.cool/arxiv/2012.05150v1) | <details><summary>Show</summary><p>Establishing causal relations between random variables from observational data is perhaps the most important challenge in today's \blue{science}. In remote sensing and geosciences this is of special relevance to better understand the Earth's system and the complex interactions between the governing processes. In this paper, we focus on observational causal inference, thus we try to estimate the correct direction of causation using a finite set of empirical data. In addition, we focus on the more complex bivariate scenario that requires strong assumptions and no conditional independence tests can be used. In particular, we explore the framework of (non-deterministic) additive noise models, which relies on the principle of independence between the cause and the generating mechanism. A practical algorithmic instantiation of such principle only requires 1) two regression models in the forward and backward directions, and 2) the estimation of {\em statistical independence} between the obtained residuals and the observations. The direction leading to more independent residuals is decided to be the cause. We instead propose a criterion that uses the {\em sensitivity} (derivative) of the dependence estimator, the sensitivity criterion allows to identify samples most affecting the dependence measure, and hence the criterion is robust to spurious detections. We illustrate performance in a collection of 28 geoscience causal inference problems, in a database of radiative transfer models simulations and machine learning emulators in vegetation parameter modeling involving 182 problems, and in assessing the impact of different regression models in a carbon cycle problem. The criterion achieves state-of-the-art detection rates in all cases, it is generally robust to noise sources and distortions.</p></details> |  |
| **[Causal Inference in Geosciences with Kernel Sensitivity Maps](http://arxiv.org/abs/2012.14303v1)** | 2020-12-07 | [papers-cool](https://papers.cool/arxiv/2012.14303v1) | <details><summary>Show</summary><p>Establishing causal relations between random variables from observational data is perhaps the most important challenge in today's Science. In remote sensing and geosciences this is of special relevance to better understand the Earth's system and the complex and elusive interactions between processes. In this paper we explore a framework to derive cause-effect relations from pairs of variables via regression and dependence estimation. We propose to focus on the sensitivity (curvature) of the dependence estimator to account for the asymmetry of the forward and inverse densities of approximation residuals. Results in a large collection of 28 geoscience causal inference problems demonstrate the good capabilities of the method.</p></details> | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:1611.00555, arXiv:2012.05150</p></details> |
| **[High Definition image classification in Geoscience using Machine Learning](http://arxiv.org/abs/2010.03965v1)** | 2020-09-25 | [papers-cool](https://papers.cool/arxiv/2010.03965v1) | <details><summary>Show</summary><p>High Definition (HD) digital photos taken with drones are widely used in the study of Geoscience. However, blurry images are often taken in collected data, and it takes a lot of time and effort to distinguish clear images from blurry ones. In this work, we apply Machine learning techniques, such as Support Vector Machine (SVM) and Neural Network (NN) to classify HD images in Geoscience as clear and blurry, and therefore automate data cleaning in Geoscience. We compare the results of classification based on features abstracted from several mathematical models. Some of the implementation of our machine learning tool is freely available at: https://github.com/zachgolden/geoai.</p></details> | 8 pages, 14 figures |
| **[70 years of machine learning in geoscience in review](http://arxiv.org/abs/2006.13311v3)** | 2020-08-26 | [papers-cool](https://papers.cool/arxiv/2006.13311v3) | <details><summary>Show</summary><p>This review gives an overview of the development of machine learning in geoscience. A thorough analysis of the co-developments of machine learning applications throughout the last 70 years relates the recent enthusiasm for machine learning to developments in geoscience. I explore the shift of kriging towards a mainstream machine learning method and the historic application of neural networks in geoscience, following the general trend of machine learning enthusiasm through the decades. Furthermore, this chapter explores the shift from mathematical fundamentals and knowledge in software development towards skills in model validation, applied statistics, and integrated subject matter expertise. The review is interspersed with code examples to complement the theoretical foundations and illustrate model validation and machine learning explainability for science. The scope of this review includes various shallow machine learning methods, e.g. Decision Trees, Random Forests, Support-Vector Machines, and Gaussian Processes, as well as, deep neural networks, including feed-forward neural networks, convolutional neural networks, recurrent neural networks and generative adversarial networks. Regarding geoscience, the review has a bias towards geophysics but aims to strike a balance with geochemistry, geostatistics, and geology, however excludes remote sensing, as this would exceed the scope. In general, I aim to provide context for the recent enthusiasm surrounding deep learning with respect to research, hardware, and software developments that enable successful application of shallow and deep machine learning in all disciplines of Earth science.</p></details> | <details><summary>36 pa...</summary><p>36 pages, 17 figures, book chapter</p></details> |
| **[Physically Interpretable Neural Networks for the Geosciences: Applications to Earth System Variability](http://arxiv.org/abs/1912.01752v2)** | 2020-05-27 | [papers-cool](https://papers.cool/arxiv/1912.01752v2) | <details><summary>Show</summary><p>Neural networks have become increasingly prevalent within the geosciences, although a common limitation of their usage has been a lack of methods to interpret what the networks learn and how they make decisions. As such, neural networks have often been used within the geosciences to most accurately identify a desired output given a set of inputs, with the interpretation of what the network learns used as a secondary metric to ensure the network is making the right decision for the right reason. Neural network interpretation techniques have become more advanced in recent years, however, and we therefore propose that the ultimate objective of using a neural network can also be the interpretation of what the network has learned rather than the output itself. We show that the interpretation of neural networks can enable the discovery of scientifically meaningful connections within geoscientific data. In particular, we use two methods for neural network interpretation called backwards optimization and layerwise relevance propagation, both of which project the decision pathways of a network back onto the original input dimensions. To the best of our knowledge, LRP has not yet been applied to geoscientific research, and we believe it has great potential in this area. We show how these interpretation techniques can be used to reliably infer scientifically meaningful information from neural networks by applying them to common climate patterns. These results suggest that combining interpretable neural networks with novel scientific hypotheses will open the door to many new avenues in neural network-related geoscience research.</p></details> | <details><summary>The s...</summary><p>The second version of this manuscript is currently under review at the Journal of Advances in Modeling Earth Systems (JAMES)</p></details> |
| **[HexaShrink, an exact scalable framework for hexahedral meshes with attributes and discontinuities: multiresolution rendering and storage of geoscience models](http://arxiv.org/abs/1903.07614v2)** | 2019-05-04 | [papers-cool](https://papers.cool/arxiv/1903.07614v2) | <details><summary>Show</summary><p>With huge data acquisition progresses realized in the past decades and acquisition systems now able to produce high resolution grids and point clouds, the digitization of physical terrains becomes increasingly more precise. Such extreme quantities of generated and modeled data greatly impact computational performances on many levels of high-performance computing (HPC): storage media, memory requirements, transfer capability, and finally simulation interactivity, necessary to exploit this instance of big data. Efficient representations and storage are thus becoming "enabling technologies'' in HPC experimental and simulation science. We propose HexaShrink, an original decomposition scheme for structured hexahedral volume meshes. The latter are used for instance in biomedical engineering, materials science, or geosciences. HexaShrink provides a comprehensive framework allowing efficient mesh visualization and storage. Its exactly reversible multiresolution decomposition yields a hierarchy of meshes of increasing levels of details, in terms of either geometry, continuous or categorical properties of cells. Starting with an overview of volume meshes compression techniques, our contribution blends coherently different multiresolution wavelet schemes in different dimensions. It results in a global framework preserving discontinuities (faults) across scales, implemented as a fully reversible upscaling at different resolutions. Experimental results are provided on meshes of varying size and complexity. They emphasize the consistency of the proposed representation, in terms of visualization, attribute downsampling and distribution at different resolutions. Finally, HexaShrink yields gains in storage space when combined to lossless compression techniques.</p></details> |  |
| **[Particle filters for high-dimensional geoscience applications: a review](http://arxiv.org/abs/1807.10434v2)** | 2019-04-13 | [papers-cool](https://papers.cool/arxiv/1807.10434v2) | <details><summary>Show</summary><p>Particle filters contain the promise of fully nonlinear data assimilation. They have been applied in numerous science areas, but their application to the geosciences has been limited due to their inefficiency in high-dimensional systems in standard settings. However, huge progress has been made, and this limitation is disappearing fast due to recent developments in proposal densities, the use of ideas from (optimal) transportation, the use of localisation and intelligent adaptive resampling strategies. Furthermore, powerful hybrids between particle filters and ensemble Kalman filters and variational methods have been developed. We present a state of the art discussion of present efforts of developing particle filters for highly nonlinear geoscience state-estimation problems with an emphasis on atmospheric and oceanic applications, including many new ideas, derivations, and unifications, highlighting hidden connections, and generating a valuable tool and guide for the community. Initial experiments show that particle filters can be competitive with present-day methods for numerical weather prediction suggesting that they will become mainstream soon.</p></details> | <details><summary>Revie...</summary><p>Review paper, 36 pages, 9 figures, Resubmitted to Q.J.Royal Meteorol. Soc</p></details> |
| **[Power-law size distributions in geoscience revisited](http://arxiv.org/abs/1810.07868v2)** | 2019-04-04 | [papers-cool](https://papers.cool/arxiv/1810.07868v2) | <details><summary>Show</summary><p>The size or energy of diverse structures or phenomena in geoscience appears to follow power-law distributions. A rigorous statistical analysis of such observations is tricky, though. Observables can span several orders of magnitude, but the range for which the power law may be valid is typically truncated, usually because the smallest events are too tiny to be detected and the largest ones are limited by the system size. We revisit several examples of proposed power-law distributions dealing with potentially damaging natural phenomena. Adequate fits of the distributions of sizes are especially important in these cases, given that they may be used to assess long-term hazard. After reviewing the theoretical background for power-law distributions, we improve an objective statistical fitting method and apply it to diverse data sets. The method is described in full detail and it is easy to implement. Our analysis elucidates the range of validity of the power-law fit and the corresponding exponent, and whether a power-law tail is improved by a truncated log-normal. We confirm that impact fireballs and Californian earthquakes show untruncated power-law behavior, whereas global earthquakes follow a double power law. Rain precipitation over space and time and tropical cyclones show a truncated power-law regime. Karst sinkholes and wildfires, in contrast, are better described by truncated log-normals, although wildfires also may show power-law regimes. Our conclusions only apply to the analyzed data sets, but show the potential of applying this robust statistical technique in the future.</p></details> |  |
| **[Data Assimilation in the Geosciences - An overview on methods, issues and perspectives](http://arxiv.org/abs/1709.02798v3)** | 2018-06-08 | [papers-cool](https://papers.cool/arxiv/1709.02798v3) | <details><summary>Show</summary><p>We commonly refer to state-estimation theory in geosciences as data assimilation. This term encompasses the entire sequence of operations that, starting from the observations of a system, and from additional statistical and dynamical information (such as a dynamical evolution model), provides an estimate of its state. Data assimilation is standard practice in numerical weather prediction, but its application is becoming widespread in many other areas of climate, atmosphere, ocean and environment modeling; in all circumstances where one intends to estimate the state of a large dynamical system based on limited information. While the complexity of data assimilation, and of the methods thereof, stands on its interdisciplinary nature across statistics, dynamical systems and numerical optimization, when applied to geosciences an additional difficulty arises by the continually increasing sophistication of the environmental models. Thus, in spite of data assimilation being nowadays ubiquitous in geosciences, it has so far remained a topic mostly reserved to experts. We aim this overview article at geoscientists with a background in mathematical and physical modeling, who are interested in the rapid development of data assimilation and its growing domains of application in environmental science, but so far have not delved into its conceptual and methodological complexities.</p></details> | <details><summary>79 pa...</summary><p>79 pages, 10 figures, Invited review</p></details> |
| **[Machine Learning for the Geosciences: Challenges and Opportunities](http://arxiv.org/abs/1711.04708v1)** | 2017-11-13 | [papers-cool](https://papers.cool/arxiv/1711.04708v1) | <details><summary>Show</summary><p>Geosciences is a field of great societal relevance that requires solutions to several urgent problems facing our humanity and the planet. As geosciences enters the era of big data, machine learning (ML) -- that has been widely successful in commercial domains -- offers immense potential to contribute to problems in geosciences. However, problems in geosciences have several unique challenges that are seldom found in traditional applications, requiring novel problem formulations and methodologies in machine learning. This article introduces researchers in the machine learning (ML) community to these challenges offered by geoscience problems and the opportunities that exist for advancing both machine learning and geosciences. We first highlight typical sources of geoscience data and describe their properties that make it challenging to use traditional machine learning techniques. We then describe some of the common categories of geoscience problems where machine learning can play a role, and discuss some of the existing efforts and promising directions for methodological development in machine learning. We conclude by discussing some of the emerging research themes in machine learning that are applicable across all problems in the geosciences, and the importance of a deep collaboration between machine learning and geosciences for synergistic advancements in both disciplines.</p></details> | <details><summary>Under...</summary><p>Under review at IEEE Transactions on Knowledge and Data Engineering</p></details> |

## Spatial
| **Title** | **Date** | **KiMi** | **Abstract** | **Comment** |
| --- | --- | --- | --- | --- |
| **[SFNet: Fusion of Spatial and Frequency-Domain Features for Remote Sensing Image Forgery Detection](http://arxiv.org/abs/2506.20599v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20599v1) | <details><summary>Show</summary><p>The rapid advancement of generative artificial intelligence is producing fake remote sensing imagery (RSI) that is increasingly difficult to detect, potentially leading to erroneous intelligence, fake news, and even conspiracy theories. Existing forgery detection methods typically rely on single visual features to capture predefined artifacts, such as spatial-domain cues to detect forged objects like roads or buildings in RSI, or frequency-domain features to identify artifacts from up-sampling operations in adversarial generative networks (GANs). However, the nature of artifacts can significantly differ depending on geographic terrain, land cover types, or specific features within the RSI. Moreover, these complex artifacts evolve as generative models become more sophisticated. In short, over-reliance on a single visual cue makes existing forgery detectors struggle to generalize across diverse remote sensing data. This paper proposed a novel forgery detection framework called SFNet, designed to identify fake images in diverse remote sensing data by leveraging spatial and frequency domain features. Specifically, to obtain rich and comprehensive visual information, SFNet employs two independent feature extractors to capture spatial and frequency domain features from input RSIs. To fully utilize the complementary domain features, the domain feature mapping module and the hybrid domain feature refinement module(CBAM attention) of SFNet are designed to successively align and fuse the multi-domain features while suppressing redundant information. Experiments on three datasets show that SFNet achieves an accuracy improvement of 4%-15.18% over the state-of-the-art RS forgery detection methods and exhibits robust generalization capabilities. The code is available at https://github.com/GeoX-Lab/RSTI/tree/main/SFNet.</p></details> |  |
| **[Breaking Spatial Boundaries: Spectral-Domain Registration Guided Hyperspectral and Multispectral Blind Fusion](http://arxiv.org/abs/2506.20293v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20293v1) | <details><summary>Show</summary><p>The blind fusion of unregistered hyperspectral images (HSIs) and multispectral images (MSIs) has attracted growing attention recently. To address the registration challenge, most existing methods employ spatial transformations on the HSI to achieve alignment with the MSI. However, due to the substantial differences in spatial resolution of the images, the performance of these methods is often unsatisfactory. Moreover, the registration process tends to be time-consuming when dealing with large-sized images in remote sensing. To address these issues, we propose tackling the registration problem from the spectral domain. Initially, a lightweight Spectral Prior Learning (SPL) network is developed to extract spectral features from the HSI and enhance the spectral resolution of the MSI. Following this, the obtained image undergoes spatial downsampling to produce the registered HSI. In this process, subspace representation and cyclic training strategy are employed to improve spectral accuracy of the registered HSI obtained. Next, we propose a blind sparse fusion (BSF) method, which utilizes group sparsity regularization to equivalently promote the low-rankness of the image. This approach not only circumvents the need for rank estimation, but also reduces computational complexity. Then, we employ the Proximal Alternating Optimization (PAO) algorithm to solve the BSF model, and present its convergence analysis. Finally, extensive numerical experiments on simulated and real datasets are conducted to verify the effectiveness of our method in registration and fusion. We also demonstrate its efficacy in enhancing classification performance.</p></details> |  |
| **[ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding](http://arxiv.org/abs/2505.21381v4)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2505.21381v4) | <details><summary>Show</summary><p>State Space models (SSMs) such as PointMamba enable efficient feature extraction for point cloud self-supervised learning with linear complexity, outperforming Transformers in computational efficiency. However, existing PointMamba-based methods depend on complex token ordering and random masking, which disrupt spatial continuity and local semantic correlations. We propose ZigzagPointMamba to tackle these challenges. The core of our approach is a simple zigzag scan path that globally sequences point cloud tokens, enhancing spatial continuity by preserving the proximity of spatially adjacent point tokens. Nevertheless, random masking undermines local semantic modeling in self-supervised learning. To address this, we introduce a Semantic-Siamese Masking Strategy (SMS), which masks semantically similar tokens to facilitate reconstruction by integrating local features of original and similar tokens. This overcomes the dependence on isolated local features and enables robust global semantic modeling. Our pre-trained ZigzagPointMamba weights significantly improve downstream tasks, achieving a 1.59% mIoU gain on ShapeNetPart for part segmentation, a 0.4% higher accuracy on ModelNet40 for classification, and 0.19%, 1.22%, and 0.72% higher accuracies respectively for the classification tasks on the OBJ-BG, OBJ-ONLY, and PB-T50-RS subsets of ScanObjectNN.</p></details> | <details><summary>The f...</summary><p>The format of the document has an error and needs to be revised</p></details> |
| **[ToSA: Token Merging with Spatial Awareness](http://arxiv.org/abs/2506.20066v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.20066v1) | <details><summary>Show</summary><p>Token merging has emerged as an effective strategy to accelerate Vision Transformers (ViT) by reducing computational costs. However, existing methods primarily rely on the visual token's feature similarity for token merging, overlooking the potential of integrating spatial information, which can serve as a reliable criterion for token merging in the early layers of ViT, where the visual tokens only possess weak visual information. In this paper, we propose ToSA, a novel token merging method that combines both semantic and spatial awareness to guide the token merging process. ToSA leverages the depth image as input to generate pseudo spatial tokens, which serve as auxiliary spatial information for the visual token merging process. With the introduced spatial awareness, ToSA achieves a more informed merging strategy that better preserves critical scene structure. Experimental results demonstrate that ToSA outperforms previous token merging methods across multiple benchmarks on visual and embodied question answering while largely reducing the runtime of the ViT, making it an efficient solution for ViT acceleration. The code will be available at: https://github.com/hsiangwei0903/ToSA</p></details> | <details><summary>Accep...</summary><p>Accepted by IROS 2025</p></details> |
| **[Two-Stream Spatial-Temporal Transformer Framework for Person Identification via Natural Conversational Keypoints](http://arxiv.org/abs/2502.20803v2)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2502.20803v2) | <details><summary>Show</summary><p>In the age of AI-driven generative technologies, traditional biometric recognition systems face unprecedented challenges, particularly from sophisticated deepfake and face reenactment techniques. In this study, we propose a Two-Stream Spatial-Temporal Transformer Framework for person identification using upper body keypoints visible during online conversations, which we term conversational keypoints. Our framework processes both spatial relationships between keypoints and their temporal evolution through two specialized branches: a Spatial Transformer (STR) that learns distinctive structural patterns in keypoint configurations, and a Temporal Transformer (TTR) that captures sequential motion patterns. Using the state-of-the-art Sapiens pose estimator, we extract 133 keypoints (based on COCO-WholeBody format) representing facial features, head pose, and hand positions. The framework was evaluated on a dataset of 114 individuals engaged in natural conversations, achieving recognition accuracies of 80.12% for the spatial stream, 63.61% for the temporal stream. We then explored two fusion strategies: a shared loss function approach achieving 82.22% accuracy, and a feature-level fusion method that concatenates feature maps from both streams, significantly improving performance to 94.86%. By jointly modeling both static anatomical relationships and dynamic movement patterns, our approach learns comprehensive identity signatures that are more robust to spoofing than traditional appearance-based methods.</p></details> | <details><summary>I wou...</summary><p>I would like to withdraw this submission due to the need for substantial revisions in the results and analysis. I plan to correct and improve the study and submit a more complete version in the near future</p></details> |
| **[Estimating Spatially-Dependent GPS Errors Using a Swarm of Robots](http://arxiv.org/abs/2506.19712v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19712v1) | <details><summary>Show</summary><p>External factors, including urban canyons and adversarial interference, can lead to Global Positioning System (GPS) inaccuracies that vary as a function of the position in the environment. This study addresses the challenge of estimating a static, spatially-varying error function using a team of robots. We introduce a State Bias Estimation Algorithm (SBE) whose purpose is to estimate the GPS biases. The central idea is to use sensed estimates of the range and bearing to the other robots in the team to estimate changes in bias across the environment. A set of drones moves in a 2D environment, each sampling data from GPS, range, and bearing sensors. The biases calculated by the SBE at estimated positions are used to train a Gaussian Process Regression (GPR) model. We use a Sparse Gaussian process-based Informative Path Planning (IPP) algorithm that identifies high-value regions of the environment for data collection. The swarm plans paths that maximize information gain in each iteration, further refining their understanding of the environment's positional bias landscape. We evaluated SBE and IPP in simulation and compared the IPP methodology to an open-loop strategy.</p></details> | <details><summary>6 pag...</summary><p>6 pages, 7 figures, 2025 IEEE 21st International Conference on Automation Science and Engineering</p></details> |
| **[T-Rex: Task-Adaptive Spatial Representation Extraction for Robotic Manipulation with Vision-Language Models](http://arxiv.org/abs/2506.19498v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19498v1) | <details><summary>Show</summary><p>Building a general robotic manipulation system capable of performing a wide variety of tasks in real-world settings is a challenging task. Vision-Language Models (VLMs) have demonstrated remarkable potential in robotic manipulation tasks, primarily due to the extensive world knowledge they gain from large-scale datasets. In this process, Spatial Representations (such as points representing object positions or vectors representing object orientations) act as a bridge between VLMs and real-world scene, effectively grounding the reasoning abilities of VLMs and applying them to specific task scenarios. However, existing VLM-based robotic approaches often adopt a fixed spatial representation extraction scheme for various tasks, resulting in insufficient representational capability or excessive extraction time. In this work, we introduce T-Rex, a Task-Adaptive Framework for Spatial Representation Extraction, which dynamically selects the most appropriate spatial representation extraction scheme for each entity based on specific task requirements. Our key insight is that task complexity determines the types and granularity of spatial representations, and Stronger representational capabilities are typically associated with Higher overall system operation costs. Through comprehensive experiments in real-world robotic environments, we show that our approach delivers significant advantages in spatial understanding, efficiency, and stability without additional training.</p></details> | <details><summary>submi...</summary><p>submitted to NeurIPS 2025</p></details> |
| **[Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System](http://arxiv.org/abs/2506.19433v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19433v1) | <details><summary>Show</summary><p>Vision-and-Language Navigation (VLN) in large-scale urban environments requires embodied agents to ground linguistic instructions in complex scenes and recall relevant experiences over extended time horizons. Prior modular pipelines offer interpretability but lack unified memory, while end-to-end (M)LLM agents excel at fusing vision and language yet remain constrained by fixed context windows and implicit spatial reasoning. We introduce \textbf{Mem4Nav}, a hierarchical spatial-cognition long-short memory system that can augment any VLN backbone. Mem4Nav fuses a sparse octree for fine-grained voxel indexing with a semantic topology graph for high-level landmark connectivity, storing both in trainable memory tokens embedded via a reversible Transformer. Long-term memory (LTM) compresses and retains historical observations at both octree and graph nodes, while short-term memory (STM) caches recent multimodal entries in relative coordinates for real-time obstacle avoidance and local planning. At each step, STM retrieval sharply prunes dynamic context, and, when deeper history is needed, LTM tokens are decoded losslessly to reconstruct past embeddings. Evaluated on Touchdown and Map2Seq across three backbones (modular, state-of-the-art VLN with prompt-based LLM, and state-of-the-art VLN with strided-attention MLLM), Mem4Nav yields 7-13 pp gains in Task Completion, sufficient SPD reduction, and >10 pp nDTW improvement. Ablations confirm the indispensability of both the hierarchical map and dual memory modules. Our codes are open-sourced via https://github.com/tsinghua-fib-lab/Mem4Nav.</p></details> |  |
| **[Loss functions incorporating auditory spatial perception in deep learning -- a review](http://arxiv.org/abs/2506.19404v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19404v1) | <details><summary>Show</summary><p>Binaural reproduction aims to deliver immersive spatial audio with high perceptual realism over headphones. Loss functions play a central role in optimizing and evaluating algorithms that generate binaural signals. However, traditional signal-related difference measures often fail to capture the perceptual properties that are essential to spatial audio quality. This review paper surveys recent loss functions that incorporate spatial perception cues relevant to binaural reproduction. It focuses on losses applied to binaural signals, which are often derived from microphone recordings or Ambisonics signals, while excluding those based on room impulse responses. Guided by the Spatial Audio Quality Inventory (SAQI), the review emphasizes perceptual dimensions related to source localization and room response, while excluding general spectral-temporal attributes. The literature survey reveals a strong focus on localization cues, such as interaural time and level differences (ITDs, ILDs), while reverberation and other room acoustic attributes remain less explored in loss function design. Recent works that estimate room acoustic parameters and develop embeddings that capture room characteristics indicate their potential for future integration into neural network training. The paper concludes by highlighting future research directions toward more perceptually grounded loss functions that better capture the listener's spatial experience.</p></details> | <details><summary>Submi...</summary><p>Submitted to I3DA 2025</p></details> |
| **[An accuracy-runtime trade-off comparison of scalable Gaussian process approximations for spatial data](http://arxiv.org/abs/2501.11448v2)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2501.11448v2) | <details><summary>Show</summary><p>Gaussian processes (GPs) are flexible, probabilistic, non-parametric models widely employed in various fields such as spatial statistics and machine learning. A drawback of Gaussian processes is their computational cost having $\mathcal{O}(N^3)$ time and $\mathcal{O}(N^2)$ memory complexity which makes them prohibitive for large data sets. Numerous approximation techniques have been proposed to address this limitation. In this work, we systematically compare the accuracy of different Gaussian process approximations concerning likelihood evaluation, parameter estimation, and prediction taking into account the computational time required to perform these tasks. In other words, we analyze the trade-off between accuracy and runtime on multiple simulated and large-scale real-world data sets. We find that Vecchia approximations consistently emerge as the most accurate in almost all experiments.</p></details> |  |
| **[Temporal-Spectral-Spatial Unified Remote Sensing Dense Prediction](http://arxiv.org/abs/2505.12280v2)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2505.12280v2) | <details><summary>Show</summary><p>The proliferation of multi-source remote sensing data has propelled the development of deep learning for dense prediction, yet significant challenges in data and task unification persist. Current deep learning architectures for remote sensing are fundamentally rigid. They are engineered for fixed input-output configurations, restricting their adaptability to the heterogeneous spatial, temporal, and spectral dimensions inherent in real-world data. Furthermore, these models neglect the intrinsic correlations among semantic segmentation, binary change detection, and semantic change detection, necessitating the development of distinct models or task-specific decoders. This paradigm is also constrained to a predefined set of output semantic classes, where any change to the classes requires costly retraining. To overcome these limitations, we introduce the Spatial-Temporal-Spectral Unified Network (STSUN) for unified modeling. STSUN can adapt to input and output data with arbitrary spatial sizes, temporal lengths, and spectral bands by leveraging their metadata for a unified representation. Moreover, STSUN unifies disparate dense prediction tasks within a single architecture by conditioning the model on trainable task embeddings. Similarly, STSUN facilitates flexible prediction across any set of semantic categories by integrating trainable category embeddings as metadata. Extensive experiments on multiple datasets with diverse STS configurations in multiple scenarios demonstrate that a single STSUN model effectively adapts to heterogeneous inputs and outputs, unifying various dense prediction tasks and diverse semantic class predictions. The proposed approach consistently achieves state-of-the-art performance, highlighting its robustness and generalizability for complex remote sensing applications.</p></details> | <details><summary>14 pa...</summary><p>14 pages, 6 figures, Code link:https://github.com/walking-shadow/Official_TSSUN</p></details> |
| **[Spatial Regionalization: A Hybrid Quantum Computing Approach](http://arxiv.org/abs/2506.18799v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18799v1) | <details><summary>Show</summary><p>Quantum computing has shown significant potential to address complex optimization problems; however, its application remains confined to specific problems at limited scales. Spatial regionalization remains largely unexplored in quantum computing due to its complexity and large number of variables. In this paper, we introduce the first hybrid quantum-classical method to spatial regionalization by decomposing the problem into manageable subproblems, leveraging the strengths of both classical and quantum computation. This study establishes a foundational framework for effectively integrating quantum computing methods into realistic and complex spatial optimization tasks. Our initial results show a promising quantum performance advantage for a broad range of spatial regionalization problems and their variants.</p></details> |  |
| **[SWA-SOP: Spatially-aware Window Attention for Semantic Occupancy Prediction in Autonomous Driving](http://arxiv.org/abs/2506.18785v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18785v1) | <details><summary>Show</summary><p>Perception systems in autonomous driving rely on sensors such as LiDAR and cameras to perceive the 3D environment. However, due to occlusions and data sparsity, these sensors often fail to capture complete information. Semantic Occupancy Prediction (SOP) addresses this challenge by inferring both occupancy and semantics of unobserved regions. Existing transformer-based SOP methods lack explicit modeling of spatial structure in attention computation, resulting in limited geometric awareness and poor performance in sparse or occluded areas. To this end, we propose Spatially-aware Window Attention (SWA), a novel mechanism that incorporates local spatial context into attention. SWA significantly improves scene completion and achieves state-of-the-art results on LiDAR-based SOP benchmarks. We further validate its generality by integrating SWA into a camera-based SOP pipeline, where it also yields consistent gains across modalities.</p></details> | under reviewed |
| **[A Spatial-Domain Coordinated Control Method for CAVs at Unsignalized Intersections Considering Motion Uncertainty](http://arxiv.org/abs/2412.04290v2)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2412.04290v2) | <details><summary>Show</summary><p>Coordinated control of connected and automated vehicles (CAVs) emerges as a promising technology to improve traffic safety, efficiency, and sustainability. Meanwhile, mixed traffic, where CAVs coexist with conventional human-driven vehicles (HDVs), represents an upcoming and necessary stage in the development of intelligent transportation systems. Considering the motion uncertainty of HDVs, this paper proposes a coordinated control method for trajectory planning of CAVs at an unsignalized intersection in mixed traffic. By sampling in distance and using an exact change of variables, the coordinated control problem is formulated in the spatial domain as a nonlinear program, thereby allowing for unified linear collision avoidance constraints to handle vehicle crossing, following, merging, and diverging conflicts. The motion uncertainty of HDVs is decoupled and modeled as path uncertainty and speed uncertainty, whereby the robustness of collision avoidance is ensured in both spatial and temporal dimensions. The prediction deviation for HDVs is compensated by receding horizon optimization, and a real-time iteration (RTI) scheme is developed to improve computational efficiency. Simulation case studies are conducted to validate the efficacy, robustness, and potential for real-time application of the proposed methods. The results show that the proposed control scheme provides collision-free and smooth trajectories with state and control constraints satisfied. Compared with the converged baseline, the RTI scheme reduces the computation time by orders of magnitude, and the solution deviation is less than 2.3%, demonstrating a favorable trade-off between computational effort and optimality.</p></details> | 15 pages, 15 figures |
| **[SHAMaNS: Sound Localization with Hybrid Alpha-Stable Spatial Measure and Neural Steerer](http://arxiv.org/abs/2506.18954v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18954v1) | <details><summary>Show</summary><p>This paper describes a sound source localization (SSL) technique that combines an $\alpha$-stable model for the observed signal with a neural network-based approach for modeling steering vectors. Specifically, a physics-informed neural network, referred to as Neural Steerer, is used to interpolate measured steering vectors (SVs) on a fixed microphone array. This allows for a more robust estimation of the so-called $\alpha$-stable spatial measure, which represents the most plausible direction of arrival (DOA) of a target signal. As an $\alpha$-stable model for the non-Gaussian case ($\alpha$ $\in$ (0, 2)) theoretically defines a unique spatial measure, we choose to leverage it to account for residual reconstruction error of the Neural Steerer in the downstream tasks. The objective scores indicate that our proposed technique outperforms state-of-the-art methods in the case of multiple sound sources.</p></details> | <details><summary>Europ...</summary><p>European Signal Processing Conference (EUSIPCO), Sep 2025, Palermo, Italy</p></details> |
| **[InternSpatial: A Comprehensive Dataset for Spatial Reasoning in Vision-Language Models](http://arxiv.org/abs/2506.18385v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18385v1) | <details><summary>Show</summary><p>Recent benchmarks and datasets have been proposed to improve spatial reasoning in vision-language models (VLMs), yet existing open resources remain limited in scale, visual diversity, and instruction expressiveness. In this work, we introduce InternSpatial, the largest open-source dataset for spatial reasoning in VLMs, along with InternSpatial-Bench, a corresponding evaluation benchmark designed to assess spatial understanding under diverse instruction formats. InternSpatial comprises 12 million QA pairs spanning both single-view and multi-view settings, drawn from diverse visual environments and supporting 19 instruction formats that reflect varied query styles. For evaluation, we propose InternSpatial-Bench for single-view tasks and expand multi-view reasoning by introducing a novel rotation angle prediction task that has not been explored in prior work. Experimental results show that models trained on InternSpatial achieve 12.1% improvement on InternSpatial-Bench and 10.7% on VSI-Bench, while maintaining strong performance on general-purpose benchmarks. We hope these resources will support the development of spatially capable VLMs in practical applications such as robotics and embodied AI.</p></details> |  |
| **[Spatial frequency information fusion network for few-shot learning](http://arxiv.org/abs/2506.18364v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18364v1) | <details><summary>Show</summary><p>The objective of Few-shot learning is to fully leverage the limited data resources for exploring the latent correlations within the data by applying algorithms and training a model with outstanding performance that can adequately meet the demands of practical applications. In practical applications, the number of images in each category is usually less than that in traditional deep learning, which can lead to over-fitting and poor generalization performance. Currently, many Few-shot classification models pay more attention to spatial domain information while neglecting frequency domain information, which contains more feature information. Ignoring frequency domain information will prevent the model from fully exploiting feature information, which would effect the classification performance. Based on conventional data augmentation, this paper proposes an SFIFNet with innovative data preprocessing. The key of this method is enhancing the accuracy of image feature representation by integrating frequency domain information with spatial domain information. The experimental results demonstrate the effectiveness of this method in enhancing classification performance.</p></details> |  |
| **[Global Context-aware Representation Learning for Spatially Resolved Transcriptomics](http://arxiv.org/abs/2506.15698v2)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.15698v2) | <details><summary>Show</summary><p>Spatially Resolved Transcriptomics (SRT) is a cutting-edge technique that captures the spatial context of cells within tissues, enabling the study of complex biological networks. Recent graph-based methods leverage both gene expression and spatial information to identify relevant spatial domains. However, these approaches fall short in obtaining meaningful spot representations, especially for spots near spatial domain boundaries, as they heavily emphasize adjacent spots that have minimal feature differences from an anchor node. To address this, we propose Spotscape, a novel framework that introduces the Similarity Telescope module to capture global relationships between multiple spots. Additionally, we propose a similarity scaling strategy to regulate the distances between intra- and inter-slice spots, facilitating effective multi-slice integration. Extensive experiments demonstrate the superiority of Spotscape in various downstream tasks, including single-slice and multi-slice scenarios. Our code is available at the following link: https: //github.com/yunhak0/Spotscape.</p></details> | ICML 2025 |
| **[A Multi-Scale Spatial Attention-Based Zero-Shot Learning Framework for Low-Light Image Enhancement](http://arxiv.org/abs/2506.18323v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18323v1) | <details><summary>Show</summary><p>Low-light image enhancement remains a challenging task, particularly in the absence of paired training data. In this study, we present LucentVisionNet, a novel zero-shot learning framework that addresses the limitations of traditional and deep learning-based enhancement methods. The proposed approach integrates multi-scale spatial attention with a deep curve estimation network, enabling fine-grained enhancement while preserving semantic and perceptual fidelity. To further improve generalization, we adopt a recurrent enhancement strategy and optimize the model using a composite loss function comprising six tailored components, including a novel no-reference image quality loss inspired by human visual perception. Extensive experiments on both paired and unpaired benchmark datasets demonstrate that LucentVisionNet consistently outperforms state-of-the-art supervised, unsupervised, and zero-shot methods across multiple full-reference and no-reference image quality metrics. Our framework achieves high visual quality, structural consistency, and computational efficiency, making it well-suited for deployment in real-world applications such as mobile photography, surveillance, and autonomous navigation.</p></details> |  |
| **[CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs](http://arxiv.org/abs/2412.19663v2)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2412.19663v2) | <details><summary>Show</summary><p>Computer-aided design (CAD) significantly enhances the efficiency, accuracy, and innovation of design processes by enabling precise 2D and 3D modeling, extensive analysis, and optimization. Existing methods for creating CAD models rely on latent vectors or point clouds, which are difficult to obtain, and storage costs are substantial. Recent advances in Multimodal Large Language Models (MLLMs) have inspired researchers to use natural language instructions and images for CAD model construction. However, these models still struggle with inferring accurate 3D spatial location and orientation, leading to inaccuracies in determining the spatial 3D starting points and extrusion directions for constructing geometries. This work introduces CAD-GPT, a CAD synthesis method with spatial reasoning-enhanced MLLM that takes either a single image or a textual description as input. To achieve precise spatial inference, our approach introduces a 3D Modeling Spatial Mechanism. This method maps 3D spatial positions and 3D sketch plane rotation angles into a 1D linguistic feature space using a specialized spatial unfolding mechanism, while discretizing 2D sketch coordinates into an appropriate planar space to enable precise determination of spatial starting position, sketch orientation, and 2D sketch coordinate translations. Extensive experiments demonstrate that CAD-GPT consistently outperforms existing state-of-the-art methods in CAD model synthesis, both quantitatively and qualitatively.</p></details> | <details><summary>Accep...</summary><p>Accepted at AAAI 2025 (Vol. 39, No. 8), pages 7880-7888. DOI: 10.1609/aaai.v39i8.32849</p></details> |
| **[MIRAGE: A Multi-modal Benchmark for Spatial Perception, Reasoning, and Intelligence](http://arxiv.org/abs/2505.10604v2)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2505.10604v2) | <details><summary>Show</summary><p>Spatial perception and reasoning are core components of human cognition, encompassing object recognition, spatial relational understanding, and dynamic reasoning. Despite progress in computer vision, existing benchmarks reveal significant gaps in models' abilities to accurately recognize object attributes and reason about spatial relationships, both essential for dynamic reasoning. To address these limitations, we propose MIRAGE, a multi-modal benchmark designed to evaluate models' capabilities in Counting (object attribute recognition), Relation (spatial relational reasoning), and Counting with Relation. Through diverse and complex scenarios requiring fine-grained recognition and reasoning, MIRAGE highlights critical limitations in state-of-the-art models, underscoring the need for improved representations and reasoning frameworks. By targeting these foundational abilities, MIRAGE provides a pathway toward spatiotemporal reasoning in future research.</p></details> |  |
| **[Transformer-based RGB-T Tracking with Channel and Spatial Feature Fusion](http://arxiv.org/abs/2405.03177v3)** | 2025-06-22 | [papers-cool](https://papers.cool/arxiv/2405.03177v3) | <details><summary>Show</summary><p>The main problem in RGB-T tracking is the correct and optimal merging of the cross-modal features of visible and thermal images. Some previous methods either do not fully exploit the potential of RGB and TIR information for channel and spatial feature fusion or lack a direct interaction between the template and the search area, which limits the model's ability to fully utilize the original semantic information of both modalities. To address these limitations, we investigate how to achieve a direct fusion of cross-modal channels and spatial features in RGB-T tracking and propose CSTNet. It uses the Vision Transformer (ViT) as the backbone and adds a Joint Spatial and Channel Fusion Module (JSCFM) and Spatial Fusion Module (SFM) integrated between the transformer blocks to facilitate cross-modal feature interaction. The JSCFM module achieves joint modeling of channel and multi-level spatial features. The SFM module includes a cross-attention-like architecture for cross modeling and joint learning of RGB and TIR features. Comprehensive experiments show that CSTNet achieves state-of-the-art performance. To enhance practicality, we retrain the model without JSCFM and SFM modules and use CSNet as the pretraining weight, and propose CSTNet-small, which achieves 50% speedup with an average decrease of 1-2% in SR and PR performance. CSTNet and CSTNet-small achieve real-time speeds of 21 fps and 33 fps on the Nvidia Jetson Xavier, meeting actual deployment requirements. Code is available at https://github.com/LiYunfengLYF/CSTNet.</p></details> | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Balancing Interference and Correlation in Spatial Experimental Designs: A Causal Graph Cut Approach](http://arxiv.org/abs/2505.20130v2)** | 2025-06-21 | [papers-cool](https://papers.cool/arxiv/2505.20130v2) | <details><summary>Show</summary><p>This paper focuses on the design of spatial experiments to optimize the amount of information derived from the experimental data and enhance the accuracy of the resulting causal effect estimator. We propose a surrogate function for the mean squared error (MSE) of the estimator, which facilitates the use of classical graph cut algorithms to learn the optimal design. Our proposal offers three key advances: (1) it accommodates moderate to large spatial interference effects; (2) it adapts to different spatial covariance functions; (3) it is computationally efficient. Theoretical results and numerical experiments based on synthetic environments and a dispatch simulator that models a city-scale ridesharing market, further validate the effectiveness of our design. A python implementation of our method is available at https://github.com/Mamba413/CausalGraphCut.</p></details> | Accepted by ICML2025 |
| **[On the Power of Spatial Locality on Online Routing Problems](http://arxiv.org/abs/2506.17517v1)** | 2025-06-20 | [papers-cool](https://papers.cool/arxiv/2506.17517v1) | <details><summary>Show</summary><p>We consider the online versions of two fundamental routing problems, traveling salesman (TSP) and dial-a-ride (DARP), which have a variety of relevant applications in logistics and robotics. The online versions of these problems concern with efficiently serving a sequence of requests presented in a real-time on-line fashion located at points of a metric space by servers (salesmen/vehicles/robots). In this paper, motivated from real-world applications, such as Uber/Lyft rides, where some limited knowledge is available on the future requests, we propose the {\em spatial locality} model that provides in advance the distance within which new request(s) will be released from the current position of server(s). We study the usefulness of this advanced information on achieving the improved competitive ratios for both the problems with $k\geq 1$ servers, compared to the competitive results established in the literature without such spatial locality consideration. We show that small locality is indeed useful in obtaining improved competitive ratios irrespective of the metric space.</p></details> | 13 pages |
| **[Spatial-Temporal Pre-Training for Embryo Viability Prediction Using Time-Lapse Videos](http://arxiv.org/abs/2506.17403v1)** | 2025-06-20 | [papers-cool](https://papers.cool/arxiv/2506.17403v1) | <details><summary>Show</summary><p>Automating embryo viability prediction for in vitro fertilization (IVF) is important but challenging due to the limited availability of labeled pregnancy outcome data, as only a small fraction of embryos are labeled after transfer. Self-supervised learning (SSL) can leverage both labeled and unlabeled data to improve prediction. However, existing SSL methods for videos are not directly applicable to embryo development videos due to two challenges: (1) embryo time-lapse videos contain hundreds of frames, requiring significant GPU memory for conventional SSL; (2) the dataset contains videos with varying lengths and many outlier frames, causing traditional video alignment methods to struggle with semantic misalignment. We propose Spatial-Temporal Pre-Training (STPT) to address these challenges. STPT includes two stages: spatial and temporal. In each stage, only one encoder is trained while the other is frozen, reducing memory demands. To handle temporal misalignment, STPT avoids frame-by-frame alignment across videos. The spatial stage learns from alignments within each video and its temporally consistent augmentations. The temporal stage then models relationships between video embeddings. Our method efficiently handles long videos and temporal variability. On 23,027 time-lapse videos (3,286 labeled), STPT achieves the highest AUC of 0.635 (95% CI: 0.632-0.638) compared to baselines, with limited computational resources.</p></details> | <details><summary>Prepr...</summary><p>Preprint submitted to Medical Image Analysis</p></details> |
| **[SDDiff: Boost Radar Perception via Spatial-Doppler Diffusion](http://arxiv.org/abs/2506.16936v1)** | 2025-06-20 | [papers-cool](https://papers.cool/arxiv/2506.16936v1) | <details><summary>Show</summary><p>Point cloud extraction (PCE) and ego velocity estimation (EVE) are key capabilities gaining attention in 3D radar perception. However, existing work typically treats these two tasks independently, which may neglect the interplay between radar's spatial and Doppler domain features, potentially introducing additional bias. In this paper, we observe an underlying correlation between 3D points and ego velocity, which offers reciprocal benefits for PCE and EVE. To fully unlock such inspiring potential, we take the first step to design a Spatial-Doppler Diffusion (SDDiff) model for simultaneously dense PCE and accurate EVE. To seamlessly tailor it to radar perception, SDDiff improves the conventional latent diffusion process in three major aspects. First, we introduce a representation that embodies both spatial occupancy and Doppler features. Second, we design a directional diffusion with radar priors to streamline the sampling. Third, we propose Iterative Doppler Refinement to enhance the model's adaptability to density variations and ghosting effects. Extensive evaluations show that SDDiff significantly outperforms state-of-the-art baselines by achieving 59% higher in EVE accuracy, 4X greater in valid generation density while boosting PCE effectiveness and reliability.</p></details> |  |
| **[LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning?](http://arxiv.org/abs/2503.19990v3)** | 2025-06-20 | [papers-cool](https://papers.cool/arxiv/2503.19990v3) | <details><summary>Show</summary><p>Multi-step spatial reasoning entails understanding and reasoning about spatial relationships across multiple sequential steps, which is crucial for tackling complex real-world applications, such as robotic manipulation, autonomous navigation, and automated assembly. To assess how well current Multimodal Large Language Models (MLLMs) have acquired this fundamental capability, we introduce LEGO-Puzzles, a scalable benchmark designed to evaluate both spatial understanding and sequential reasoning in MLLMs through LEGO-based tasks. LEGO-Puzzles consists of 1,100 carefully curated visual question-answering (VQA) samples spanning 11 distinct tasks, ranging from basic spatial understanding to complex multi-step reasoning. Based on LEGO-Puzzles, we conduct a comprehensive evaluation of 20 state-of-the-art MLLMs and uncover significant limitations in their spatial reasoning capabilities: even the most powerful MLLMs can answer only about half of the test cases, whereas human participants achieve over 90% accuracy. Furthermore, based on LEGO-Puzzles, we design generation tasks to investigate whether MLLMs can transfer their spatial understanding and reasoning abilities to image generation. Our experiments show that only GPT-4o and Gemini-2.0-Flash exhibit a limited ability to follow these instructions, while other MLLMs either replicate the input image or generate completely irrelevant outputs. Overall, LEGO-Puzzles exposes critical deficiencies in existing MLLMs' spatial understanding and sequential reasoning capabilities, and underscores the need for further advancements in multimodal spatial reasoning.</p></details> | 11 pages, 3 figures |
| **[Exploring the effect of spatial scales in studying urban mobility pattern](http://arxiv.org/abs/2506.16762v1)** | 2025-06-20 | [papers-cool](https://papers.cool/arxiv/2506.16762v1) | <details><summary>Show</summary><p>Urban mobility plays a crucial role in the functioning of cities, influencing economic activity, accessibility, and quality of life. However, the effectiveness of analytical models in understanding urban mobility patterns can be significantly affected by the spatial scales employed in the analysis. This paper explores the impact of spatial scales on the performance of the gravity model in explaining urban mobility patterns using public transport flow data in Singapore. The model is evaluated across multiple spatial scales of origin and destination locations, ranging from individual bus stops and train stations to broader regional aggregations. Results indicate the existence of an optimal intermediate spatial scale at which the gravity model performs best. At the finest scale, where individual transport nodes are considered, the model exhibits poor performance due to noisy and highly variable travel patterns. Conversely, at larger scales, model performance also suffers as over-aggregation of transport nodes results in excessive generalisation which obscures the underlying mobility dynamics. Furthermore, distance-based spatial aggregation of transport nodes proves to outperform administrative boundary-based aggregation, suggesting that actual urban organisation and movement patterns may not necessarily align with imposed administrative divisions. These insights highlight the importance of selecting appropriate spatial scales in mobility analysis and urban modelling in general, offering valuable guidance for urban and transport planning efforts aimed at enhancing mobility in complex urban environments.</p></details> | <details><summary>in th...</summary><p>in the proceedings of the International Conference on Computational Science ICCS 2025, and the Lecture Notes in Computer Science (LNCS) series</p></details> |
| **[Spatially-Aware Evaluation of Segmentation Uncertainty](http://arxiv.org/abs/2506.16589v1)** | 2025-06-19 | [papers-cool](https://papers.cool/arxiv/2506.16589v1) | <details><summary>Show</summary><p>Uncertainty maps highlight unreliable regions in segmentation predictions. However, most uncertainty evaluation metrics treat voxels independently, ignoring spatial context and anatomical structure. As a result, they may assign identical scores to qualitatively distinct patterns (e.g., scattered vs. boundary-aligned uncertainty). We propose three spatially aware metrics that incorporate structural and boundary information and conduct a thorough validation on medical imaging data from the prostate zonal segmentation challenge within the Medical Segmentation Decathlon. Our results demonstrate improved alignment with clinically important factors and better discrimination between meaningful and spurious uncertainty patterns.</p></details> | <details><summary>Prese...</summary><p>Presented at the 4th Workshop on Uncertainty Quantification for Computer Vision (CVPR 2025), June 11, 2025. This version is not included in the official proceedings</p></details> |
| **[Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention](http://arxiv.org/abs/2403.10173v4)** | 2025-06-19 | [papers-cool](https://papers.cool/arxiv/2403.10173v4) | <details><summary>Show</summary><p>Event cameras offer high temporal resolution and dynamic range with minimal motion blur, making them promising for robust object detection. While Spiking Neural Networks (SNNs) on neuromorphic hardware are often considered for energy-efficient and low latency event-based data processing, they often fall short of Artificial Neural Networks (ANNs) in accuracy and flexibility. Here, we introduce Attention-based Hybrid SNN-ANN backbones for event-based object detection to leverage the strengths of both SNN and ANN architectures. A novel Attention-based SNN-ANN bridge module captures sparse spatial and temporal relations from the SNN layer and converts them into dense feature maps for the ANN part of the backbone. Additionally, we present a variant that integrates DWConvL-STMs to the ANN blocks to capture slower dynamics. This multi-timescale network combines fast SNN processing for short timesteps with long-term dense RNN processing, effectively capturing both fast and slow dynamics. Experimental results demonstrate that our proposed method surpasses SNN-based approaches by significant margins, with results comparable to existing ANN and RNN-based methods. Unlike ANN-only networks, the hybrid setup allows us to implement the SNN blocks on digital neuromorphic hardware to investigate the feasibility of our approach. Extensive ablation studies and implementation on neuromorphic hardware confirm the effectiveness of our proposed modules and architectural choices. Our hybrid SNN-ANN architectures pave the way for ANN-like performance at a drastically reduced parameter, latency, and power budget.</p></details> |  |
| **[Learning Multi-scale Spatial-frequency Features for Image Denoising](http://arxiv.org/abs/2506.16307v1)** | 2025-06-19 | [papers-cool](https://papers.cool/arxiv/2506.16307v1) | <details><summary>Show</summary><p>Recent advancements in multi-scale architectures have demonstrated exceptional performance in image denoising tasks. However, existing architectures mainly depends on a fixed single-input single-output Unet architecture, ignoring the multi-scale representations of pixel level. In addition, previous methods treat the frequency domain uniformly, ignoring the different characteristics of high-frequency and low-frequency noise. In this paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for image denoising. We use image pyramid inputs to restore noise-free results from low-resolution images. In order to realize the interaction of high-frequency and low-frequency information, we design an adaptive spatial-frequency learning unit (ASFU), where a learnable mask is used to separate the information into high-frequency and low-frequency components. In the skip connections, we design a global feature fusion block to enhance the features at different scales. Extensive experiments on both synthetic and real noisy image datasets verify the effectiveness of MADNet compared with current state-of-the-art denoising approaches.</p></details> |  |
| **[Robust Maximum $L_q$-Likelihood Covariance Estimation for Replicated Spatial Data](http://arxiv.org/abs/2407.17592v2)** | 2025-06-19 | [papers-cool](https://papers.cool/arxiv/2407.17592v2) | <details><summary>Show</summary><p>Parameter estimation with the maximum $L_q$-likelihood estimator (ML$q$E) is an alternative to the maximum likelihood estimator (MLE) that considers the $q$-th power of the likelihood values for some $q<1$. In this method, extreme values are down-weighted because of their lower likelihood values, which yields robust estimates. In this work, we study the properties of the ML$q$E for spatial data with replicates. We investigate the asymptotic properties of the ML$q$E for Gaussian random fields with a Mat\'ern covariance function, and carry out simulation studies to investigate the numerical performance of the ML$q$E. We show that it can provide more robust and stable estimation results when some of the replicates in the spatial data contain outliers. In addition, we develop a mechanism to find the optimal choice of the hyper-parameter $q$ for the ML$q$E. The robustness of our approach is further verified on a United States precipitation dataset. Compared with other robust methods for spatial data, our proposal is more intuitive and easier to understand, yet it performs well when dealing with datasets containing outliers.</p></details> |  |
| **[STAR-Pose: Efficient Low-Resolution Video Human Pose Estimation via Spatial-Temporal Adaptive Super-Resolution](http://arxiv.org/abs/2506.16061v1)** | 2025-06-19 | [papers-cool](https://papers.cool/arxiv/2506.16061v1) | <details><summary>Show</summary><p>Human pose estimation in low-resolution videos presents a fundamental challenge in computer vision. Conventional methods either assume high-quality inputs or employ computationally expensive cascaded processing, which limits their deployment in resource-constrained environments. We propose STAR-Pose, a spatial-temporal adaptive super-resolution framework specifically designed for video-based human pose estimation. Our method features a novel spatial-temporal Transformer with LeakyReLU-modified linear attention, which efficiently captures long-range temporal dependencies. Moreover, it is complemented by an adaptive fusion module that integrates parallel CNN branch for local texture enhancement. We also design a pose-aware compound loss to achieve task-oriented super-resolution. This loss guides the network to reconstruct structural features that are most beneficial for keypoint localization, rather than optimizing purely for visual quality. Extensive experiments on several mainstream video HPE datasets demonstrate that STAR-Pose outperforms existing approaches. It achieves up to 5.2% mAP improvement under extremely low-resolution (64x48) conditions while delivering 2.8x to 4.4x faster inference than cascaded approaches.</p></details> | <details><summary>14pag...</summary><p>14pages 3figures, alredy submiss to PRCV 2025</p></details> |
| **[Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing](http://arxiv.org/abs/2506.09965v2)** | 2025-06-19 | [papers-cool](https://papers.cool/arxiv/2506.09965v2) | <details><summary>Show</summary><p>As textual reasoning with large language models (LLMs) has advanced significantly, there has been growing interest in enhancing the multimodal reasoning capabilities of large vision-language models (LVLMs). However, existing methods primarily approach multimodal reasoning in a straightforward, text-centric manner, where both reasoning and answer derivation are conducted purely through text, with the only difference being the presence of multimodal input. As a result, these methods often encounter fundamental limitations in spatial reasoning tasks that demand precise geometric understanding and continuous spatial tracking-capabilities that humans achieve through mental visualization and manipulation. To address the limitations, we propose drawing to reason in space, a novel paradigm that enables LVLMs to reason through elementary drawing operations in the visual space. By equipping models with basic drawing operations, including annotating bounding boxes and drawing auxiliary lines, we empower them to express and analyze spatial relationships through direct visual manipulation, meanwhile avoiding the performance ceiling imposed by specialized perception tools in previous tool-integrated reasoning approaches. To cultivate this capability, we develop a three-stage training framework: cold-start training with synthetic data to establish basic drawing abilities, reflective rejection sampling to enhance self-reflection behaviors, and reinforcement learning to directly optimize for target rewards. Extensive experiments demonstrate that our model, named VILASR, consistently outperforms existing methods across diverse spatial reasoning benchmarks, involving maze navigation, static spatial reasoning, video-based reasoning, and multi-view-based reasoning tasks, with an average improvement of 18.4%.</p></details> |  |
| **[Non-Uniform Spatial Alignment Errors in sUAS Imagery From Wide-Area Disasters](http://arxiv.org/abs/2405.06593v2)** | 2025-06-18 | [papers-cool](https://papers.cool/arxiv/2405.06593v2) | <details><summary>Show</summary><p>This work presents the first quantitative study of alignment errors between small uncrewed aerial systems (sUAS) georectified imagery and a priori building polygons and finds that alignment errors are non-uniform and irregular, which negatively impacts field robotics systems and human-robot interfaces that rely on geospatial information. There are no efforts that have considered the alignment of a priori spatial data with georectified sUAS imagery, possibly because straight-forward linear transformations often remedy any misalignment in satellite imagery. However, an attempt to develop machine learning models for an sUAS field robotics system for disaster response from nine wide-area disasters using the CRASAR-U-DROIDs dataset uncovered serious translational alignment errors. The analysis considered 21,608 building polygons in 51 orthomosaic images, covering 16787.2 Acres (26.23 square miles), and 7,880 adjustment annotations, averaging 75.36 pixels and an average intersection over union of 0.65. Further analysis found no uniformity among the angle and distance metrics of the building polygon alignments, presenting an average circular variance of 0.28 and an average distance variance of 0.45 pixels2, making it impossible to use the linear transform used to align satellite imagery. The study's primary contribution is alerting field robotics and human-robot interaction (HRI) communities to the problem of spatial alignment and that a new method will be needed to automate and communicate the alignment of spatial data in sUAS georectified imagery. This paper also contributes a description of the updated CRASAR-U-DROIDs dataset of sUAS imagery, which contains building polygons and human-curated corrections to spatial misalignment for further research in field robotics and HRI.</p></details> | 6 pages, 4 figures |
| **[A System Level Compiler for Massively-Parallel, Spatial, Dataflow Architectures](http://arxiv.org/abs/2506.15875v1)** | 2025-06-18 | [papers-cool](https://papers.cool/arxiv/2506.15875v1) | <details><summary>Show</summary><p>We have developed a novel compiler called the Multiple-Architecture Compiler for Advanced Computing Hardware (MACH) designed specifically for massively-parallel, spatial, dataflow architectures like the Wafer Scale Engine. Additionally, MACH can execute code on traditional unified-memory devices. MACH addresses the complexities in compiling for spatial architectures through a conceptual Virtual Machine, a flexible domain-specific language, and a compiler that can lower high-level languages to machine-specific code in compliance with the Virtual Machine concept. While MACH is designed to be operable on several architectures and provide the flexibility for several standard and user-defined data mappings, we introduce the concept with dense tensor examples from NumPy and show lowering to the Wafer Scale Engine by targeting Cerebras' hardware specific languages.</p></details> | <details><summary>26 pa...</summary><p>26 pages, 5 figures, 14 listings</p></details> |
| **[Baltimore Atlas: FreqWeaver Adapter for Semi-supervised Ultra-high Spatial Resolution Land Cover Classification](http://arxiv.org/abs/2506.15565v1)** | 2025-06-18 | [papers-cool](https://papers.cool/arxiv/2506.15565v1) | <details><summary>Show</summary><p>Ultra-high Spatial Resolution Land Cover Classification is essential for fine-grained land cover analysis, yet it remains challenging due to the high cost of pixel-level annotations, significant scale variation, and the limited adaptability of large-scale vision models. Existing methods typically focus on 1-meter spatial resolution imagery and rely heavily on annotated data, whereas practical applications often require processing higher-resolution imagery under weak supervision. To address this, we propose a parameter-efficient semi-supervised segmentation framework for 0.3 m spatial resolution imagery, which leverages the knowledge of SAM2 and introduces a remote sensing-specific FreqWeaver Adapter to enhance fine-grained detail modeling while maintaining a lightweight design at only 5.96% of the total model parameters. By effectively leveraging unlabeled data and maintaining minimal parameter overhead, the proposed method delivers robust segmentation results with superior structural consistency, achieving a 1.78% improvement over existing parameter-efficient tuning strategies and a 3.44% gain compared to state-of-the-art high-resolution remote sensing segmentation approaches.</p></details> |  |
| **[Sonic4D: Spatial Audio Generation for Immersive 4D Scene Exploration](http://arxiv.org/abs/2506.15759v1)** | 2025-06-18 | [papers-cool](https://papers.cool/arxiv/2506.15759v1) | <details><summary>Show</summary><p>Recent advancements in 4D generation have demonstrated its remarkable capability in synthesizing photorealistic renderings of dynamic 3D scenes. However, despite achieving impressive visual performance, almost all existing methods overlook the generation of spatial audio aligned with the corresponding 4D scenes, posing a significant limitation to truly immersive audiovisual experiences. To mitigate this issue, we propose Sonic4D, a novel framework that enables spatial audio generation for immersive exploration of 4D scenes. Specifically, our method is composed of three stages: 1) To capture both the dynamic visual content and raw auditory information from a monocular video, we first employ pre-trained expert models to generate the 4D scene and its corresponding monaural audio. 2) Subsequently, to transform the monaural audio into spatial audio, we localize and track the sound sources within the 4D scene, where their 3D spatial coordinates at different timestamps are estimated via a pixel-level visual grounding strategy. 3) Based on the estimated sound source locations, we further synthesize plausible spatial audio that varies across different viewpoints and timestamps using physics-based simulation. Extensive experiments have demonstrated that our proposed method generates realistic spatial audio consistent with the synthesized 4D scene in a training-free manner, significantly enhancing the immersive experience for users. Generated audio and video examples are available at https://x-drunker.github.io/Sonic4D-project-page.</p></details> | <details><summary>17 pa...</summary><p>17 pages, 7 figures. Project page: https://x-drunker.github.io/Sonic4D-project-page/</p></details> |
| **[Spatial Context-based Self-Supervised Learning for Handwritten Text Recognition](http://arxiv.org/abs/2404.11585v3)** | 2025-06-18 | [papers-cool](https://papers.cool/arxiv/2404.11585v3) | <details><summary>Show</summary><p>Handwritten Text Recognition (HTR) is a relevant problem in computer vision, and implies unique challenges owing to its inherent variability and the rich contextualization required for its interpretation. Despite the success of Self-Supervised Learning (SSL) in computer vision, its application to HTR has been rather scattered, leaving key SSL methodologies unexplored. This work focuses on one of them, namely Spatial Context-based SSL. We investigate how this family of approaches can be adapted and optimized for HTR and propose new workflows that leverage the unique features of handwritten text. Our experiments demonstrate that the methods considered lead to advancements in the state-of-the-art of SSL for HTR in a number of benchmark cases.</p></details> | <details><summary>Publi...</summary><p>Published at Pattern Recognition Letters (PRL)</p></details> |
| **[EVA-S2PMLP: Secure and Scalable Two-Party MLP via Spatial Transformation](http://arxiv.org/abs/2506.15102v1)** | 2025-06-18 | [papers-cool](https://papers.cool/arxiv/2506.15102v1) | <details><summary>Show</summary><p>Privacy-preserving neural network training in vertically partitioned scenarios is vital for secure collaborative modeling across institutions. This paper presents \textbf{EVA-S2PMLP}, an Efficient, Verifiable, and Accurate Secure Two-Party Multi-Layer Perceptron framework that introduces spatial-scale optimization for enhanced privacy and performance. To enable reliable computation under real-number domain, EVA-S2PMLP proposes a secure transformation pipeline that maps scalar inputs to vector and matrix spaces while preserving correctness. The framework includes a suite of atomic protocols for linear and non-linear secure computations, with modular support for secure activation, matrix-vector operations, and loss evaluation. Theoretical analysis confirms the reliability, security, and asymptotic complexity of each protocol. Extensive experiments show that EVA-S2PMLP achieves high inference accuracy and significantly reduced communication overhead, with up to $12.3\times$ improvement over baselines. Evaluation on benchmark datasets demonstrates that the framework maintains model utility while ensuring strict data confidentiality, making it a practical solution for privacy-preserving neural network training in finance, healthcare, and cross-organizational AI applications.</p></details> |  |
| **[SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks](http://arxiv.org/abs/2506.14512v1)** | 2025-06-17 | [papers-cool](https://papers.cool/arxiv/2506.14512v1) | <details><summary>Show</summary><p>Large Language Models (LLMs) are experiencing rapid advancements in complex reasoning, exhibiting remarkable generalization in mathematics and programming. In contrast, while spatial intelligence is fundamental for Vision-Language Models (VLMs) in real-world interaction, the systematic evaluation of their complex reasoning ability within spatial contexts remains underexplored. To bridge this gap, we introduce SIRI-Bench, a benchmark designed to evaluate VLMs' spatial intelligence through video-based reasoning tasks. SIRI-Bench comprises nearly 1K video-question-answer triplets, where each problem is embedded in a realistic 3D scene and captured by video. By carefully designing questions and corresponding 3D scenes, our benchmark ensures that solving the questions requires both spatial comprehension for extracting information and high-level reasoning for deriving solutions, making it a challenging benchmark for evaluating VLMs. To facilitate large-scale data synthesis, we develop an Automatic Scene Creation Engine. This engine, leveraging multiple specialized LLM agents, can generate realistic 3D scenes from abstract math problems, ensuring faithfulness to the original descriptions. Experimental results reveal that state-of-the-art VLMs struggle significantly on SIRI-Bench, underscoring the challenge of spatial reasoning. We hope that our study will bring researchers' attention to spatially grounded reasoning and advance VLMs in visual problem-solving.</p></details> | 16 pages, 9 figures |
| **[EVA02-AT: Egocentric Video-Language Understanding with Spatial-Temporal Rotary Positional Embeddings and Symmetric Optimization](http://arxiv.org/abs/2506.14356v1)** | 2025-06-17 | [papers-cool](https://papers.cool/arxiv/2506.14356v1) | <details><summary>Show</summary><p>Egocentric video-language understanding demands both high efficiency and accurate spatial-temporal modeling. Existing approaches face three key challenges: 1) Excessive pre-training cost arising from multi-stage pre-training pipelines, 2) Ineffective spatial-temporal encoding due to manually split 3D rotary positional embeddings that hinder feature interactions, and 3) Imprecise learning objectives in soft-label multi-instance retrieval, which neglect negative pair correlations. In this paper, we introduce EVA02-AT, a suite of EVA02-based video-language foundation models tailored to egocentric video understanding tasks. EVA02-AT first efficiently transfers an image-based CLIP model into a unified video encoder via a single-stage pretraining. Second, instead of applying rotary positional embeddings to isolated dimensions, we introduce spatial-temporal rotary positional embeddings along with joint attention, which can effectively encode both spatial and temporal information on the entire hidden dimension. This joint encoding of spatial-temporal features enables the model to learn cross-axis relationships, which are crucial for accurately modeling motion and interaction in videos. Third, focusing on multi-instance video-language retrieval tasks, we introduce the Symmetric Multi-Similarity (SMS) loss and a novel training framework that advances all soft labels for both positive and negative pairs, providing a more precise learning objective. Extensive experiments on Ego4D, EPIC-Kitchens-100, and Charades-Ego under zero-shot and fine-tuning settings demonstrate that EVA02-AT achieves state-of-the-art performance across diverse egocentric video-language tasks with fewer parameters. Models with our SMS loss also show significant performance gains on multi-instance retrieval benchmarks. Our code and models are publicly available at https://github.com/xqwang14/EVA02-AT .</p></details> |  |
| **[Learning Spatially Adaptive $\ell_1$-Norms Weights for Convolutional Synthesis Regularization](http://arxiv.org/abs/2503.09483v3)** | 2025-06-17 | [papers-cool](https://papers.cool/arxiv/2503.09483v3) | <details><summary>Show</summary><p>We propose an unrolled algorithm approach for learning spatially adaptive parameter maps in the framework of convolutional synthesis-based $\ell_1$ regularization. More precisely, we consider a family of pre-trained convolutional filters and estimate deeply parametrized spatially varying parameters applied to the sparse feature maps by means of unrolling a FISTA algorithm to solve the underlying sparse estimation problem. The proposed approach is evaluated for image reconstruction of low-field MRI and compared to spatially adaptive and non-adaptive analysis-type procedures relying on Total Variation regularization and to a well-established model-based deep learning approach. We show that the proposed approach produces visually and quantitatively comparable results with the latter approaches and at the same time remains highly interpretable. In particular, the inferred parameter maps quantify the local contribution of each filter in the reconstruction, which provides valuable insight into the algorithm mechanism and could potentially be used to discard unsuited filters.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in the proceedings of the EUSIPCO 2025 conference</p></details> |
| **[Querying functional and structural niches on spatial transcriptomics data](http://arxiv.org/abs/2410.10652v2)** | 2025-06-17 | [papers-cool](https://papers.cool/arxiv/2410.10652v2) | <details><summary>Show</summary><p>Cells in multicellular organisms coordinate to form functional and structural niches. With spatial transcriptomics enabling gene expression profiling in spatial contexts, it has been revealed that spatial niches serve as cohesive and recurrent units in physiological and pathological processes. These observations suggest universal tissue organization principles encoded by conserved niche patterns, and call for a query-based niche analytical paradigm beyond current computational tools. In this work, we defined the Niche Query Task, which is to identify similar niches across ST samples given a niche of interest (NOI). We further developed QueST, a specialized method for solving this task. QueST models each niche as a subgraph, uses contrastive learning to learn discriminative niche embeddings, and incorporates adversarial training to mitigate batch effects. In simulations and benchmark datasets, QueST outperformed existing methods repurposed for niche querying, accurately capturing niche structures in heterogeneous environments and demonstrating strong generalizability across diverse sequencing platforms. Applied to tertiary lymphoid structures in renal and lung cancers, QueST revealed functionally distinct niches associated with patient prognosis and uncovered conserved and divergent spatial architectures across cancer types. These results demonstrate that QueST enables systematic, quantitative profiling of spatial niches across samples, providing a powerful tool to dissect spatial tissue architecture in health and disease.</p></details> |  |
| **[Hierarchical Multi-Agent Reinforcement Learning-based Coordinated Spatial Reuse for Next Generation WLANs](http://arxiv.org/abs/2506.14187v1)** | 2025-06-17 | [papers-cool](https://papers.cool/arxiv/2506.14187v1) | <details><summary>Show</summary><p>High-density Wi-Fi deployments often result in significant co-channel interference, which degrades overall network performance. To address this issue, coordination of multi access points (APs) has been considered to enable coordinated spatial reuse (CSR) in next generation wireless local area networks. This paper tackles the challenge of downlink spatial reuse in Wi-Fi networks, specifically in scenarios involving overlapping basic service sets, by employing hierarchical multi-agent reinforcement learning (HMARL). We decompose the CSR process into two phases, i.e., a polling phase and a decision phase, and introduce the HMARL algorithm to enable efficient CSR. To enhance training efficiency, the proposed HMARL algorithm employs a hierarchical structure, where station selection and power control are determined by a high- and low-level policy network, respectively. Simulation results demonstrate that this approach consistently outperforms baseline methods in terms of throughput and latency across various network topologies. Moreover, the algorithm exhibits robust performance when coexisting with legacy APs. Additional experiments in a representative topology further reveal that the carefully designed reward function not only maximizes the overall network throughput, but also improves fairness in transmission opportunities for APs in high-interference regions.</p></details> |  |
| **[A Robust Nonparametric Framework for Detecting Repeated Spatial Patterns](http://arxiv.org/abs/2506.14103v1)** | 2025-06-17 | [papers-cool](https://papers.cool/arxiv/2506.14103v1) | <details><summary>Show</summary><p>Identifying spatially contiguous clusters and repeated spatial patterns (RSP) characterized by similar underlying distributions that are spatially apart is a key challenge in modern spatial statistics. Existing constrained clustering methods enforce spatial contiguity but are limited in their ability to identify RSP. We propose a novel nonparametric framework that addresses this limitation by combining constrained clustering with a post-clustering reassigment step based on the maximum mean discrepancy (MMD) statistic. We employ a block permutation strategy within each cluster that preserves local attribute structure when approximating the null distribution of the MMD. We also show that the MMD$^2$ statistic is asymptotically consistent under second-order stationarity and spatial mixing conditions. This two-stage approach enables the detection of clusters that are both spatially distant and similar in distribution. Through simulation studies that vary spatial dependence, cluster sizes, shapes, and multivariate dimensionality, we demonstrate the robustness of our proposed framework in detecting RSP. We further illustrate its applicability through an analysis of spatial proteomics data from patients with triple-negative breast cancer. Overall, our framework presents a methodological advancement in spatial clustering, offering a flexible and robust solution for spatial datasets that exhibit repeated patterns.</p></details> | <details><summary>39 pa...</summary><p>39 pages including an Appendix of 17 pages, 39 figures</p></details> |
| **[Into the Unknown: Applying Inductive Spatial-Semantic Location Embeddings for Predicting Individuals' Mobility Beyond Visited Places](http://arxiv.org/abs/2506.14070v1)** | 2025-06-17 | [papers-cool](https://papers.cool/arxiv/2506.14070v1) | <details><summary>Show</summary><p>Predicting individuals' next locations is a core task in human mobility modelling, with wide-ranging implications for urban planning, transportation, public policy and personalised mobility services. Traditional approaches largely depend on location embeddings learned from historical mobility patterns, limiting their ability to encode explicit spatial information, integrate rich urban semantic context, and accommodate previously unseen locations. To address these challenges, we explore the application of CaLLiPer -- a multimodal representation learning framework that fuses spatial coordinates and semantic features of points of interest through contrastive learning -- for location embedding in individual mobility prediction. CaLLiPer's embeddings are spatially explicit, semantically enriched, and inductive by design, enabling robust prediction performance even in scenarios involving emerging locations. Through extensive experiments on four public mobility datasets under both conventional and inductive settings, we demonstrate that CaLLiPer consistently outperforms strong baselines, particularly excelling in inductive scenarios. Our findings highlight the potential of multimodal, inductive location embeddings to advance the capabilities of human mobility prediction systems. We also release the code and data (https://github.com/xlwang233/Into-the-Unknown) to foster reproducibility and future research.</p></details> | 10 pages, 5 figures |
| **[HierVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment](http://arxiv.org/abs/2506.13925v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13925v1) | <details><summary>Show</summary><p>Semi-supervised semantic segmentation remains challenging under severe label scarcity and domain variability. Vision-only methods often struggle to generalize, resulting in pixel misclassification between similar classes, poor generalization and boundary localization. Vision-Language Models offer robust, domain-invariant semantics but lack the spatial grounding required for dense prediction. We introduce HierVL, a unified framework that bridges this gap by integrating abstract text embeddings into a mask-transformer architecture tailored for semi-supervised segmentation. HierVL features three novel components: a Hierarchical Semantic Query Generator that filters and projects abstract class embeddings into multi-scale queries to suppress irrelevant classes and handle intra-class variability; a Cross-Modal Spatial Alignment Module that aligns semantic queries with pixel features for sharper boundaries under sparse supervision; and a Dual-Query Transformer Decoder that fuses semantic and instance-level queries to prevent instance collapse. We also introduce targeted regularization losses that maintain vision-language alignment throughout training to reinforce semantic grounding. HierVL establishes a new state-of-the-art by achieving a +4.4% mean improvement of the intersection over the union on COCO (with 232 labeled images), +3.1% on Pascal VOC (with 92 labels), +5.9% on ADE20 (with 158 labels) and +1.8% on Cityscapes (with 100 labels), demonstrating better performance under 1% supervision on four benchmark datasets. Our results show that language-guided segmentation closes the label efficiency gap and unlocks new levels of fine-grained, instance-aware generalization.</p></details> |  |
| **[Gradient Boosting for Spatial Regression Models with Autoregressive Disturbances](http://arxiv.org/abs/2506.13682v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13682v1) | <details><summary>Show</summary><p>Researchers in urban and regional studies increasingly deal with spatial data that reflects geographic location and spatial relationships. As a framework for dealing with the unique nature of spatial data, various spatial regression models have been introduced. In this article, a novel model-based gradient boosting algorithm for spatial regression models with autoregressive disturbances is proposed. Due to the modular nature, the approach provides an alternative estimation procedure which is feasible even in high-dimensional settings where established quasi-maximum likelihood or generalized method of moments estimators do not yield unique solutions. The approach additionally enables data-driven variable and model selection in low- as well as high-dimensional settings. Since the bias-variance trade-off is also controlled in the algorithm, implicit regularization is imposed which improves prediction accuracy on out-of-sample spatial data. Detailed simulation studies regarding the performance of estimation, prediction and variable selection in low- and high-dimensional settings confirm proper functionality of the proposed methodology. To illustrative the functionality of the model-based gradient boosting algorithm, a case study is presented where the life expectancy in German districts is modeled incorporating a potential spatial dependence structure.</p></details> |  |
| **[EUNIS Habitat Maps: Enhancing Thematic and Spatial Resolution for Europe through Machine Learning](http://arxiv.org/abs/2506.13649v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13649v1) | <details><summary>Show</summary><p>The EUNIS habitat classification is crucial for categorising European habitats, supporting European policy on nature conservation and implementing the Nature Restoration Law. To meet the growing demand for detailed and accurate habitat information, we provide spatial predictions for 260 EUNIS habitat types at hierarchical level 3, together with independent validation and uncertainty analyses. Using ensemble machine learning models, together with high-resolution satellite imagery and ecologically meaningful climatic, topographic and edaphic variables, we produced a European habitat map indicating the most probable EUNIS habitat at 100-m resolution across Europe. Additionally, we provide information on prediction uncertainty and the most probable habitats at level 3 within each EUNIS level 1 formation. This product is particularly useful for both conservation and restoration purposes. Predictions were cross-validated at European scale using a spatial block cross-validation and evaluated against independent data from France (forests only), the Netherlands and Austria. The habitat maps obtained strong predictive performances on the validation datasets with distinct trade-offs in terms of recall and precision across habitat formations.</p></details> |  |
| **[Agentic 3D Scene Generation with Spatially Contextualized VLMs](http://arxiv.org/abs/2505.20129v2)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2505.20129v2) | <details><summary>Show</summary><p>Despite recent advances in multimodal content generation enabled by vision-language models (VLMs), their ability to reason about and generate structured 3D scenes remains largely underexplored. This limitation constrains their utility in spatially grounded tasks such as embodied AI, immersive simulations, and interactive 3D applications. We introduce a new paradigm that enables VLMs to generate, understand, and edit complex 3D environments by injecting a continually evolving spatial context. Constructed from multimodal input, this context consists of three components: a scene portrait that provides a high-level semantic blueprint, a semantically labeled point cloud capturing object-level geometry, and a scene hypergraph that encodes rich spatial relationships, including unary, binary, and higher-order constraints. Together, these components provide the VLM with a structured, geometry-aware working memory that integrates its inherent multimodal reasoning capabilities with structured 3D understanding for effective spatial reasoning. Building on this foundation, we develop an agentic 3D scene generation pipeline in which the VLM iteratively reads from and updates the spatial context. The pipeline features high-quality asset generation with geometric restoration, environment setup with automatic verification, and ergonomic adjustment guided by the scene hypergraph. Experiments show that our framework can handle diverse and challenging inputs, achieving a level of generalization not observed in prior work. Further results demonstrate that injecting spatial context enables VLMs to perform downstream tasks such as interactive scene editing and path planning, suggesting strong potential for spatially intelligent systems in computer graphics, 3D vision, and embodied applications. Project page: https://spatctxvlm.github.io/project_page/.</p></details> | <details><summary>Proje...</summary><p>Project page: https://spatctxvlm.github.io/project_page/</p></details> |
| **[SA-LUT: Spatial Adaptive 4D Look-Up Table for Photorealistic Style Transfer](http://arxiv.org/abs/2506.13465v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13465v1) | <details><summary>Show</summary><p>Photorealistic style transfer (PST) enables real-world color grading by adapting reference image colors while preserving content structure. Existing methods mainly follow either approaches: generation-based methods that prioritize stylistic fidelity at the cost of content integrity and efficiency, or global color transformation methods such as LUT, which preserve structure but lack local adaptability. To bridge this gap, we propose Spatial Adaptive 4D Look-Up Table (SA-LUT), combining LUT efficiency with neural network adaptability. SA-LUT features: (1) a Style-guided 4D LUT Generator that extracts multi-scale features from the style image to predict a 4D LUT, and (2) a Context Generator using content-style cross-attention to produce a context map. This context map enables spatially-adaptive adjustments, allowing our 4D LUT to apply precise color transformations while preserving structural integrity. To establish a rigorous evaluation framework for photorealistic style transfer, we introduce PST50, the first benchmark specifically designed for PST assessment. Experiments demonstrate that SA-LUT substantially outperforms state-of-the-art methods, achieving a 66.7% reduction in LPIPS score compared to 3D LUT approaches, while maintaining real-time performance at 16 FPS for video stylization. Our code and benchmark are available at https://github.com/Ry3nG/SA-LUT</p></details> |  |
| **[HSRMamba: Contextual Spatial-Spectral State Space Model for Single Image Hyperspectral Super-Resolution](http://arxiv.org/abs/2501.18500v2)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2501.18500v2) | <details><summary>Show</summary><p>Mamba has demonstrated exceptional performance in visual tasks due to its powerful global modeling capabilities and linear computational complexity, offering considerable potential in hyperspectral image super-resolution (HSISR). However, in HSISR, Mamba faces challenges as transforming images into 1D sequences neglects the spatial-spectral structural relationships between locally adjacent pixels, and its performance is highly sensitive to input order, which affects the restoration of both spatial and spectral details. In this paper, we propose HSRMamba, a contextual spatial-spectral modeling state space model for HSISR, to address these issues both locally and globally. Specifically, a local spatial-spectral partitioning mechanism is designed to establish patch-wise causal relationships among adjacent pixels in 3D features, mitigating the local forgetting issue. Furthermore, a global spectral reordering strategy based on spectral similarity is employed to enhance the causal representation of similar pixels across both spatial and spectral dimensions. Finally, experimental results demonstrate our HSRMamba outperforms the state-of-the-art methods in quantitative quality and visual results. Code is available at: https://github.com/Tomchenshi/HSRMamba.</p></details> |  |
| **[MT-PCR: A Hybrid Mamba-Transformer with Spatial Serialization for Hierarchical Point Cloud Registration](http://arxiv.org/abs/2506.13183v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13183v1) | <details><summary>Show</summary><p>Point cloud registration (PCR) is a fundamental task in 3D computer vision and robotics. Most existing learning-based PCR methods rely on Transformers, which suffer from quadratic computational complexity. This limitation restricts the resolution of point clouds that can be processed, inevitably leading to information loss. In contrast, Mamba-a recently proposed model based on state space models (SSMs)-achieves linear computational complexity while maintaining strong long-range contextual modeling capabilities. However, directly applying Mamba to PCR tasks yields suboptimal performance due to the unordered and irregular nature of point cloud data. To address this challenge, we propose MT-PCR, the first point cloud registration framework that integrates both Mamba and Transformer modules. Specifically, we serialize point cloud features using Z-order space-filling curves to enforce spatial locality, enabling Mamba to better model the geometric structure of the input. Additionally, we remove the order indicator module commonly used in Mamba-based sequence modeling, leads to improved performance in our setting. The serialized features are then processed by an optimized Mamba encoder, followed by a Transformer refinement stage. Extensive experiments on multiple benchmarks demonstrate that MT-PCR outperforms Transformer-based and concurrent state-of-the-art methods in both accuracy and efficiency, significantly reducing while GPU memory usage and FLOPs.</p></details> | 11 Pages |
| **[StgcDiff: Spatial-Temporal Graph Condition Diffusion for Sign Language Transition Generation](http://arxiv.org/abs/2506.13156v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13156v1) | <details><summary>Show</summary><p>Sign language transition generation seeks to convert discrete sign language segments into continuous sign videos by synthesizing smooth transitions. However,most existing methods merely concatenate isolated signs, resulting in poor visual coherence and semantic accuracy in the generated videos. Unlike textual languages,sign language is inherently rich in spatial-temporal cues, making it more complex to model. To address this,we propose StgcDiff, a graph-based conditional diffusion framework that generates smooth transitions between discrete signs by capturing the unique spatial-temporal dependencies of sign language. Specifically, we first train an encoder-decoder architecture to learn a structure-aware representation of spatial-temporal skeleton sequences. Next, we optimize a diffusion denoiser conditioned on the representations learned by the pre-trained encoder, which is tasked with predicting transition frames from noise. Additionally, we design the Sign-GCN module as the key component in our framework, which effectively models the spatial-temporal features. Extensive experiments conducted on the PHOENIX14T, USTC-CSL100,and USTC-SLR500 datasets demonstrate the superior performance of our method.</p></details> |  |
| **[Efficient 3D Perception on Multi-Sweep Point Cloud with Gumbel Spatial Pruning](http://arxiv.org/abs/2411.07742v5)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2411.07742v5) | <details><summary>Show</summary><p>This paper studies point cloud perception within outdoor environments. Existing methods face limitations in recognizing objects located at a distance or occluded, due to the sparse nature of outdoor point clouds. In this work, we observe a significant mitigation of this problem by accumulating multiple temporally consecutive point cloud sweeps, resulting in a remarkable improvement in perception accuracy. However, the computation cost also increases, hindering previous approaches from utilizing a large number of point cloud sweeps. To tackle this challenge, we find that a considerable portion of points in the accumulated point cloud is redundant, and discarding these points has minimal impact on perception accuracy. We introduce a simple yet effective Gumbel Spatial Pruning (GSP) layer that dynamically prunes points based on a learned end-to-end sampling. The GSP layer is decoupled from other network components and thus can be seamlessly integrated into existing point cloud network architectures. Without incurring additional computational overhead, we increase the number of point cloud sweeps from 10, a common practice, to as many as 40. Consequently, there is a significant enhancement in perception performance. For instance, in nuScenes 3D object detection and BEV map segmentation tasks, our pruning strategy improves several 3D perception baseline methods.</p></details> |  |
| **[SemanticST: Spatially Informed Semantic Graph Learning for Clustering, Integration, and Scalable Analysis of Spatial Transcriptomics](http://arxiv.org/abs/2506.11491v2)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.11491v2) | <details><summary>Show</summary><p>Spatial transcriptomics (ST) technologies enable gene expression profiling with spatial resolution, offering unprecedented insights into tissue organization and disease heterogeneity. However, current analysis methods often struggle with noisy data, limited scalability, and inadequate modelling of complex cellular relationships. We present SemanticST, a biologically informed, graph-based deep learning framework that models diverse cellular contexts through multi-semantic graph construction. SemanticST builds multiple context-specific graphs capturing spatial proximity, gene expression similarity, and tissue domain structure, and learns disentangled embeddings for each. These are fused using an attention-inspired strategy to yield a unified, biologically meaningful representation. A community-aware min-cut loss improves robustness over contrastive learning, particularly in sparse ST data. SemanticST supports mini-batch training, making it the first graph neural network scalable to large-scale datasets such as Xenium (500,000 cells). Benchmarking across four platforms (Visium, Slide-seq, Stereo-seq, Xenium) and multiple human and mouse tissues shows consistent 20 percentage gains in ARI, NMI, and trajectory fidelity over DeepST, GraphST, and IRIS. In re-analysis of breast cancer Xenium data, SemanticST revealed rare and clinically significant niches, including triple receptor-positive clusters, spatially distinct DCIS-to-IDC transition zones, and FOXC2 tumour-associated myoepithelial cells, suggesting non-canonical EMT programs with stem-like features. SemanticST thus provides a scalable, interpretable, and biologically grounded framework for spatial transcriptomics analysis, enabling robust discovery across tissue types and diseases, and paving the way for spatially resolved tissue atlases and next-generation precision medicine.</p></details> | 6 Figures |
| **[Deep Spatial Neural Net Models with Functional Predictors: Application in Large-Scale Crop Yield Prediction](http://arxiv.org/abs/2506.13017v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13017v1) | <details><summary>Show</summary><p>Accurate prediction of crop yield is critical for supporting food security, agricultural planning, and economic decision-making. However, yield forecasting remains a significant challenge due to the complex and nonlinear relationships between weather variables and crop production, as well as spatial heterogeneity across agricultural regions. We propose DSNet, a deep neural network architecture that integrates functional and scalar predictors with spatially varying coefficients and spatial random effects. The method is designed to flexibly model spatially indexed functional data, such as daily temperature curves, and their relationship to variability in the response, while accounting for spatial correlation. DSNet mitigates the curse of dimensionality through a low-rank structure inspired by the spatially varying functional index model (SVFIM). Through comprehensive simulations, we demonstrate that DSNet outperforms state-of-the-art functional regression models for spatial data, when the functional predictors exhibit complex structure and their relationship with the response varies spatially in a potentially nonstationary manner. Application to corn yield data from the U.S. Midwest demonstrates that DSNet achieves superior predictive accuracy compared to both leading machine learning approaches and parametric statistical models. These results highlight the model's robustness and its potential applicability to other weather-sensitive crops.</p></details> |  |
| **[Spatially Consistent Air-to-Ground Channel Modeling with Probabilistic LOS/NLOS Segmentation](http://arxiv.org/abs/2506.12794v1)** | 2025-06-15 | [papers-cool](https://papers.cool/arxiv/2506.12794v1) | <details><summary>Show</summary><p>In this paper, we present a spatially consistent A2G channel model based on probabilistic LOS/NLOS segmentation to parameterize the deterministic path loss and stochastic shadow fading model. Motivated by the limitations of existing Unmanned Aerial Vehicle (UAV) channel models that overlook spatial correlation, our approach reproduces LOS/NLOS transitions along ground user trajectories in urban environments. This model captures environment-specific obstructions by means of azimuth and elevation-dependent LOS probabilities without requiring a full detailed 3D representation of the surroundings. We validate our framework against a geometry-based simulator by evaluating it across various urban settings. The results demonstrate its accuracy and computational efficiency, enabling further realistic derivations of path loss and shadow fading models and thorough outage analysis.</p></details> | <details><summary>accep...</summary><p>accepted for IEEE VTC-Spring 2025 workshop on Innovations in Advanced Air Mobility and Non-Terrestrial Networks</p></details> |
| **[ECLIP: Energy-efficient and Practical Co-Location of ML Inference on Spatially Partitioned GPUs](http://arxiv.org/abs/2506.12598v1)** | 2025-06-14 | [papers-cool](https://papers.cool/arxiv/2506.12598v1) | <details><summary>Show</summary><p>As AI inference becomes mainstream, research has begun to focus on improving the energy consumption of inference servers. Inference kernels commonly underutilize a GPU's compute resources and waste power from idling components. To improve utilization and energy efficiency, multiple models can co-locate and share the GPU. However, typical GPU spatial partitioning techniques often experience significant overheads when reconfiguring spatial partitions, which can waste additional energy through repartitioning overheads or non-optimal partition configurations. In this paper, we present ECLIP, a framework to enable low-overhead energy-efficient kernel-wise resource partitioning between co-located inference kernels. ECLIP minimizes repartitioning overheads by pre-allocating pools of CU masked streams and assigns optimal CU assignments to groups of kernels through our resource allocation optimizer. Overall, ECLIP achieves an average of 13% improvement to throughput and 25% improvement to energy efficiency.</p></details> | <details><summary>Accep...</summary><p>Accepted to ISLPED 2025</p></details> |
| **[A Spatial Relationship Aware Dataset for Robotics](http://arxiv.org/abs/2506.12525v1)** | 2025-06-14 | [papers-cool](https://papers.cool/arxiv/2506.12525v1) | <details><summary>Show</summary><p>Robotic task planning in real-world environments requires not only object recognition but also a nuanced understanding of spatial relationships between objects. We present a spatial-relationship-aware dataset of nearly 1,000 robot-acquired indoor images, annotated with object attributes, positions, and detailed spatial relationships. Captured using a Boston Dynamics Spot robot and labelled with a custom annotation tool, the dataset reflects complex scenarios with similar or identical objects and intricate spatial arrangements. We benchmark six state-of-the-art scene-graph generation models on this dataset, analysing their inference speed and relational accuracy. Our results highlight significant differences in model performance and demonstrate that integrating explicit spatial relationships into foundation models, such as ChatGPT 4o, substantially improves their ability to generate executable, spatially-aware plans for robotics. The dataset and annotation tool are publicly available at https://github.com/PengPaulWang/SpatialAwareRobotDataset, supporting further research in spatial reasoning for robotics.</p></details> | <details><summary>7 pag...</summary><p>7 pages; 7 figures, 1 table</p></details> |
| **[ViSAGe: Video-to-Spatial Audio Generation](http://arxiv.org/abs/2506.12199v1)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2506.12199v1) | <details><summary>Show</summary><p>Spatial audio is essential for enhancing the immersiveness of audio-visual experiences, yet its production typically demands complex recording systems and specialized expertise. In this work, we address a novel problem of generating first-order ambisonics, a widely used spatial audio format, directly from silent videos. To support this task, we introduce YT-Ambigen, a dataset comprising 102K 5-second YouTube video clips paired with corresponding first-order ambisonics. We also propose new evaluation metrics to assess the spatial aspect of generated audio based on audio energy maps and saliency metrics. Furthermore, we present Video-to-Spatial Audio Generation (ViSAGe), an end-to-end framework that generates first-order ambisonics from silent video frames by leveraging CLIP visual features, autoregressive neural audio codec modeling with both directional and visual guidance. Experimental results demonstrate that ViSAGe produces plausible and coherent first-order ambisonics, outperforming two-stage approaches consisting of video-to-audio generation and audio spatialization. Qualitative examples further illustrate that ViSAGe generates temporally aligned high-quality spatial audio that adapts to viewpoint changes.</p></details> | <details><summary>ICLR ...</summary><p>ICLR 2025. Project page: https://jaeyeonkim99.github.io/visage/</p></details> |
| **[HandS3C: 3D Hand Mesh Reconstruction with State Space Spatial Channel Attention from RGB images](http://arxiv.org/abs/2405.01066v4)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2405.01066v4) | <details><summary>Show</summary><p>Reconstructing the hand mesh from one single RGB image is a challenging task because hands are often occluded by other objects. Most previous works attempt to explore more additional information and adopt attention mechanisms for improving 3D reconstruction performance, while it would increase computational complexity simultaneously. To achieve a performance-reserving architecture with high computational efficiency, in this work, we propose a simple but effective 3D hand mesh reconstruction network (i.e., HandS3C), which is the first time to incorporate state space model into the task of hand mesh reconstruction. In the network, we design a novel state-space spatial-channel attention module that extends the effective receptive field, extracts hand features in the spatial dimension, and enhances regional features of hands in the channel dimension. This helps to reconstruct a complete and detailed hand mesh. Extensive experiments conducted on well-known datasets facing heavy occlusions (such as FREIHAND, DEXYCB, and HO3D) demonstrate that our proposed HandS3C achieves state-of-the-art performance while maintaining a minimal parameters.</p></details> | 5 pages, 3 figures |
| **[Towards spatial computing: recent advances in multimodal natural interaction for XR headsets](http://arxiv.org/abs/2502.07598v2)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2502.07598v2) | <details><summary>Show</summary><p>With the widespread adoption of Extended Reality (XR) headsets, spatial computing technologies are gaining increasing attention. Spatial computing enables interaction with virtual elements through natural input methods such as eye tracking, hand gestures, and voice commands, thus placing natural human-computer interaction at its core. While previous surveys have reviewed conventional XR interaction techniques, recent advancements in natural interaction, particularly driven by artificial intelligence (AI) and large language models (LLMs), have introduced new paradigms and technologies. In this paper, we review research on multimodal natural interaction for wearable XR, focusing on papers published between 2022 and 2024 in six top venues: ACM CHI, UIST, IMWUT (Ubicomp), IEEE VR, ISMAR, and TVCG. We classify and analyze these studies based on application scenarios, operation types, and interaction modalities. This analysis provides a structured framework for understanding how researchers are designing advanced natural interaction techniques in XR. Based on these findings, we discuss the challenges in natural interaction techniques and suggest potential directions for future research. This review provides valuable insights for researchers aiming to design natural and efficient interaction systems for XR, ultimately contributing to the advancement of spatial computing.</p></details> | 28 pages, 10 figures |
| **[DualX-VSR: Dual Axial Spatial$\times$Temporal Transformer for Real-World Video Super-Resolution without Motion Compensation](http://arxiv.org/abs/2506.04830v2)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2506.04830v2) | <details><summary>Show</summary><p>Transformer-based models like ViViT and TimeSformer have advanced video understanding by effectively modeling spatiotemporal dependencies. Recent video generation models, such as Sora and Vidu, further highlight the power of transformers in long-range feature extraction and holistic spatiotemporal modeling. However, directly applying these models to real-world video super-resolution (VSR) is challenging, as VSR demands pixel-level precision, which can be compromised by tokenization and sequential attention mechanisms. While recent transformer-based VSR models attempt to address these issues using smaller patches and local attention, they still face limitations such as restricted receptive fields and dependence on optical flow-based alignment, which can introduce inaccuracies in real-world settings. To overcome these issues, we propose Dual Axial Spatial$\times$Temporal Transformer for Real-World Video Super-Resolution (DualX-VSR), which introduces a novel dual axial spatial$\times$temporal attention mechanism that integrates spatial and temporal information along orthogonal directions. DualX-VSR eliminates the need for motion compensation, offering a simplified structure that provides a cohesive representation of spatiotemporal information. As a result, DualX-VSR achieves high fidelity and superior performance in real-world VSR task.</p></details> | 15 pages, 9 figures |
| **[STOAT: Spatial-Temporal Probabilistic Causal Inference Network](http://arxiv.org/abs/2506.09544v2)** | 2025-06-12 | [papers-cool](https://papers.cool/arxiv/2506.09544v2) | <details><summary>Show</summary><p>Spatial-temporal causal time series (STC-TS) involve region-specific temporal observations driven by causally relevant covariates and interconnected across geographic or network-based spaces. Existing methods often model spatial and temporal dynamics independently and overlook causality-driven probabilistic forecasting, limiting their predictive power. To address this, we propose STOAT (Spatial-Temporal Probabilistic Causal Inference Network), a novel framework for probabilistic forecasting in STC-TS. The proposed method extends a causal inference approach by incorporating a spatial relation matrix that encodes interregional dependencies (e.g. proximity or connectivity), enabling spatially informed causal effect estimation. The resulting latent series are processed by deep probabilistic models to estimate the parameters of the distributions, enabling calibrated uncertainty modeling. We further explore multiple output distributions (e.g., Gaussian, Student's-$t$, Laplace) to capture region-specific variability. Experiments on COVID-19 data across six countries demonstrate that STOAT outperforms state-of-the-art probabilistic forecasting models (DeepAR, DeepVAR, Deep State Space Model, etc.) in key metrics, particularly in regions with strong spatial dependencies. By bridging causal inference and geospatial probabilistic forecasting, STOAT offers a generalizable framework for complex spatial-temporal tasks, such as epidemic management.</p></details> |  |
| **[An $O(n$)-Algorithm for the Higher-Order Kinematics and Inverse Dynamics of Serial Manipulators using Spatial Representation of Twists](http://arxiv.org/abs/2506.10686v1)** | 2025-06-12 | [papers-cool](https://papers.cool/arxiv/2506.10686v1) | <details><summary>Show</summary><p>Optimal control in general, and flatness-based control in particular, of robotic arms necessitate to compute the first and second time derivatives of the joint torques/forces required to achieve a desired motion. In view of the required computational efficiency, recursive $O(n)$-algorithms were proposed to this end. Aiming at compact yet efficient formulations, a Lie group formulation was recently proposed, making use of body-fixed and hybrid representation of twists and wrenches. In this paper a formulation is introduced using the spatial representation. The second-order inverse dynamics algorithm is accompanied by a fourth-order forward and inverse kinematics algorithm. An advantage of all Lie group formulations is that they can be parameterized in terms of vectorial quantities that are readily available. The method is demonstrated for the 7 DOF Franka Emika Panda robot.</p></details> |  |
| **[Description and Discussion on DCASE 2025 Challenge Task 4: Spatial Semantic Segmentation of Sound Scenes](http://arxiv.org/abs/2506.10676v1)** | 2025-06-12 | [papers-cool](https://papers.cool/arxiv/2506.10676v1) | <details><summary>Show</summary><p>Spatial Semantic Segmentation of Sound Scenes (S5) aims to enhance technologies for sound event detection and separation from multi-channel input signals that mix multiple sound events with spatial information. This is a fundamental basis of immersive communication. The ultimate goal is to separate sound event signals with 6 Degrees of Freedom (6DoF) information into dry sound object signals and metadata about the object type (sound event class) and representing spatial information, including direction. However, because several existing challenge tasks already provide some of the subset functions, this task for this year focuses on detecting and separating sound events from multi-channel spatial input signals. This paper outlines the S5 task setting of the Detection and Classification of Acoustic Scenes and Events (DCASE) 2025 Challenge Task 4 and the DCASE2025 Task 4 Dataset, newly recorded and curated for this task. We also report experimental results for an S5 system trained and evaluated on this dataset. The full version of this paper will be published after the challenge results are made public.</p></details> |  |
| **[Semantic-decoupled Spatial Partition Guided Point-supervised Oriented Object Detection](http://arxiv.org/abs/2506.10601v1)** | 2025-06-12 | [papers-cool](https://papers.cool/arxiv/2506.10601v1) | <details><summary>Show</summary><p>Recent remote sensing tech advancements drive imagery growth, making oriented object detection rapid development, yet hindered by labor-intensive annotation for high-density scenes. Oriented object detection with point supervision offers a cost-effective solution for densely packed scenes in remote sensing, yet existing methods suffer from inadequate sample assignment and instance confusion due to rigid rule-based designs. To address this, we propose SSP (Semantic-decoupled Spatial Partition), a unified framework that synergizes rule-driven prior injection and data-driven label purification. Specifically, SSP introduces two core innovations: 1) Pixel-level Spatial Partition-based Sample Assignment, which compactly estimates the upper and lower bounds of object scales and mines high-quality positive samples and hard negative samples through spatial partitioning of pixel maps. 2) Semantic Spatial Partition-based Box Extraction, which derives instances from spatial partitions modulated by semantic maps and reliably converts them into bounding boxes to form pseudo-labels for supervising the learning of downstream detectors. Experiments on DOTA-v1.0 and others demonstrate SSP\' s superiority: it achieves 45.78% mAP under point supervision, outperforming SOTA method PointOBB-v2 by 4.10%. Furthermore, when integrated with ORCNN and ReDet architectures, the SSP framework achieves mAP values of 47.86% and 48.50%, respectively. The code is available at https://github.com/antxinyuan/ssp.</p></details> |  |

## Time
| **Title** | **Date** | **KiMi** | **Abstract** | **Comment** |
| --- | --- | --- | --- | --- |
| **[Time-Aware Auto White Balance in Mobile Photography](http://arxiv.org/abs/2504.05623v2)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2504.05623v2) | <details><summary>Show</summary><p>Cameras rely on auto white balance (AWB) to correct undesirable color casts caused by scene illumination and the camera's spectral sensitivity. This is typically achieved using an illuminant estimator that determines the global color cast solely from the color information in the camera's raw sensor image. Mobile devices provide valuable additional metadata-such as capture timestamp and geolocation-that offers strong contextual clues to help narrow down the possible illumination solutions. This paper proposes a lightweight illuminant estimation method that incorporates such contextual metadata, along with additional capture information and image colors, into a compact model (~5K parameters), achieving promising results, matching or surpassing larger models. To validate our method, we introduce a dataset of 3,224 smartphone images with contextual metadata collected at various times of day and under diverse lighting conditions. The dataset includes ground-truth illuminant colors, determined using a color chart, and user-preferred illuminants validated through a user study, providing a comprehensive benchmark for AWB evaluation.</p></details> |  |
| **[On the Role of Context in Reading Time Prediction](http://arxiv.org/abs/2409.08160v4)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2409.08160v4) | <details><summary>Show</summary><p>We present a new perspective on how readers integrate context during real-time language comprehension. Our proposals build on surprisal theory, which posits that the processing effort of a linguistic unit (e.g., a word) is an affine function of its in-context information content. We first observe that surprisal is only one out of many potential ways that a contextual predictor can be derived from a language model. Another one is the pointwise mutual information (PMI) between a unit and its context, which turns out to yield the same predictive power as surprisal when controlling for unigram frequency. Moreover, both PMI and surprisal are correlated with frequency. This means that neither PMI nor surprisal contains information about context alone. In response to this, we propose a technique where we project surprisal onto the orthogonal complement of frequency, yielding a new contextual predictor that is uncorrelated with frequency. Our experiments show that the proportion of variance in reading times explained by context is a lot smaller when context is represented by the orthogonalized predictor. From an interpretability standpoint, this indicates that previous studies may have overstated the role that context has in predicting reading times.</p></details> | <details><summary>EMNLP...</summary><p>EMNLP 2024; preprocessing was corrected to exclude variance due to word skipping and the conclusions remain unchanged</p></details> |
| **[Benchmarking Unsupervised Strategies for Anomaly Detection in Multivariate Time Series](http://arxiv.org/abs/2506.20574v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20574v1) | <details><summary>Show</summary><p>Anomaly detection in multivariate time series is an important problem across various fields such as healthcare, financial services, manufacturing or physics detector monitoring. Accurately identifying when unexpected errors or faults occur is essential, yet challenging, due to the unknown nature of anomalies and the complex interdependencies between time series dimensions. In this paper, we investigate transformer-based approaches for time series anomaly detection, focusing on the recently proposed iTransformer architecture. Our contributions are fourfold: (i) we explore the application of the iTransformer to time series anomaly detection, and analyse the influence of key parameters such as window size, step size, and model dimensions on performance; (ii) we examine methods for extracting anomaly labels from multidimensional anomaly scores and discuss appropriate evaluation metrics for such labels; (iii) we study the impact of anomalous data present during training and assess the effectiveness of alternative loss functions in mitigating their influence; and (iv) we present a comprehensive comparison of several transformer-based models across a diverse set of datasets for time series anomaly detection.</p></details> | <details><summary>Submi...</summary><p>Submitted to VLDB 2026 conference, currently under review</p></details> |
| **[HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction](http://arxiv.org/abs/2506.20566v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20566v1) | <details><summary>Show</summary><p>Real-time human perception is crucial for effective human-robot interaction (HRI). Large vision-language models (VLMs) offer promising generalizable perceptual capabilities but often suffer from high latency, which negatively impacts user experience and limits VLM applicability in real-world scenarios. To systematically study VLM capabilities in human perception for HRI and performance-latency trade-offs, we introduce HRIBench, a visual question-answering (VQA) benchmark designed to evaluate VLMs across a diverse set of human perceptual tasks critical for HRI. HRIBench covers five key domains: (1) non-verbal cue understanding, (2) verbal instruction understanding, (3) human-robot object relationship understanding, (4) social navigation, and (5) person identification. To construct HRIBench, we collected data from real-world HRI environments to curate questions for non-verbal cue understanding, and leveraged publicly available datasets for the remaining four domains. We curated 200 VQA questions for each domain, resulting in a total of 1000 questions for HRIBench. We then conducted a comprehensive evaluation of both state-of-the-art closed-source and open-source VLMs (N=11) on HRIBench. Our results show that, despite their generalizability, current VLMs still struggle with core perceptual capabilities essential for HRI. Moreover, none of the models within our experiments demonstrated a satisfactory performance-latency trade-off suitable for real-time deployment, underscoring the need for future research on developing smaller, low-latency VLMs with improved human perception capabilities. HRIBench and our results can be found in this Github repository: https://github.com/interaction-lab/HRIBench.</p></details> | <details><summary>Accep...</summary><p>Accepted to the 19th International Symposium on Experimental Robotics (ISER 2025)</p></details> |
| **[Adversarial Reasoning at Jailbreaking Time](http://arxiv.org/abs/2502.01633v2)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2502.01633v2) | <details><summary>Show</summary><p>As large language models (LLMs) are becoming more capable and widespread, the study of their failure cases is becoming increasingly important. Recent advances in standardizing, measuring, and scaling test-time compute suggest new methodologies for optimizing models to achieve high performance on hard tasks. In this paper, we apply these advances to the task of model jailbreaking: eliciting harmful responses from aligned LLMs. We develop an adversarial reasoning approach to automatic jailbreaking that leverages a loss signal to guide the test-time compute, achieving SOTA attack success rates against many aligned LLMs, even those that aim to trade inference-time compute for adversarial robustness. Our approach introduces a new paradigm in understanding LLM vulnerabilities, laying the foundation for the development of more robust and trustworthy AI systems.</p></details> | <details><summary>Accep...</summary><p>Accepted to the 42nd International Conference on Machine Learning (ICML 2025)</p></details> |
| **[A Decomposition Method for Finite-Time Stabilization of Bilinear Systems with Applications to Parabolic and Hyperbolic Equations](http://arxiv.org/abs/2506.20492v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20492v1) | <details><summary>Show</summary><p>In this work, we address the problem of finite-time stabilization for a class of bilinear system. We propose a decomposition-based approach in which the nominal system is split into two subsystems, one of which is inherently finite-time stable without control. This allows the stabilization analysis to focus solely on the remaining subsystem. To ensure the well-posedness of the closed-loop system, we establish sufficient conditions on the system and control operators. The stabilization results are then derived using a suitable Lyapunov function and an observation condition. The effectiveness of the proposed approach is demonstrated through examples involving both parabolic and hyperbolic infinite-dimensional systems.</p></details> |  |
| **[Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations](http://arxiv.org/abs/2506.20474v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20474v1) | <details><summary>Show</summary><p>An intrinsic aspect of every conversation is the way talk-time is shared between multiple speakers. Conversations can be balanced, with each speaker claiming a similar amount of talk-time, or imbalanced when one talks disproportionately. Such overall distributions are the consequence of continuous negotiations between the speakers throughout the conversation: who should be talking at every point in time, and for how long? In this work we introduce a computational framework for quantifying both the conversation-level distribution of talk-time between speakers, as well as the lower-level dynamics that lead to it. We derive a typology of talk-time sharing dynamics structured by several intuitive axes of variation. By applying this framework to a large dataset of video-chats between strangers, we confirm that, perhaps unsurprisingly, different conversation-level distributions of talk-time are perceived differently by speakers, with balanced conversations being preferred over imbalanced ones, especially by those who end up talking less. Then we reveal that -- even when they lead to the same level of overall balance -- different types of talk-time sharing dynamics are perceived differently by the participants, highlighting the relevance of our newly introduced typology. Finally, we discuss how our framework offers new tools to designers of computer-mediated communication platforms, for both human-human and human-AI communication.</p></details> |  |
| **[MARCO: Multi-Agent Code Optimization with Real-Time Knowledge Integration for High-Performance Computing](http://arxiv.org/abs/2505.03906v3)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2505.03906v3) | <details><summary>Show</summary><p>Large language models (LLMs) have transformed software development through code generation capabilities, yet their effectiveness for high-performance computing (HPC) remains limited. HPC code requires specialized optimizations for parallelism, memory efficiency, and architecture-specific considerations that general-purpose LLMs often overlook. We present MARCO (Multi-Agent Reactive Code Optimizer), a novel framework that enhances LLM-generated code for HPC through a specialized multi-agent architecture. MARCO employs separate agents for code generation and performance evaluation, connected by a feedback loop that progressively refines optimizations. A key innovation is MARCO's web-search component that retrieves real-time optimization techniques from recent conference proceedings and research publications, bridging the knowledge gap in pre-trained LLMs. Our extensive evaluation on the LeetCode 75 problem set demonstrates that MARCO achieves a 14.6\% average runtime reduction compared to Claude 3.5 Sonnet alone, while the integration of the web-search component yields a 30.9\% performance improvement over the base MARCO system. These results highlight the potential of multi-agent systems to address the specialized requirements of high-performance code generation, offering a cost-effective alternative to domain-specific model fine-tuning.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 4 figures, 2 tables</p></details> |
| **[Exponential quadrature rules for problems with time-dependent fractional source](http://arxiv.org/abs/2501.18395v2)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2501.18395v2) | <details><summary>Show</summary><p>In this manuscript, we propose newly-derived exponential quadrature rules for stiff linear differential equations with time-dependent fractional sources in the form $h(t^r)$, with $0<r<1$ and $h$ a sufficiently smooth function. To construct the methods, the source term is interpolated at $\nu$ collocation points by a suitable non-polynomial function, yielding to time marching schemes that we call Exponential Quadrature Rules for Fractional sources (EQRF$\nu$). The error analysis is done in the framework of strongly continuous semigroups. Compared to classical exponential quadrature rules, which in our case of interest converge with order $1+r$ at most, we prove that the new methods may reach order $1+\nu r$ for proper choices of the collocation points. We also show that the proposed integrators can be written in terms of special instances of the Mittag--Leffler functions that we call fractional $\varphi$ functions. Several numerical experiments demonstrate the theoretical findings and highlight the effectiveness of the approach.</p></details> |  |
| **[The role of audio-visual integration in the time course of phonetic encoding in self-supervised speech models](http://arxiv.org/abs/2506.20361v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20361v1) | <details><summary>Show</summary><p>Human speech perception is multimodal. In natural speech, lip movements can precede corresponding voicing by a non-negligible gap of 100-300 ms, especially for specific consonants, affecting the time course of neural phonetic encoding in human listeners. However, it remains unexplored whether self-supervised learning models, which have been used to simulate audio-visual integration in humans, can capture this asynchronicity between audio and visual cues. We compared AV-HuBERT, an audio-visual model, with audio-only HuBERT, by using linear classifiers to track their phonetic decodability over time. We found that phoneme information becomes available in AV-HuBERT embeddings only about 20 ms before HuBERT, likely due to AV-HuBERT's lower temporal resolution and feature concatenation process. It suggests AV-HuBERT does not adequately capture the temporal dynamics of multimodal speech perception, limiting its suitability for modeling the multimodal speech perception process.</p></details> | <details><summary>Accep...</summary><p>Accepted by Interspeech 2025</p></details> |
| **[On the ability of Deep Neural Networks to Learn Granger Causality in Multi-Variate Time Series Data](http://arxiv.org/abs/2506.20347v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20347v1) | <details><summary>Show</summary><p>Granger Causality (GC) offers an elegant statistical framework to study the association between multivariate time series data. Linear Vector Autoregressive models (VAR) though have nice interpretation properties but have limited practical application due to underlying assumptions on the kind of associations that can be captured by these models. Numerous attempts have already been made in the literature that exploit the functional approximation power of Deep Neural Networks (DNNs) for the task of GC estimation. These methods however treat GC as a variable selection problem. We present a novel paradigm for approaching GC. We present this idea that GC is essentially linked with prediction and if a deep learning model is used to model the time series collectively or jointly, a well regularized model may learn the true granger causal structure from the data, given that there is enough training data. We propose to uncover the learned GC structure by comparing the model uncertainty or distribution of the residuals when the past of everything is used as compared to the one where a specific time series component is dropped from the model. We also compare the effect of input layer dropout on the ability of a neural network to learn granger causality from the data. We show that a well regularized model infact can learn the true GC structure from the data without explicitly adding terms in the loss function that guide the model to select variables or perform sparse regression.</p></details> |  |
| **[Near Time-Optimal Hybrid Motion Planning for Timber Cranes](http://arxiv.org/abs/2506.20314v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20314v1) | <details><summary>Show</summary><p>Efficient, collision-free motion planning is essential for automating large-scale manipulators like timber cranes. They come with unique challenges such as hydraulic actuation constraints and passive joints-factors that are seldom addressed by current motion planning methods. This paper introduces a novel approach for time-optimal, collision-free hybrid motion planning for a hydraulically actuated timber crane with passive joints. We enhance the via-point-based stochastic trajectory optimization (VP-STO) algorithm to include pump flow rate constraints and develop a novel collision cost formulation to improve robustness. The effectiveness of the enhanced VP-STO as an optimal single-query global planner is validated by comparison with an informed RRT* algorithm using a time-optimal path parameterization (TOPP). The overall hybrid motion planning is formed by combination with a gradient-based local planner that is designed to follow the global planner's reference and to systematically consider the passive joint dynamics for both collision avoidance and sway damping.</p></details> | <details><summary>Accep...</summary><p>Accepted at ICRA 2025</p></details> |
| **[Real-Time Obstacle Avoidance Algorithms for Unmanned Aerial and Ground Vehicles](http://arxiv.org/abs/2506.20311v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20311v1) | <details><summary>Show</summary><p>The growing use of mobile robots in sectors such as automotive, agriculture, and rescue operations reflects progress in robotics and autonomy. In unmanned aerial vehicles (UAVs), most research emphasizes visual SLAM, sensor fusion, and path planning. However, applying UAVs to search and rescue missions in disaster zones remains underexplored, especially for autonomous navigation. This report develops methods for real-time and secure UAV maneuvering in complex 3D environments, crucial during forest fires. Building upon past research, it focuses on designing navigation algorithms for unfamiliar and hazardous environments, aiming to improve rescue efficiency and safety through UAV-based early warning and rapid response. The work unfolds in phases. First, a 2D fusion navigation strategy is explored, initially for mobile robots, enabling safe movement in dynamic settings. This sets the stage for advanced features such as adaptive obstacle handling and decision-making enhancements. Next, a novel 3D reactive navigation strategy is introduced for collision-free movement in forest fire simulations, addressing the unique challenges of UAV operations in such scenarios. Finally, the report proposes a unified control approach that integrates UAVs and unmanned ground vehicles (UGVs) for coordinated rescue missions in forest environments. Each phase presents challenges, proposes control models, and validates them with mathematical and simulation-based evidence. The study offers practical value and academic insights for improving the role of UAVs in natural disaster rescue operations.</p></details> |  |
| **[Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement](http://arxiv.org/abs/2506.20254v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20254v1) | <details><summary>Show</summary><p>The complexity and diversity of surgical workflows, driven by heterogeneous operating room settings, institutional protocols, and anatomical variability, present a significant challenge in developing generalizable models for cross-institutional and cross-procedural surgical understanding. While recent surgical foundation models pretrained on large-scale vision-language data offer promising transferability, their zero-shot performance remains constrained by domain shifts, limiting their utility in unseen surgical environments. To address this, we introduce Surgical Phase Anywhere (SPA), a lightweight framework for versatile surgical workflow understanding that adapts foundation models to institutional settings with minimal annotation. SPA leverages few-shot spatial adaptation to align multi-modal embeddings with institution-specific surgical scenes and phases. It also ensures temporal consistency through diffusion modeling, which encodes task-graph priors derived from institutional procedure protocols. Finally, SPA employs dynamic test-time adaptation, exploiting the mutual agreement between multi-modal phase prediction streams to adapt the model to a given test video in a self-supervised manner, enhancing the reliability under test-time distribution shifts. SPA is a lightweight adaptation framework, allowing hospitals to rapidly customize phase recognition models by defining phases in natural language text, annotating a few images with the phase labels, and providing a task graph defining phase transitions. The experimental results show that the SPA framework achieves state-of-the-art performance in few-shot surgical phase recognition across multiple institutions and procedures, even outperforming full-shot models with 32-shot labeled data. Code is available at https://github.com/CAMMA-public/SPA</p></details> | <details><summary>Accep...</summary><p>Accepted by MICCAI 2025</p></details> |
| **[Time-series surrogates from energy consumers generated by machine learning approaches for long-term forecasting scenarios](http://arxiv.org/abs/2506.20253v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20253v1) | <details><summary>Show</summary><p>Forecasting attracts a lot of research attention in the electricity value chain. However, most studies concentrate on short-term forecasting of generation or consumption with a focus on systems and less on individual consumers. Even more neglected is the topic of long-term forecasting of individual power consumption. Here, we provide an in-depth comparative evaluation of data-driven methods for generating synthetic time series data tailored to energy consumption long-term forecasting. High-fidelity synthetic data is crucial for a wide range of applications, including state estimations in energy systems or power grid planning. In this study, we assess and compare the performance of multiple state-of-the-art but less common techniques: a hybrid Wasserstein Generative Adversarial Network (WGAN), Denoising Diffusion Probabilistic Model (DDPM), Hidden Markov Model (HMM), and Masked Autoregressive Bernstein polynomial normalizing Flows (MABF). We analyze the ability of each method to replicate the temporal dynamics, long-range dependencies, and probabilistic transitions characteristic of individual energy consumption profiles. Our comparative evaluation highlights the strengths and limitations of: WGAN, DDPM, HMM and MABF aiding in selecting the most suitable approach for state estimations and other energy-related tasks. Our generation and analysis framework aims to enhance the accuracy and reliability of synthetic power consumption data while generating data that fulfills criteria like anonymisation - preserving privacy concerns mitigating risks of specific profiling of single customers. This study utilizes an open-source dataset from households in Germany with 15min time resolution. The generated synthetic power profiles can readily be used in applications like state estimations or consumption forecasting.</p></details> |  |
| **[A Unifying Theory for Runge-Kutta-like Time Integrators: Convergence and Stability](http://arxiv.org/abs/2402.13788v3)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2402.13788v3) | <details><summary>Show</summary><p>The work deals with two major topics concerning the numerical analysis of Runge-Kutta-like (RK-like) methods, namely their stability and order of convergence. RK-like methods differ from additive RK methods in that their coefficients are allowed to depend on the solution and the step size. As a result of this, we also refer to them as non-standard additive RK (NSARK) methods. The first major part of this thesis is dedicated to providing a tool for deriving order conditions for NSARK methods. The proposed approach may yield implicit order conditions, which can be rewritten in explicit form using the NB-series of the stages. The obtained explicit order conditions can be further reduced using Gr\"obner bases computations. With the presented approach, it was possible for the first time to obtain conditions for the construction of 3rd and 4th order GeCo as well as 4th order MPRK schemes. Moreover, a new fourth order MPRK method is constructed using our theory and the order of convergence is validated numerically. The second major part is concerned with the stability of nonlinear time integrators preserving at least one linear invariant. We discuss how the given approach generalizes the notion of A-stability. We can prove that investigating the Jacobian of the generating map is sufficient to understand the stability of the nonlinear method in a neighborhood of the steady state. This approach allows for the first time the investigation of several modified Patankar. In the case of MPRK schemes, we compute a general stability function in a way that can be easily adapted to the case of PDRS. Finally, the approach from the theory of dynamical systems is used to derive a necessary condition for avoiding unrealistic oscillations of the numerical approximation.</p></details> | Doctoral thesis |
| **[FGS-SLAM: Fourier-based Gaussian Splatting for Real-time SLAM with Sparse and Dense Map Fusion](http://arxiv.org/abs/2503.01109v2)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2503.01109v2) | <details><summary>Show</summary><p>3D gaussian splatting has advanced simultaneous localization and mapping (SLAM) technology by enabling real-time positioning and the construction of high-fidelity maps. However, the uncertainty in gaussian position and initialization parameters introduces challenges, often requiring extensive iterative convergence and resulting in redundant or insufficient gaussian representations. To address this, we introduce a novel adaptive densification method based on Fourier frequency domain analysis to establish gaussian priors for rapid convergence. Additionally, we propose constructing independent and unified sparse and dense maps, where a sparse map supports efficient tracking via Generalized Iterative Closest Point (GICP) and a dense map creates high-fidelity visual representations. This is the first SLAM system leveraging frequency domain analysis to achieve high-quality gaussian mapping in real-time. Experimental results demonstrate an average frame rate of 36 FPS on Replica and TUM RGB-D datasets, achieving competitive accuracy in both localization and mapping.</p></details> |  |
| **[MS-TVNet:A Long-Term Time Series Prediction Method Based on Multi-Scale Dynamic Convolution](http://arxiv.org/abs/2506.17253v2)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.17253v2) | <details><summary>Show</summary><p>Long-term time series prediction has predominantly relied on Transformer and MLP models, while the potential of convolutional networks in this domain remains underexplored. To address this gap, we introduce a novel multi-scale time series reshape module, which effectively captures the relationships among multi-period patches and variable dependencies. Building upon this module, we propose MS-TVNet, a multi-scale 3D dynamic convolutional neural network. Through comprehensive evaluations on diverse datasets, MS-TVNet demonstrates superior performance compared to baseline models, achieving state-of-the-art (SOTA) results in long-term time series prediction. Our findings highlight the effectiveness of leveraging convolutional networks for capturing complex temporal patterns, suggesting a promising direction for future research in this field.The code is realsed on https://github.com/Curyyfaust/TVNet.</p></details> |  |
| **[SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs](http://arxiv.org/abs/2506.20167v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20167v1) | <details><summary>Show</summary><p>Multivariate time series forecasting requires models to simultaneously capture variable-wise structural dependencies and generalize across diverse tasks. While structural encoders are effective in modeling feature interactions, they lack the capacity to support semantic-level reasoning or task adaptation. Conversely, large language models (LLMs) possess strong generalization capabilities but remain incompatible with raw time series inputs. This gap limits the development of unified, transferable prediction systems. Therefore, we introduce SEED, a structural encoder for embedding-driven decoding, which integrates four stages: a token-aware encoder for patch extraction, a projection module that aligns patches with language model embeddings, a semantic reprogramming mechanism that maps patches to task-aware prototypes, and a frozen language model for prediction. This modular architecture decouples representation learning from inference, enabling efficient alignment between numerical patterns and semantic reasoning. Empirical results demonstrate that the proposed method achieves consistent improvements over strong baselines, and comparative studies on various datasets confirm SEED's role in addressing the structural-semantic modeling gap.</p></details> |  |
| **[Irec: A Metacognitive Scaffolding for Self-Regulated Learning through Just-in-Time Insight Recall: A Conceptual Framework and System Prototype](http://arxiv.org/abs/2506.20156v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20156v1) | <details><summary>Show</summary><p>The core challenge in learning has shifted from knowledge acquisition to effective Self-Regulated Learning (SRL): planning, monitoring, and reflecting on one's learning. Existing digital tools, however, inadequately support metacognitive reflection. Spaced Repetition Systems (SRS) use de-contextualized review, overlooking the role of context, while Personal Knowledge Management (PKM) tools require high manual maintenance. To address these challenges, this paper introduces "Insight Recall," a novel paradigm that conceptualizes the context-triggered retrieval of personal past insights as a metacognitive scaffold to promote SRL. We formalize this paradigm using the Just-in-Time Adaptive Intervention (JITAI) framework and implement a prototype system, Irec, to demonstrate its feasibility. At its core, Irec uses a dynamic knowledge graph of the user's learning history. When a user faces a new problem, a hybrid retrieval engine recalls relevant personal "insights." Subsequently, a large language model (LLM) performs a deep similarity assessment to filter and present the most relevant scaffold in a just-in-time manner. To reduce cognitive load, Irec features a human-in-the-loop pipeline for LLM-based knowledge graph construction. We also propose an optional "Guided Inquiry" module, where users can engage in a Socratic dialogue with an expert LLM, using the current problem and recalled insights as context. The contribution of this paper is a solid theoretical framework and a usable system platform for designing next-generation intelligent learning systems that enhance metacognition and self-regulation.</p></details> | <details><summary>Versi...</summary><p>Version 1 of a work in progress. Finalized system flowcharts, a public GitHub repository with the source code, and a full reproducibility package detailing the prompts, models, and testing guidelines will be provided in v2</p></details> |
| **[TSPulse: Dual Space Tiny Pre-Trained Models for Rapid Time-Series Analysis](http://arxiv.org/abs/2505.13033v2)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2505.13033v2) | <details><summary>Show</summary><p>The rise of time-series pre-trained models has advanced temporal representation learning, but current state-of-the-art models are often large-scale, requiring substantial compute. We introduce TSPulse, ultra-compact time-series pre-trained models with only 1M parameters, specialized to perform strongly across classification, anomaly detection, imputation, and retrieval tasks. TSPulse introduces innovations at both the architecture and task levels. At the architecture level, it employs a dual-space masked reconstruction, learning from both time and frequency domains to capture complementary signals. This is further enhanced by a dual-embedding disentanglement, generating both detailed embeddings for fine-grained analysis and high-level semantic embeddings for broader task understanding. Notably, TSPulse's semantic embeddings are robust to shifts in time, magnitude, and noise, which is important for robust retrieval. At the task level, TSPulse incorporates TSLens, a fine-tuning component enabling task-specific feature attention. It also introduces a multi-head triangulation technique that correlates deviations from multiple prediction heads, enhancing anomaly detection by fusing complementary model outputs. Additionally, a hybrid mask pretraining is proposed to improves zero-shot imputation by reducing pre-training bias. These architecture and task innovations collectively contribute to TSPulse's significant performance gains: 5-16% on the UEA classification benchmarks, +20% on the TSB-AD anomaly detection leaderboard, +50% in zero-shot imputation, and +25% in time-series retrieval. Remarkably, these results are achieved with just 1M parameters (10-100X smaller than existing SOTA models) and allow GPU-free inference, setting a new standard for efficient time-series pre-trained models. The models can be accessed from https://huggingface.co/ibm-granite/granite-timeseries-tspulse-r1</p></details> |  |
| **[ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](http://arxiv.org/abs/2506.20093v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20093v1) | <details><summary>Show</summary><p>Time-series data are critical in diverse applications, such as industrial monitoring, medical diagnostics, and climate research. However, effectively integrating these high-dimensional temporal signals with natural language for dynamic, interactive tasks remains a significant challenge. To address this, we introduce the Time-Series Question Answering (Time-Series QA) task and release EngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset designed to capture complex interactions between time-series signals and natural language. Building on this resource, we propose the Instruct Time Transformer (ITFormer), a novel framework that bridges time-series encoders with frozen large language models (LLMs). ITFormer effectively extracts, aligns, and fuses temporal and textual features, achieving a strong improvement in QA accuracy over strong baselines with fewer than 1\% additional trainable parameters. By combining computational efficiency with robust cross-modal modeling, our work establishes a adaptable paradigm for integrating temporal data with natural language, paving the way for new research and applications in multi-modal AI. More details about the project, including datasets and code, are available at: https://pandalin98.github.io/itformer_site/</p></details> |  |
| **[The Contiguous Art Gallery Problem is Solvable in Polynomial Time](http://arxiv.org/abs/2412.13938v2)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2412.13938v2) | <details><summary>Show</summary><p>In this paper, we study the Contiguous Art Gallery Problem, introduced by Thomas C. Shermer at the 2024 Canadian Conference on Computational Geometry, a variant of the classical art gallery problem from 1973 by Victor Klee. In the contiguous variant, the input is a simple polygon $P$, and the goal is to partition the boundary into a minimum number of polygonal chains such that each chain is visible to a guard. We present a polynomial-time real RAM algorithm, which solves the contiguous art gallery problem. Our algorithm is simple and practical, and we make a C++ implementation available. In contrast, many variations of the art gallery problem are at least NP-hard, making the contiguous variant stand out. These include the edge-covering problem, proven NP-hard by Laurentini [The Visual Computer 1999], and the classical art gallery problem, recently shown $\exists\mathbb{R}$-complete by Abrahamsen, Adamaszek, and Miltzow [J. ACM 2022]. Our algorithm is a greedy algorithm that repeatedly traverses the polygon's boundary. To find an optimal solution, we show that it is sufficient to traverse the polygon polynomially many times, resulting in a runtime of $\mathcal{O}\!\left( n^7 \log n \right)$. Additionally, we provide algorithms for the restricted settings, where either the endpoints of the polygonal chains or the guards must coincide with the vertices of the polygon.</p></details> |  |
| **[Causal mediation analysis for longitudinal and survival data in continuous time using Bayesian non-parametric joint models](http://arxiv.org/abs/2506.20058v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.20058v1) | <details><summary>Show</summary><p>Observational cohort data is an important source of information for understanding the causal effects of treatments on survival and the degree to which these effects are mediated through changes in disease-related risk factors. However, these analyses are often complicated by irregular data collection intervals and the presence of longitudinal confounders and mediators. We propose a causal mediation framework that jointly models longitudinal exposures, confounders, mediators, and time-to-event outcomes as continuous functions of age. This framework for longitudinal covariate trajectories enables statistical inference even at ages where the subject's covariate measurements are unavailable. The observed data distribution in our framework is modeled using an enriched Dirichlet process mixture (EDPM) model. Using data from the Atherosclerosis Risk in Communities cohort study, we apply our methods to assess how medication -- prescribed to target cardiovascular disease (CVD) risk factors -- affects the time-to-CVD death.</p></details> |  |
| **[Polynomial-Time Approximation Schemes via Utility Alignment: Unit-Demand Pricing and More](http://arxiv.org/abs/2506.20030v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.20030v1) | <details><summary>Show</summary><p>This paper derives polynomial-time approximation schemes for several NP-hard stochastic optimization problems from the algorithmic mechanism design and operations research literatures. The problems we consider involve a principal or seller optimizing with respect to a subsequent choice by an agent or buyer. These include posted pricing for a unit-demand buyer with independent values (Chawla et al., 2007, Cai and Daskalakis, 2011), assortment optimization with independent utilities (Talluri and van Ryzin, 2004), and delegated choice (Khodabakhsh et al., 2024). Our results advance the state of the art for each of these problems. For unit-demand pricing with discrete distributions, our multiplicative PTAS improves on the additive PTAS of Cai and Daskalakis, and we additionally give a PTAS for the unbounded regular case, improving on the latter paper's QPTAS. For assortment optimization, no constant approximation was previously known. For delegated choice, we improve on both the $3$-approximation for the case with no outside option and the super-constant-approximation with an outside option. A key technical insight driving our results is an economically meaningful property we term utility alignment. Informally, a problem is utility aligned if, at optimality, the principal derives most of their utility from realizations where the agent's utility is also high. Utility alignment allows the algorithm designer to focus on maximizing performance on realizations with high agent utility, which is often an algorithmically simpler task. We prove utility alignment results for all the problems mentioned above, including strong results for unit-demand pricing and delegation, as well as a weaker but very broad guarantee that holds for many other problems under very mild conditions.</p></details> |  |
| **[Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models](http://arxiv.org/abs/2506.20018v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.20018v1) | <details><summary>Show</summary><p>This paper investigates real-time decision support systems that leverage low-latency AI models, bringing together recent progress in holistic AI-driven decision tools, integration with Edge-IoT technologies, and approaches for effective human-AI teamwork. It looks into how large language models can assist decision-making, especially when resources are limited. The research also examines the effects of technical developments such as DeLLMa, methods for compressing models, and improvements for analytics on edge devices, while also addressing issues like limited resources and the need for adaptable frameworks. Through a detailed review, the paper offers practical perspectives on development strategies and areas of application, adding to the field by pointing out opportunities for more efficient and flexible AI-supported systems. The conclusions set the stage for future breakthroughs in this fast-changing area, highlighting how AI can reshape real-time decision support.</p></details> |  |
| **[Tipping Point Sensitivity Analysis for Missing Data in Time-to-Event Endpoints: Model-Based and Model-Free Approaches](http://arxiv.org/abs/2506.19988v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19988v1) | <details><summary>Show</summary><p>Missing data frequently occurs in clinical trials with time-to-event endpoints, often due to administrative censoring. Other reasons, such as loss-to-follow up and patient withdrawal of consent, can violate the censoring-at-random assumption hence lead to biased estimates of the treatment effect under treatment policy estimand. Numerous methods have been proposed to conduct sensitivity analyses in these situations, one of which is the tipping point analysis. It aims to evaluate the robustness of trial conclusions by varying certain data and/or model aspects while imputing missing data. We provide an overview of the missing data considerations. The main contribution of this paper lies in categorizing and contrasting tipping point methods as two groups, namely model-based and model-free approaches, where the latter is under-emphasized in the literature. We highlight their important differences in terms of assumptions, behaviors and interpretations. Through two case studies and simulations under various scenarios, we provide insight on how different tipping point methods impact the interpretation of trial outcomes. Through these comparisons, we aim to provide a practical guide to conduct tipping point analyses from the choice of methods to ways of conducting clinical plausibility assessment, and ultimately contributing to more robust and reliable interpretation of clinical trial results in the presence of missing data for time-to-event endpoints.</p></details> |  |
| **[ScaleCap: Inference-Time Scalable Image Captioning via Dual-Modality Debiasing](http://arxiv.org/abs/2506.19848v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19848v1) | <details><summary>Show</summary><p>This paper presents ScaleCap, an inference-time scalable image captioning strategy that generates comprehensive and detailed image captions. The key challenges of high-quality image captioning lie in the inherent biases of LVLMs: multimodal bias resulting in imbalanced descriptive granularity, offering detailed accounts of some elements while merely skimming over others; linguistic bias leading to hallucinated descriptions of non-existent objects. To address these issues, we propose a scalable debiased captioning strategy, which continuously enriches and calibrates the caption with increased inference budget. Specifically, we propose two novel components: heuristic question answering and contrastive sentence rating. The former generates content-specific questions based on the image and answers them to progressively inject relevant information into the caption. The latter employs sentence-level offline contrastive decoding to effectively identify and eliminate hallucinations caused by linguistic biases. With increased inference cost, more heuristic questions are raised by ScaleCap to progressively capture additional visual details, generating captions that are more accurate, balanced, and informative. Extensive modality alignment experiments demonstrate the effectiveness of ScaleCap. Annotating 450K images with ScaleCap and using them for LVLM pretraining leads to consistent performance gains across 11 widely used benchmarks. Furthermore, ScaleCap showcases superb richness and fidelity of generated captions with two additional tasks: replacing images with captions in VQA task, and reconstructing images from captions to assess semantic coverage. Code is available at https://github.com/Cooperx521/ScaleCap.</p></details> | <details><summary>Code ...</summary><p>Code is available at https://github.com/Cooperx521/ScaleCap</p></details> |
| **[The Shape of Consumer Behavior: A Symbolic and Topological Analysis of Time Series](http://arxiv.org/abs/2506.19759v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19759v1) | <details><summary>Show</summary><p>Understanding temporal patterns in online search behavior is crucial for real-time marketing and trend forecasting. Google Trends offers a rich proxy for public interest, yet the high dimensionality and noise of its time-series data present challenges for effective clustering. This study evaluates three unsupervised clustering approaches, Symbolic Aggregate approXimation (SAX), enhanced SAX (eSAX), and Topological Data Analysis (TDA), applied to 20 Google Trends keywords representing major consumer categories. Our results show that while SAX and eSAX offer fast and interpretable clustering for stable time series, they struggle with volatility and complexity, often producing ambiguous ``catch-all'' clusters. TDA, by contrast, captures global structural features through persistent homology and achieves more balanced and meaningful groupings. We conclude with practical guidance for using symbolic and topological methods in consumer analytics and suggest that hybrid approaches combining both perspectives hold strong potential for future applications.</p></details> | 33 pages, 30 figures |
| **[Bootstrap-based tests for the total time on test and the excess wealth orders](http://arxiv.org/abs/2310.13339v2)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2310.13339v2) | <details><summary>Show</summary><p>Given a pair of non-negative random variables $X$ and $Y$, we introduce a class of nonparametric tests for the null hypothesis that $X$ dominates $Y$ in the total time on test order. Critical values are determined using bootstrap-based inference, and the tests are shown to be consistent. The same approach is used to construct tests for the excess wealth order. As a byproduct, we also obtain a class of goodness-of-fit tests for the NBUE (New Better than Used in Expectation) family of distributions.</p></details> |  |
| **[The Origami flip graph of the $2\times n$ Miura-ori](http://arxiv.org/abs/2506.19700v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19700v1) | <details><summary>Show</summary><p>Given an origami crease pattern $C=(V,E)$, a straight-line planar graph embedded in a region of $\mathbb{R}^2$, we assign each crease to be either a mountain crease (which bends convexly) or a valley crease (which bends concavely), creating a mountain-valley (MV) assignment $\mu:E\to\{-1,1\}$. An MV assignment $\mu$ is locally valid if the faces around each vertex in $C$ can be folded flat under $\mu$. In this paper, we investigate locally valid MV assignments of the Miura-ori, $M_{m,n}$, an $m\times n$ parallelogram tessellation used in numerous engineering applications. The origami flip graph $OFG(C)$ of $C$ is a graph whose vertices are locally valid MV assignments of $C$, and two vertices are adjacent if they differ by a face flip, an operation that swaps the MV-parity of every crease bordering a given face of $C$. We enumerate the number of vertices and edges in $OFG(M_{2,n})$ and prove several facts about the degrees of vertices in $OFG(M_{2,n})$. By finding recurrence relations, we show that the number of vertices of degree $d$ and $2n-a$ (for $0\leq a$) are both described by polynomials of particular degrees. We then prove that the diameter of $OFG(M_{2,n})$ is $\lceil \frac{n^2}{2}\rceil$ using techniques from 3-coloring reconfiguration graphs.</p></details> |  |
| **[Linear Time Subsequence and Supersequence Regex Matching](http://arxiv.org/abs/2504.16288v2)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2504.16288v2) | <details><summary>Show</summary><p>It is well-known that checking whether a given string $w$ matches a given regular expression $r$ can be done in quadratic time $O(|w|\cdot |r|)$ and that this cannot be improved to a truly subquadratic running time of $O((|w|\cdot |r|)^{1-\epsilon})$ assuming the strong exponential time hypothesis (SETH). We study a different matching paradigm where we ask instead whether $w$ has a subsequence that matches $r$, and show that regex matching in this sense can be solved in linear time $O(|w| + |r|)$. Further, the same holds if we ask for a supersequence. We show that the quantitative variants where we want to compute a longest or shortest subsequence or supersequence of $w$ that matches $r$ can be solved in $O(|w| \cdot |r|)$, i. e., asymptotically no worse than classical regex matching; and we show that $O(|w| + |r|)$ is conditionally not possible for these problems. We also investigate these questions with respect to other natural string relations like the infix, prefix, left-extension or extension relation instead of the subsequence and supersequence relation. We further study the complexity of the universal problem where we ask if all subsequences (or supersequences, infixes, prefixes, left-extensions or extensions) of an input string satisfy a given regular expression.</p></details> | <details><summary>31 pa...</summary><p>31 pages. Full version including all proofs</p></details> |
| **[Vision Transformer-Based Time-Series Image Reconstruction for Cloud-Filling Applications](http://arxiv.org/abs/2506.19591v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19591v1) | <details><summary>Show</summary><p>Cloud cover in multispectral imagery (MSI) poses significant challenges for early season crop mapping, as it leads to missing or corrupted spectral information. Synthetic aperture radar (SAR) data, which is not affected by cloud interference, offers a complementary solution, but lack sufficient spectral detail for precise crop mapping. To address this, we propose a novel framework, Time-series MSI Image Reconstruction using Vision Transformer (ViT), to reconstruct MSI data in cloud-covered regions by leveraging the temporal coherence of MSI and the complementary information from SAR from the attention mechanism. Comprehensive experiments, using rigorous reconstruction evaluation metrics, demonstrate that Time-series ViT framework significantly outperforms baselines that use non-time-series MSI and SAR or time-series MSI without SAR, effectively enhancing MSI image reconstruction in cloud-covered regions.</p></details> | <details><summary>This ...</summary><p>This paper has been accepted as a conference paper at the 2025 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)</p></details> |
| **[Time-Sensitive Importance Splitting](http://arxiv.org/abs/2506.19568v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19568v1) | <details><summary>Show</summary><p>State-of-the-art methods for rare event simulation of non-Markovian models face practical or theoretical limits if observing the event of interest requires prior knowledge or information on the timed behavior of the system. In this paper, we attack both limits by extending importance splitting with a time-sensitive importance function. To this end, we perform backwards reachability search from the target states, considering information about the lower and upper bounds of the active timers in order to steer the generation of paths towards the rare event. We have developed a prototype implementation of the approach for input/output stochastic automata within the Modest Toolset. Preliminary experiments show the potential of the approach in estimating rare event probabilities for an example from reliability engineering.</p></details> | <details><summary>Accep...</summary><p>Accepted at QEST+FORMATS 2025</p></details> |
| **[High-order adaptive multi-domain time integration scheme for microscale lithium-ion batteries simulations](http://arxiv.org/abs/2310.06573v3)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2310.06573v3) | <details><summary>Show</summary><p>We investigate the modeling and simulation of ionic transport and charge conservation in lithium-ion batteries (LIBs) at the microscale. It is a multiphysics problem that involves a wide range of time scales. The associated computational challenges motivate the investigation of numerical techniques that can decouple the time integration of the governing equations in the liquid electrolyte and the solid phase (active materials and current collectors). First, it is shown that semi-discretization in space of the non-dimensionalized governing equations leads to a system of index-1 semi-explicit differential algebraic equations (DAEs). Then, a new generation of strategies for multi-domain integration is presented, enabling high-order adaptive coupling of both domains in time, with efficient and potentially different domain integrators. They reach a high level of flexibility for real applications, beyond the limitations of multirate methods. A simple 1D LIB half-cell code is implemented as a demonstrator of the new strategy for the simulation of different modes of cell operation. The integration of the decoupled subsystems is performed with high-order accurate implicit nonlinear solvers. The accuracy of the space discretization is assessed by comparing the numerical results to the analytical solutions. Then, temporal convergence studies demonstrate the accuracy of the new multi-domain coupling approach. Finally, the accuracy and computational efficiency of the adaptive coupling strategy are discussed in the light of the conditioning of the decoupled subproblems compared to the one of the fully-coupled problem. This new approach will constitute a key ingredient for the high-fidelity 3D LIB simulations based on actual electrode microstructures.</p></details> | <details><summary>SMAI ...</summary><p>SMAI Journal of Computational Mathematics, In press</p></details> |
| **[FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting](http://arxiv.org/abs/2506.19567v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19567v1) | <details><summary>Show</summary><p>Multi-task and few-shot time series forecasting tasks are commonly encountered in scenarios such as the launch of new products in different cities. However, traditional time series forecasting methods suffer from insufficient historical data, which stems from a disregard for the generalized and specific features among different tasks. For the aforementioned challenges, we propose the Feature-Adaptive Time Series Forecasting Framework (FAF), which consists of three key components: the Generalized Knowledge Module (GKM), the Task-Specific Module (TSM), and the Rank Module (RM). During training phase, the GKM is updated through a meta-learning mechanism that enables the model to extract generalized features across related tasks. Meanwhile, the TSM is trained to capture diverse local dynamics through multiple functional regions, each of which learns specific features from individual tasks. During testing phase, the RM dynamically selects the most relevant functional region from the TSM based on input sequence features, which is then combined with the generalized knowledge learned by the GKM to generate accurate forecasts. This design enables FAF to achieve robust and personalized forecasting even with sparse historical observations We evaluate FAF on five diverse real-world datasets under few-shot time series forecasting settings. Experimental results demonstrate that FAF consistently outperforms baselines that include three categories of time series forecasting methods. In particular, FAF achieves a 41.81\% improvement over the best baseline, iTransformer, on the CO$_2$ emissions dataset.</p></details> | <details><summary>12 pa...</summary><p>12 pages,4 figures, 8 tables</p></details> |
| **[Finite-Horizon Strategy in Infinite-Horizon Linear-Quadratic Discrete-Time Dynamic Games](http://arxiv.org/abs/2506.19565v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19565v1) | <details><summary>Show</summary><p>This paper explores a finite-horizon strategy, ``watching $T$ steps into the future and moving one step now,'' in an $N$-person infinite-horizon discrete-time linear-quadratic dynamic game. The game involves linear input/output/state dynamics and quadratic cost functions with heterogeneous discount factors. For the finite-horizon version, which forms the basis of the infinite-horizon game, we analyze the structure of the coupled generalized discrete Riccati difference equations related to the feedback Nash equilibrium (FNE) and derive a sufficient condition for the uniqueness of the finite-horizon FNE. Under this condition, the FNE can be efficiently computed via the proposed algorithm. In the infinite-horizon game, assume all players adopt this finite-horizon strategy. If the iterations of the coupled equations related to the FNE converge, and the invertibility and stability conditions hold, we prove the convergence of each player's total cost under the finite-horizon strategy, even when players use individual prediction horizons. Furthermore, we provide an explicit upper bound on the cost difference between the finite-horizon strategy and the infinite-horizon FNE associated with the limiting matrices, expressed via the distance between their feedback strategy matrices. This bound vanishes as $T$ tends to infinity, implying convergence to the infinite-horizon FNE cost. A non-scalar numerical example illustrates the convergence behavior.</p></details> | 10 pages, 2 figures |
| **[Health Sentinel: An AI Pipeline For Real-time Disease Outbreak Detection](http://arxiv.org/abs/2506.19548v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19548v1) | <details><summary>Show</summary><p>Early detection of disease outbreaks is crucial to ensure timely intervention by the health authorities. Due to the challenges associated with traditional indicator-based surveillance, monitoring informal sources such as online media has become increasingly popular. However, owing to the number of online articles getting published everyday, manual screening of the articles is impractical. To address this, we propose Health Sentinel. It is a multi-stage information extraction pipeline that uses a combination of ML and non-ML methods to extract events-structured information concerning disease outbreaks or other unusual health events-from online articles. The extracted events are made available to the Media Scanning and Verification Cell (MSVC) at the National Centre for Disease Control (NCDC), Delhi for analysis, interpretation and further dissemination to local agencies for timely intervention. From April 2022 till date, Health Sentinel has processed over 300 million news articles and identified over 95,000 unique health events across India of which over 3,500 events were shortlisted by the public health experts at NCDC as potential outbreaks.</p></details> |  |
| **[Time-Constrained Interception of Seeker-Equipped Interceptors with Bounded Input](http://arxiv.org/abs/2506.19522v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19522v1) | <details><summary>Show</summary><p>This paper presents a nonlinear guidance scheme designed to achieve precise interception of stationary targets at a pre-specified impact time. The proposed strategy essentially accounts for the constraints imposed by the interceptor's seeker field-of-view (FOV) and actuator limitations, which, if ignored, can degrade guidance performance. To address these challenges, the guidance law incorporates known actuator bounds directly into its design, thereby improving overall interceptor effectiveness. The proposed method utilizes an input-affine magnitude saturation model to effectively enforce these constraints. By appending this input saturation model to the interceptor's kinematic equations, a guidance law is derived that ensures interception at the desired impact time while accounting for the physical constraints of the sensor and actuator. The efficacy of the proposed strategies is demonstrated through comprehensive numerical simulations across various scenarios and is compared against an existing guidance strategy.</p></details> |  |
| **[Anisotropic approximation on space-time domains](http://arxiv.org/abs/2506.19517v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19517v1) | <details><summary>Show</summary><p>We investigate anisotropic (piecewise) polynomial approximation of functions in Lebesgue spaces as well as anisotropic Besov spaces. For this purpose we study temporal and spacial moduli of smoothness and their properties. In particular, we prove Jackson- and Whitney-type inequalities on Lipschitz cylinders, i.e., space-time domains $I\times D$ with a finite interval $I$ and a bounded Lipschitz domain $D\subset \R^d$, $d\in \N$. As an application, we prove a direct estimate result for adaptive space-time finite element approximation in the discontinuous setting.</p></details> | 5 figures |
| **[Smart Traffic Signals: Comparing MARL and Fixed-Time Strategies](http://arxiv.org/abs/2505.14544v2)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2505.14544v2) | <details><summary>Show</summary><p>Urban traffic congestion, particularly at intersections, significantly impacts travel time, fuel consumption, and emissions. Traditional fixed-time signal control systems often lack the adaptability to manage dynamic traffic patterns effectively. This study explores the application of multi-agent reinforcement learning (MARL) to optimize traffic signal coordination across multiple intersections within a simulated environment. Utilizing Pygame, a simulation was developed to model a network of interconnected intersections with randomly generated vehicle flows to reflect realistic traffic variability. A decentralized MARL controller was implemented, in which each traffic signal operates as an autonomous agent, making decisions based on local observations and information from neighboring agents. Performance was evaluated against a baseline fixed-time controller using metrics such as average vehicle wait time and overall throughput. The MARL approach demonstrated statistically significant improvements, including reduced average waiting times and improved throughput. These findings suggest that MARL-based dynamic control strategies hold substantial promise for improving urban traffic management efficiency. More research is recommended to address scalability and real-world implementation challenges.</p></details> |  |
| **[TRMAC: A Time-Reversal-based MAC Protocol for Wireless Networks within Computing Packages](http://arxiv.org/abs/2506.19487v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19487v1) | <details><summary>Show</summary><p>As chiplet-based integration and many-core architectures become the norm in high-performance computing, on-chip wireless communication has emerged as a compelling alternative to traditional interconnects. However, scalable Medium Access Control (MAC) remains a fundamental challenge, particularly under dense traffic and limited spectral resources. This paper presents TRMAC, a novel cross-layer MAC protocol that exploits the spatial focusing capability of Time Reversal (TR) to enable multiple parallel transmissions over a shared frequency channel. By leveraging the quasi-deterministic nature of on-chip wireless channels, TRMAC pre-characterizes channel impulse responses to coordinate access using energy-based thresholds, eliminating the need for orthogonal resource allocation or centralized arbitration. Through detailed physical-layer simulation and system-level evaluation on diverse traffic, TRMAC demonstrates comparable or superior performance to existing multi-channel MAC protocols, achieving low latency, high throughput, and strong scalability across hundreds of cores. TRMAC provides a low-complexity, high-efficiency solution for future Wireless Networks-on-Chip (WNoCs), particularly in chiplet-based systems where spatial reuse and modularity are critical. With simulations we prove that TRMAC can be utilized for parallel transmissions with a single frequency channel with a similar throughput and latency as in using multiple frequency bands omitting the need for complex transceivers. This work establishes a new design direction for MAC protocols that are tightly integrated with the underlying channel physics to meet the demands of next-generation computing platforms.</p></details> |  |
| **[Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models](http://arxiv.org/abs/2502.19918v3)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2502.19918v3) | <details><summary>Show</summary><p>Large Language Models (LLMs) increasingly rely on prolonged reasoning chains to solve complex tasks. However, this trial-and-error approach often leads to high computational overhead and error propagation, where early mistakes can derail subsequent steps. To address these issues, we introduce Meta-Reasoner, a framework that dynamically optimizes inference-time reasoning by enabling LLMs to "think about how to think." Drawing inspiration from human meta-cognition and dual-process theory, Meta-Reasoner operates as a strategic advisor, decoupling high-level guidance from step-by-step generation. It employs contextual multi-armed bandits to iteratively evaluate reasoning progress and select optimal strategies (e.g., backtrack, clarify ambiguity, restart from scratch, or propose alternative approaches), and reallocates computational resources toward the most promising paths. Our evaluations on mathematical reasoning and puzzles highlight the potential of dynamic reasoning chains to overcome inherent challenges in the LLM reasoning process and also show promise in broader applications, offering a scalable and adaptable solution for reasoning-intensive tasks.</p></details> |  |
| **[Training-Free Motion Customization for Distilled Video Generators with Adaptive Test-Time Distillation](http://arxiv.org/abs/2506.19348v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19348v1) | <details><summary>Show</summary><p>Distilled video generation models offer fast and efficient synthesis but struggle with motion customization when guided by reference videos, especially under training-free settings. Existing training-free methods, originally designed for standard diffusion models, fail to generalize due to the accelerated generative process and large denoising steps in distilled models. To address this, we propose MotionEcho, a novel training-free test-time distillation framework that enables motion customization by leveraging diffusion teacher forcing. Our approach uses high-quality, slow teacher models to guide the inference of fast student models through endpoint prediction and interpolation. To maintain efficiency, we dynamically allocate computation across timesteps according to guidance needs. Extensive experiments across various distilled video generation models and benchmark datasets demonstrate that our method significantly improves motion fidelity and generation quality while preserving high efficiency. Project page: https://euminds.github.io/motionecho/</p></details> |  |
| **[Inference-Time Reward Hacking in Large Language Models](http://arxiv.org/abs/2506.19248v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19248v1) | <details><summary>Show</summary><p>A common paradigm to improve the performance of large language models is optimizing for a reward model. Reward models assign a numerical score to LLM outputs indicating, for example, which response would likely be preferred by a user or is most aligned with safety goals. However, reward models are never perfect. They inevitably function as proxies for complex desiderata such as correctness, helpfulness, and safety. By overoptimizing for a misspecified reward, we can subvert intended alignment goals and reduce overall performance -- a phenomenon commonly referred to as reward hacking. In this work, we characterize reward hacking in inference-time alignment and demonstrate when and how we can mitigate it by hedging on the proxy reward. We study this phenomenon under Best-of-$n$ (BoN) and Soft-Best-of-$n$ (SBoN), and we introduce Best-of-Poisson (BoP) that provides an efficient, near-exact approximation of the optimal reward-KL divergence policy at inference time. We show that the characteristic pattern of hacking as observed in practice (where the true reward first increases before declining) is an inevitable property of a broad class of inference-time mechanisms, including BoN and BoP. To counter this effect, hedging offers a tactical choice to avoid placing undue confidence in high but potentially misleading proxy reward signals. We introduce HedgeTune, an efficient algorithm to find the optimal inference-time parameter and avoid reward hacking. We demonstrate through experiments that hedging mitigates reward hacking and achieves superior distortion-reward tradeoffs with minimal computational overhead.</p></details> | <details><summary>Accep...</summary><p>Accepted to ICML 2025 Workshop on Models of Human Feedback for AI Alignment</p></details> |
| **[Incremental Shortest Paths in Almost Linear Time via a Modified Interior Point Method](http://arxiv.org/abs/2506.19207v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19207v1) | <details><summary>Show</summary><p>We give an algorithm that takes a directed graph $G$ undergoing $m$ edge insertions with lengths in $[1, W]$, and maintains $(1+\epsilon)$-approximate shortest path distances from a fixed source $s$ to all other vertices. The algorithm is deterministic and runs in total time $m^{1+o(1)}\log W$, for any $\epsilon > \exp(-(\log m)^{0.99})$. This is achieved by designing a nonstandard interior point method to crudely detect when the distances from $s$ other vertices $v$ have decreased by a $(1+\epsilon)$ factor, and implementing it using the deterministic min-ratio cycle data structure of [Chen-Kyng-Liu-Meierhans-Probst, STOC 2024].</p></details> | 20 pages |
| **[Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series](http://arxiv.org/abs/2506.10412v2)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.10412v2) | <details><summary>Show</summary><p>Time series data in real-world applications such as healthcare, climate modeling, and finance are often irregular, multimodal, and messy, with varying sampling rates, asynchronous modalities, and pervasive missingness. However, existing benchmarks typically assume clean, regularly sampled, unimodal data, creating a significant gap between research and real-world deployment. We introduce Time-IMM, a dataset specifically designed to capture cause-driven irregularity in multimodal multivariate time series. Time-IMM represents nine distinct types of time series irregularity, categorized into trigger-based, constraint-based, and artifact-based mechanisms. Complementing the dataset, we introduce IMM-TSF, a benchmark library for forecasting on irregular multimodal time series, enabling asynchronous integration and realistic evaluation. IMM-TSF includes specialized fusion modules, including a timestamp-to-text fusion module and a multimodality fusion module, which support both recency-aware averaging and attention-based integration strategies. Empirical results demonstrate that explicitly modeling multimodality on irregular time series data leads to substantial gains in forecasting performance. Time-IMM and IMM-TSF provide a foundation for advancing time series analysis under real-world conditions. The dataset is publicly available at https://www.kaggle.com/datasets/blacksnail789521/time-imm/data, and the benchmark library can be accessed at https://anonymous.4open.science/r/IMMTSF_NeurIPS2025.</p></details> | <details><summary>This ...</summary><p>This paper is currently under review</p></details> |
| **[TD-Paint: Faster Diffusion Inpainting Through Time Aware Pixel Conditioning](http://arxiv.org/abs/2410.09306v2)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2410.09306v2) | <details><summary>Show</summary><p>Diffusion models have emerged as highly effective techniques for inpainting, however, they remain constrained by slow sampling rates. While recent advances have enhanced generation quality, they have also increased sampling time, thereby limiting scalability in real-world applications. We investigate the generative sampling process of diffusion-based inpainting models and observe that these models make minimal use of the input condition during the initial sampling steps. As a result, the sampling trajectory deviates from the data manifold, requiring complex synchronization mechanisms to realign the generation process. To address this, we propose Time-aware Diffusion Paint (TD-Paint), a novel approach that adapts the diffusion process by modeling variable noise levels at the pixel level. This technique allows the model to efficiently use known pixel values from the start, guiding the generation process toward the target manifold. By embedding this information early in the diffusion process, TD-Paint significantly accelerates sampling without compromising image quality. Unlike conventional diffusion-based inpainting models, which require a dedicated architecture or an expensive generation loop, TD-Paint achieves faster sampling times without architectural modifications. Experimental results across three datasets show that TD-Paint outperforms state-of-the-art diffusion models while maintaining lower complexity.</p></details> |  |
| **[MEDEA: A Design-Time Multi-Objective Manager for Energy-Efficient DNN Inference on Heterogeneous Ultra-Low Power Platforms](http://arxiv.org/abs/2506.19067v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.19067v1) | <details><summary>Show</summary><p>The growing demand for on-device AI necessitates energy-efficient execution of DNN based applications on resource-constrained ultra-low power (ULP) platforms. Heterogeneous architectures, combining specialized processing elements (PEs), have emerged as a key solution for achieving the required performance and energy efficiency. However, optimizing energy while executing applications on these platforms requires efficiently managing platform resources like PEs, power features, and memory footprint, all while adhering to critical application deadlines. This paper presents MEDEA, a novel design-time multi-objective manager for energy-efficient DNN inference on Heterogeneous ULP (HULP) platforms. MEDEA uniquely integrates: kernel-level dynamic voltage and frequency scaling (DVFS) for dynamic energy adaptation; kernel-level granularity scheduling, suitable for specialized accelerators; memory-aware adaptive tiling to navigate severe memory constraints; and all within a timing constraint-based optimization strategy, which minimizes energy based on application deadline. To showcase practical viability, we evaluate MEDEA on HEEPtimize, a heterogeneous ULP platform (22 nm, FPGA-prototyped) featuring a RISC-V processor besides Near-Memory Computing (NMC) and Coarse-Grained Reconfigurable Array (CGRA) accelerators. Experimental results, using a biomedical seizure detection case study, demonstrate that MEDEA achieves overall energy reductions of up to 38% compared to representative state-of-the-art methods, while consistently meeting all timing and memory requirements. This effectiveness is attributed to its integrated features, with our analysis showing that kernel-level DVFS alone can be responsible for over 31% of the energy savings in specific scenarios.</p></details> | <details><summary>Submi...</summary><p>Submitted to ACM Transactions on Embedded Computing Systems (TECS)</p></details> |
| **[Failure Modes of Time Series Interpretability Algorithms for Critical Care Applications and Potential Solutions](http://arxiv.org/abs/2506.19035v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.19035v1) | <details><summary>Show</summary><p>Interpretability plays a vital role in aligning and deploying deep learning models in critical care, especially in constantly evolving conditions that influence patient survival. However, common interpretability algorithms face unique challenges when applied to dynamic prediction tasks, where patient trajectories evolve over time. Gradient, Occlusion, and Permutation-based methods often struggle with time-varying target dependency and temporal smoothness. This work systematically analyzes these failure modes and supports learnable mask-based interpretability frameworks as alternatives, which can incorporate temporal continuity and label consistency constraints to learn feature importance over time. Here, we propose that learnable mask-based approaches for dynamic timeseries prediction problems provide more reliable and consistent interpretations for applications in critical care and similar domains.</p></details> | <details><summary>13 pa...</summary><p>13 pages, 10 figures, Accepted at the AMIA Annual Symposium 2025. The final version will appear in the official proceedings</p></details> |
| **[Orthogonal Projection Subspace to Aggregate Online Prior-knowledge for Continual Test-time Adaptation](http://arxiv.org/abs/2506.19022v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.19022v1) | <details><summary>Show</summary><p>Continual Test Time Adaptation (CTTA) is a task that requires a source pre-trained model to continually adapt to new scenarios with changing target distributions. Existing CTTA methods primarily focus on mitigating the challenges of catastrophic forgetting and error accumulation. Though there have been emerging methods based on forgetting adaptation with parameter-efficient fine-tuning, they still struggle to balance competitive performance and efficient model adaptation, particularly in complex tasks like semantic segmentation. In this paper, to tackle the above issues, we propose a novel pipeline, Orthogonal Projection Subspace to aggregate online Prior-knowledge, dubbed OoPk. Specifically, we first project a tuning subspace orthogonally which allows the model to adapt to new domains while preserving the knowledge integrity of the pre-trained source model to alleviate catastrophic forgetting. Then, we elaborate an online prior-knowledge aggregation strategy that employs an aggressive yet efficient image masking strategy to mimic potential target dynamism, enhancing the student model's domain adaptability. This further gradually ameliorates the teacher model's knowledge, ensuring high-quality pseudo labels and reducing error accumulation. We demonstrate our method with extensive experiments that surpass previous CTTA methods and achieve competitive performances across various continual TTA benchmarks in semantic segmentation tasks.</p></details> |  |
| **[4D-LRM: Large Space-Time Reconstruction Model From and To Any View at Any Time](http://arxiv.org/abs/2506.18890v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18890v1) | <details><summary>Show</summary><p>Can we scale 4D pretraining to learn general space-time representations that reconstruct an object from a few views at some times to any view at any time? We provide an affirmative answer with 4D-LRM, the first large-scale 4D reconstruction model that takes input from unconstrained views and timestamps and renders arbitrary novel view-time combinations. Unlike prior 4D approaches, e.g., optimization-based, geometry-based, or generative, that struggle with efficiency, generalization, or faithfulness, 4D-LRM learns a unified space-time representation and directly predicts per-pixel 4D Gaussian primitives from posed image tokens across time, enabling fast, high-quality rendering at, in principle, infinite frame rate. Our results demonstrate that scaling spatiotemporal pretraining enables accurate and efficient 4D reconstruction. We show that 4D-LRM generalizes to novel objects, interpolates across time, and handles diverse camera setups. It reconstructs 24-frame sequences in one forward pass with less than 1.5 seconds on a single A100 GPU.</p></details> | <details><summary>Proje...</summary><p>Project page: https://4dlrm.github.io/</p></details> |
| **[A Reliable Framework for Human-in-the-Loop Anomaly Detection in Time Series](http://arxiv.org/abs/2405.03234v4)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2405.03234v4) | <details><summary>Show</summary><p>Time series anomaly detection is a critical machine learning task for numerous applications, such as finance, healthcare, and industrial systems. However, even high-performing models may exhibit potential issues such as biases, leading to unreliable outcomes and misplaced confidence. While model explanation techniques, particularly visual explanations, offer valuable insights by elucidating model attributions of their decision, many limitations still exist -- They are primarily instance-based and not scalable across the dataset, and they provide one-directional information from the model to the human side, lacking a mechanism for users to address detected issues. To fulfill these gaps, we introduce HILAD, a novel framework designed to foster a dynamic and bidirectional collaboration between humans and AI for enhancing anomaly detection models in time series. Through our visual interface, HILAD empowers domain experts to detect, interpret, and correct unexpected model behaviors at scale. Our evaluation through user studies with two models and three time series datasets demonstrates the effectiveness of HILAD, which fosters a deeper model understanding, immediate corrective actions, and model reliability enhancement.</p></details> | <details><summary>The m...</summary><p>The manuscript is currently under review</p></details> |
| **[Unconditionally stable space-time isogeometric method for the linear Schrödinger equation](http://arxiv.org/abs/2506.18859v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18859v1) | <details><summary>Show</summary><p>We propose and analyze a space-time isogeometric finite element method based on splines with maximal regularity in time for the linear time-dependent Schr\"odinger equation with a spatially varying potential. We investigate the stability and conservation properties of the method, demonstrating that it preserves both mass and energy at the final time, and it is unconditionally stable. Numerical experiments confirm our theoretical findings and illustrate the convergence behavior of the scheme. Incidentally, our analysis also provides an alternative proof of unconditional stability of the first-order-in-time isogeometric method for the wave equation proposed in (M. Ferrari, S. Fraschini, G. Loli and I. Perugia (2025)), eliminating the need for the numerical verifications required in the previous analysis.</p></details> |  |
| **[Optimal adaptive implicit time stepping](http://arxiv.org/abs/2506.18809v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18809v1) | <details><summary>Show</summary><p>We revisit adaptive time stepping, one of the classical topics of numerical analysis and computational engineering. While widely used in application and subject of many theoretical works, a complete understanding is still missing. Apart from special cases, there does not exist a complete theory that shows how to choose the time steps such that convergence towards the exact solution is guaranteed with the optimal convergence rate. In this work, we use recent advances in adaptive mesh refinement to propose an adaptive time stepping algorithm that is mathematically guaranteed to be optimal in the sense that it achieves the best possible convergence of the error with respect to the number of time steps, and it can be implemented using a time stepping scheme as a black box.</p></details> |  |
| **[Flow-Aware Diffusion for Real-Time VR Restoration: Enhancing Spatiotemporal Coherence and Efficiency](http://arxiv.org/abs/2506.18786v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18786v1) | <details><summary>Show</summary><p>Cybersickness remains a critical barrier to the widespread adoption of Virtual Reality (VR), particularly in scenarios involving intense or artificial motion cues. Among the key contributors is excessive optical flow-perceived visual motion that, when unmatched by vestibular input, leads to sensory conflict and discomfort. While previous efforts have explored geometric or hardware based mitigation strategies, such methods often rely on predefined scene structures, manual tuning, or intrusive equipment. In this work, we propose U-MAD, a lightweight, real-time, AI-based solution that suppresses perceptually disruptive optical flow directly at the image level. Unlike prior handcrafted approaches, this method learns to attenuate high-intensity motion patterns from rendered frames without requiring mesh-level editing or scene specific adaptation. Designed as a plug and play module, U-MAD integrates seamlessly into existing VR pipelines and generalizes well to procedurally generated environments. The experiments show that U-MAD consistently reduces average optical flow and enhances temporal stability across diverse scenes. A user study further confirms that reducing visual motion leads to improved perceptual comfort and alleviated cybersickness symptoms. These findings demonstrate that perceptually guided modulation of optical flow provides an effective and scalable approach to creating more user-friendly immersive experiences. The code will be released at https://github.com/XXXXX (upon publication).</p></details> |  |
| **[Self-Normalized Inference in (Quantile, Expected Shortfall) Regressions for Time Series](http://arxiv.org/abs/2502.10065v2)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2502.10065v2) | <details><summary>Show</summary><p>This paper proposes valid inference tools, based on self-normalization, in time series expected shortfall regressions and, as a corollary, also in quantile regressions. Extant methods for such time series regressions, based on a bootstrap or direct estimation of the long-run variance, are computationally more involved, require the choice of tuning parameters and have serious size distortions when the regression errors are strongly serially dependent. In contrast, our inference tools only require estimates of the (quantile, expected shortfall) regression parameters that are computed on an expanding window, and are correctly sized as we show in simulations. Two empirical applications to stock return predictability and to Growth-at-Risk demonstrate the practical usefulness of the developed inference tools.</p></details> |  |
| **[BulletGen: Improving 4D Reconstruction with Bullet-Time Generation](http://arxiv.org/abs/2506.18601v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18601v1) | <details><summary>Show</summary><p>Transforming casually captured, monocular videos into fully immersive dynamic experiences is a highly ill-posed task, and comes with significant challenges, e.g., reconstructing unseen regions, and dealing with the ambiguity in monocular depth estimation. In this work we introduce BulletGen, an approach that takes advantage of generative models to correct errors and complete missing information in a Gaussian-based dynamic scene representation. This is done by aligning the output of a diffusion-based video generation model with the 4D reconstruction at a single frozen "bullet-time" step. The generated frames are then used to supervise the optimization of the 4D Gaussian model. Our method seamlessly blends generative content with both static and dynamic scene components, achieving state-of-the-art results on both novel-view synthesis, and 2D/3D tracking tasks.</p></details> |  |
| **[No Training Wheels: Steering Vectors for Bias Correction at Inference Time](http://arxiv.org/abs/2506.18598v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18598v1) | <details><summary>Show</summary><p>Neural network classifiers trained on datasets with uneven group representation often inherit class biases and learn spurious correlations. These models may perform well on average but consistently fail on atypical groups. For example, in hair color classification, datasets may over-represent females with blond hair, reinforcing stereotypes. Although various algorithmic and data-centric methods have been proposed to address such biases, they often require retraining or significant compute. In this work, we propose a cheap, training-free method inspired by steering vectors used to edit behaviors in large language models. We compute the difference in mean activations between majority and minority groups to define a "bias vector," which we subtract from the model's residual stream. This leads to reduced classification bias and improved worst-group accuracy. We explore multiple strategies for extracting and applying these vectors in transformer-like classifiers, showing that steering vectors, traditionally used in generative models, can also be effective in classification. More broadly, we showcase an extremely cheap, inference time, training free method to mitigate bias in classification models.</p></details> |  |

## Trajectory
| **Title** | **Date** | **KiMi** | **Abstract** | **Comment** |
| --- | --- | --- | --- | --- |
| **[Towards Interpretable and Efficient Feature Selection in Trajectory Datasets: A Taxonomic Approach](http://arxiv.org/abs/2506.20359v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20359v1) | <details><summary>Show</summary><p>Trajectory analysis is not only about obtaining movement data, but it is also of paramount importance in understanding the pattern in which an object moves through space and time, as well as in predicting its next move. Due to the significant interest in the area, data collection has improved substantially, resulting in a large number of features becoming available for training and predicting models. However, this introduces a high-dimensionality-induced feature explosion problem, which reduces the efficiency and interpretability of the data, thereby reducing the accuracy of machine learning models. To overcome this issue, feature selection has become one of the most prevalent tools. Thus, the objective of this paper was to introduce a taxonomy-based feature selection method that categorizes features based on their internal structure. This approach classifies the data into geometric and kinematic features, further categorizing them into curvature, indentation, speed, and acceleration. The comparative analysis indicated that a taxonomy-based approach consistently achieved comparable or superior predictive performance. Furthermore, due to the taxonomic grouping, which reduces combinatorial space, the time taken to select features was drastically reduced. The taxonomy was also used to gain insights into what feature sets each dataset was more sensitive to. Overall, this study provides robust evidence that a taxonomy-based feature selection method can add a layer of interpretability, reduce dimensionality and computational complexity, and contribute to high-level decision-making. It serves as a step toward providing a methodological framework for researchers and practitioners dealing with trajectory datasets and contributing to the broader field of explainable artificial intelligence.</p></details> |  |
| **[Generating and Customizing Robotic Arm Trajectories using Neural Networks](http://arxiv.org/abs/2506.20259v1)** | 2025-06-25 | [papers-cool](https://papers.cool/arxiv/2506.20259v1) | <details><summary>Show</summary><p>We introduce a neural network approach for generating and customizing the trajectory of a robotic arm, that guarantees precision and repeatability. To highlight the potential of this novel method, we describe the design and implementation of the technique and show its application in an experimental setting of cognitive robotics. In this scenario, the NICO robot was characterized by the ability to point to specific points in space with precise linear movements, increasing the predictability of the robotic action during its interaction with humans. To achieve this goal, the neural network computes the forward kinematics of the robot arm. By integrating it with a generator of joint angles, another neural network was developed and trained on an artificial dataset created from suitable start and end poses of the robotic arm. Through the computation of angular velocities, the robot was characterized by its ability to perform the movement, and the quality of its action was evaluated in terms of shape and accuracy. Thanks to its broad applicability, our approach successfully generates precise trajectories that could be customized in their shape and adapted to different settings.</p></details> | <details><summary>The c...</summary><p>The code is released at https://github.com/andylucny/nico2/tree/main/generate</p></details> |
| **[RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories](http://arxiv.org/abs/2506.15242v2)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.15242v2) | <details><summary>Show</summary><p>Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have emerged as powerful tools for 3D reconstruction and SLAM tasks. However, their performance depends heavily on accurate camera pose priors. Existing approaches attempt to address this issue by introducing external constraints but fall short of achieving satisfactory accuracy, particularly when camera trajectories are complex. In this paper, we propose a novel method, RA-NeRF, capable of predicting highly accurate camera poses even with complex camera trajectories. Following the incremental pipeline, RA-NeRF reconstructs the scene using NeRF with photometric consistency and incorporates flow-driven pose regulation to enhance robustness during initialization and localization. Additionally, RA-NeRF employs an implicit pose filter to capture the camera movement pattern and eliminate the noise for pose estimation. To validate our method, we conduct extensive experiments on the Tanks\&Temple dataset for standard evaluation, as well as the NeRFBuster dataset, which presents challenging camera pose trajectories. On both datasets, RA-NeRF achieves state-of-the-art results in both camera pose estimation and visual quality, demonstrating its effectiveness and robustness in scene reconstruction under complex pose trajectories.</p></details> | IROS 2025 |
| **[FusionForce: End-to-end Differentiable Neural-Symbolic Layer for Trajectory Prediction](http://arxiv.org/abs/2502.10156v4)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2502.10156v4) | <details><summary>Show</summary><p>We propose end-to-end differentiable model that predicts robot trajectories on rough offroad terrain from camera images and/or lidar point clouds. The model integrates a learnable component that predicts robot-terrain interaction forces with a neural-symbolic layer that enforces the laws of classical mechanics and consequently improves generalization on out-of-distribution data. The neural-symbolic layer includes a differentiable physics engine that computes the robot's trajectory by querying these forces at the points of contact with the terrain. As the proposed architecture comprises substantial geometrical and physics priors, the resulting model can also be seen as a learnable physics engine conditioned on real sensor data that delivers $10^4$ trajectories per second. We argue and empirically demonstrate that this architecture reduces the sim-to-real gap and mitigates out-of-distribution sensitivity. The differentiability, in conjunction with the rapid simulation speed, makes the model well-suited for various applications including model predictive control, trajectory shooting, supervised and reinforcement learning, or SLAM.</p></details> | <details><summary>Code:...</summary><p>Code: https://github.com/ctu-vras/fusionforce</p></details> |
| **[Pseudo-Kinematic Trajectory Control and Planning of Tracked Vehicles](http://arxiv.org/abs/2409.18641v2)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2409.18641v2) | <details><summary>Show</summary><p>Tracked vehicles distribute their weight continuously over a large surface area (the tracks). This distinctive feature makes them the preferred choice for vehicles required to traverse soft and uneven terrain. From a robotics perspective, however, this flexibility comes at a cost: the complexity of modelling the system and the resulting difficulty in designing theoretically sound navigation solutions. In this paper, we aim to bridge this gap by proposing a framework for the navigation of tracked vehicles, built upon three key pillars. The first pillar comprises two models: a simulation model and a control-oriented model. The simulation model captures the intricate terramechanics dynamics arising from soil-track interaction and is employed to develop faithful digital twins of the system across a wide range of operating conditions. The control-oriented model is pseudo-kinematic and mathematically tractable, enabling the design of efficient and theoretically robust control schemes. The second pillar is a Lyapunov-based feedback trajectory controller that provides certifiable tracking guarantees. The third pillar is a portfolio of motion planning solutions, each offering different complexity-accuracy trade-offs. The various components of the proposed approach are validated through an extensive set of simulation and experimental data.</p></details> |  |
| **[Path Learning with Trajectory Advantage Regression](http://arxiv.org/abs/2506.19375v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19375v1) | <details><summary>Show</summary><p>In this paper, we propose trajectory advantage regression, a method of offline path learning and path attribution based on reinforcement learning. The proposed method can be used to solve path optimization problems while algorithmically only solving a regression problem.</p></details> |  |
| **[Trajectory Prediction in Dynamic Object Tracking: A Critical Study](http://arxiv.org/abs/2506.19341v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19341v1) | <details><summary>Show</summary><p>This study provides a detailed analysis of current advancements in dynamic object tracking (DOT) and trajectory prediction (TP) methodologies, including their applications and challenges. It covers various approaches, such as feature-based, segmentation-based, estimation-based, and learning-based methods, evaluating their effectiveness, deployment, and limitations in real-world scenarios. The study highlights the significant impact of these technologies in automotive and autonomous vehicles, surveillance and security, healthcare, and industrial automation, contributing to safety and efficiency. Despite the progress, challenges such as improved generalization, computational efficiency, reduced data dependency, and ethical considerations still exist. The study suggests future research directions to address these challenges, emphasizing the importance of multimodal data integration, semantic information fusion, and developing context-aware systems, along with ethical and privacy-preserving frameworks.</p></details> |  |
| **[Reinforcement learning for efficient and robust multi-setpoint and multi-trajectory tracking in bioprocesses](http://arxiv.org/abs/2503.22409v2)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2503.22409v2) | <details><summary>Show</summary><p>Efficient and robust bioprocess control is essential for maximizing performance and adaptability in advanced biotechnological systems. In this work, we present a reinforcement-learning framework for multi-setpoint and multi-trajectory tracking. Tracking multiple setpoints and time-varying trajectories in reinforcement learning is challenging due to the complexity of balancing multiple objectives, a difficulty further exacerbated by system uncertainties such as uncertain initial conditions and stochastic dynamics. This challenge is relevant, e.g., in bioprocesses involving microbial consortia, where precise control over population compositions is required. We introduce a novel return function based on multiplicative reciprocal saturation functions, which explicitly couples reward gains to the simultaneous satisfaction of multiple references. Through a case study involving light-mediated cybergenetic growth control in microbial consortia, we demonstrate via computational experiments that our approach achieves faster convergence, improved stability, and superior control compliance compared to conventional quadratic-cost-based return functions. Moreover, our method enables tuning of the saturation function's parameters, shaping the learning process and policy updates. By incorporating system uncertainties, our framework also demonstrates robustness, a key requirement in industrial bioprocessing. Overall, this work advances reinforcement-learning-based control strategies in bioprocess engineering, with implications in the broader field of process and systems engineering.</p></details> |  |
| **[Augmenting Multi-Agent Communication with State Delta Trajectory](http://arxiv.org/abs/2506.19209v1)** | 2025-06-24 | [papers-cool](https://papers.cool/arxiv/2506.19209v1) | <details><summary>Show</summary><p>Multi-agent techniques such as role playing or multi-turn debates have been shown to be effective in improving the performance of large language models (LLMs) in downstream tasks. Despite their differences in workflows, existing LLM-based multi-agent systems mostly use natural language for agent communication. While this is appealing for its simplicity and interpretability, it also introduces inevitable information loss as one model must down sample its continuous state vectors to concrete tokens before transferring them to the other model. Such losses are particularly significant when the information to transfer is not simple facts, but reasoning logics or abstractive thoughts. To tackle this problem, we propose a new communication protocol that transfers both natural language tokens and token-wise state transition trajectory from one agent to another. Particularly, compared to the actual state value, we find that the sequence of state changes in LLMs after generating each token can better reflect the information hidden behind the inference process, so we propose a State Delta Encoding (SDE) method to represent state transition trajectories. The experimental results show that multi-agent systems with SDE achieve SOTA performance compared to other communication protocols, particularly in tasks that involve complex reasoning. This shows the potential of communication augmentation for LLM-based multi-agent systems.</p></details> | 22 pages, 5 figures |
| **[Employing Laban Shape for Generating Emotionally and Functionally Expressive Trajectories in Robotic Manipulators](http://arxiv.org/abs/2505.11716v2)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2505.11716v2) | <details><summary>Show</summary><p>Successful human-robot collaboration depends on cohesive communication and a precise understanding of the robot's abilities, goals, and constraints. While robotic manipulators offer high precision, versatility, and productivity, they exhibit expressionless and monotonous motions that conceal the robot's intention, resulting in a lack of efficiency and transparency with humans. In this work, we use Laban notation, a dance annotation language, to enable robotic manipulators to generate trajectories with functional expressivity, where the robot uses nonverbal cues to communicate its abilities and the likelihood of succeeding at its task. We achieve this by introducing two novel variants of Hesitant expressive motion (Spoke-Like and Arc-Like). We also enhance the emotional expressivity of four existing emotive trajectories (Happy, Sad, Shy, and Angry) by augmenting Laban Effort usage with Laban Shape. The functionally expressive motions are validated via a human-subjects study, where participants equate both variants of Hesitant motion with reduced robot competency. The enhanced emotive trajectories are shown to be viewed as distinct emotions using the Valence-Arousal-Dominance (VAD) spectrum, corroborating the usage of Laban Shape.</p></details> | <details><summary>Accep...</summary><p>Accepted for presentation at the 2025 IEEE RO-MAN Conference</p></details> |
| **[ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs](http://arxiv.org/abs/2506.18896v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18896v1) | <details><summary>Show</summary><p>Process Reward Models (PRMs) have recently emerged as a powerful framework for supervising intermediate reasoning steps in large language models (LLMs). Previous PRMs are primarily trained on model final output responses and struggle to evaluate intermediate thinking trajectories robustly, especially in the emerging setting of trajectory-response outputs generated by frontier reasoning models like Deepseek-R1. In this work, we introduce ReasonFlux-PRM, a novel trajectory-aware PRM explicitly designed to evaluate the trajectory-response type of reasoning traces. ReasonFlux-PRM incorporates both step-level and trajectory-level supervision, enabling fine-grained reward assignment aligned with structured chain-of-thought data. We adapt ReasonFlux-PRM to support reward supervision under both offline and online settings, including (i) selecting high-quality model distillation data for downstream supervised fine-tuning of smaller models, (ii) providing dense process-level rewards for policy optimization during reinforcement learning, and (iii) enabling reward-guided Best-of-N test-time scaling. Empirical results on challenging downstream benchmarks such as AIME, MATH500, and GPQA-Diamond demonstrate that ReasonFlux-PRM-7B selects higher quality data than strong PRMs (e.g., Qwen2.5-Math-PRM-72B) and human-curated baselines. Furthermore, our derived ReasonFlux-PRM-7B yields consistent performance improvements, achieving average gains of 12.1% in supervised fine-tuning, 4.5% in reinforcement learning, and 6.3% in test-time scaling. We also release our efficient ReasonFlux-PRM-1.5B for resource-constrained applications and edge deployment. Projects: https://github.com/Gen-Verse/ReasonFlux</p></details> | <details><summary>Codes...</summary><p>Codes and Models: https://github.com/Gen-Verse/ReasonFlux</p></details> |
| **[Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories](http://arxiv.org/abs/2506.18824v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18824v1) | <details><summary>Show</summary><p>Large Language Model (LLM)-based agents are increasingly employed to automate complex software engineering tasks such as program repair and issue resolution. These agents operate by autonomously generating natural language thoughts, invoking external tools, and iteratively refining their solutions. Despite their widespread adoption, the internal decision-making processes of these agents remain largely unexplored, limiting our understanding of their operational dynamics and failure modes. In this paper, we present a large-scale empirical study of the thought-action-result trajectories of three state-of-the-art LLM-based agents: \textsc{RepairAgent}, \textsc{AutoCodeRover}, and \textsc{OpenHands}. We unify their interaction logs into a common format, capturing 120 trajectories and 2822 LLM interactions focused on program repair and issue resolution. Our study combines quantitative analyses of structural properties, action patterns, and token usage with qualitative assessments of reasoning coherence and feedback integration. We identify key trajectory characteristics such as iteration counts and token consumption, recurring action sequences, and the semantic coherence linking thoughts, actions, and their results. Our findings reveal behavioral motifs and anti-patterns that distinguish successful from failed executions, providing actionable insights for improving agent design, including prompting strategies, failure diagnosis, and anti-pattern detection. We release our dataset and annotation framework to support further research on transparent and robust autonomous software engineering agents.</p></details> |  |
| **[Selective Social-Interaction via Individual Importance for Fast Human Trajectory Prediction](http://arxiv.org/abs/2506.18291v1)** | 2025-06-23 | [papers-cool](https://papers.cool/arxiv/2506.18291v1) | <details><summary>Show</summary><p>This paper presents an architecture for selecting important neighboring people to predict the primary person's trajectory. To achieve effective neighboring people selection, we propose a people selection module called the Importance Estimator which outputs the importance of each neighboring person for predicting the primary person's future trajectory. To prevent gradients from being blocked by non-differentiable operations when sampling surrounding people based on their importance, we employ the Gumbel Softmax for training. Experiments conducted on the JRDB dataset show that our method speeds up the process with competitive prediction accuracy.</p></details> | MIRU 2025 |
| **[Area between trajectories: Insights into optimal group selection and trajectory heterogeneity in group-based trajectory modeling](http://arxiv.org/abs/2506.18108v1)** | 2025-06-22 | [papers-cool](https://papers.cool/arxiv/2506.18108v1) | <details><summary>Show</summary><p>Group-based trajectory modeling (GBTM) is commonly used to identify longitudinal patterns in health outcomes among older adults, with determining the optimal number of groups being a crucial step. While statistically grounded criteria are primarily relied upon, clinical relevance is gradually emphasized in medicine to ensure that the identified trajectory heterogeneity appropriately reflects changes in a disease or symptom over time. However, such considerations are often judged through visual comparisons, without concrete approaches for their application. To address this, the Area Between Trajectories (ABTs) was introduced as insights for quantifying trajectory group differences. Using a simulated sleep quality dataset, GBTM was applied to build and compare models. Subsequently, ABTs was demonstrated to show how it works, while also highlighting its limitations and potential applications.</p></details> | <details><summary>15 pa...</summary><p>15 pages, 4 figures, 1 table</p></details> |
| **[DriveSuprim: Towards Precise Trajectory Selection for End-to-End Planning](http://arxiv.org/abs/2506.06659v2)** | 2025-06-22 | [papers-cool](https://papers.cool/arxiv/2506.06659v2) | <details><summary>Show</summary><p>In complex driving environments, autonomous vehicles must navigate safely. Relying on a single predicted path, as in regression-based approaches, usually does not explicitly assess the safety of the predicted trajectory. Selection-based methods address this by generating and scoring multiple trajectory candidates and predicting the safety score for each, but face optimization challenges in precisely selecting the best option from thousands of possibilities and distinguishing subtle but safety-critical differences, especially in rare or underrepresented scenarios. We propose DriveSuprim to overcome these challenges and advance the selection-based paradigm through a coarse-to-fine paradigm for progressive candidate filtering, a rotation-based augmentation method to improve robustness in out-of-distribution scenarios, and a self-distillation framework to stabilize training. DriveSuprim achieves state-of-the-art performance, reaching 93.5% PDMS in NAVSIM v1 and 87.1% EPDMS in NAVSIM v2 without extra data, demonstrating superior safetycritical capabilities, including collision avoidance and compliance with rules, while maintaining high trajectory quality in various driving scenarios.</p></details> | 15 pages, 6 figures |
| **[Leveling the Playing Field: Carefully Comparing Classical and Learned Controllers for Quadrotor Trajectory Tracking](http://arxiv.org/abs/2506.17832v1)** | 2025-06-21 | [papers-cool](https://papers.cool/arxiv/2506.17832v1) | <details><summary>Show</summary><p>Learning-based control approaches like reinforcement learning (RL) have recently produced a slew of impressive results for tasks like quadrotor trajectory tracking and drone racing. Naturally, it is common to demonstrate the advantages of these new controllers against established methods like analytical controllers. We observe, however, that reliably comparing the performance of such very different classes of controllers is more complicated than might appear at first sight. As a case study, we take up the problem of agile tracking of an end-effector for a quadrotor with a fixed arm. We develop a set of best practices for synthesizing the best-in-class RL and geometric controllers (GC) for benchmarking. In the process, we resolve widespread RL-favoring biases in prior studies that provide asymmetric access to: (1) the task definition, in the form of an objective function, (2) representative datasets, for parameter optimization, and (3) feedforward information, describing the desired future trajectory. The resulting findings are the following: our improvements to the experimental protocol for comparing learned and classical controllers are critical, and each of the above asymmetries can yield misleading conclusions. Prior works have claimed that RL outperforms GC, but we find the gaps between the two controller classes are much smaller than previously published when accounting for symmetric comparisons. Geometric control achieves lower steady-state error than RL, while RL has better transient performance, resulting in GC performing better in relatively slow or less agile tasks, but RL performing better when greater agility is required. Finally, we open-source implementations of geometric and RL controllers for these aerial vehicles, implementing best practices for future development. Website and code is available at https://pratikkunapuli.github.io/rl-vs-gc/</p></details> | <details><summary>Accep...</summary><p>Accepted for publication to RSS 2025. 10 pages, 5 figures. Project website: https://pratikkunapuli.github.io/rl-vs-gc/</p></details> |
| **[Trajectory Prediction for Autonomous Driving: Progress, Limitations, and Future Directions](http://arxiv.org/abs/2503.03262v2)** | 2025-06-21 | [papers-cool](https://papers.cool/arxiv/2503.03262v2) | <details><summary>Show</summary><p>As the potential for autonomous vehicles to be integrated on a large scale into modern traffic systems continues to grow, ensuring safe navigation in dynamic environments is crucial for smooth integration. To guarantee safety and prevent collisions, autonomous vehicles must be capable of accurately predicting the trajectories of surrounding traffic agents. Over the past decade, significant efforts from both academia and industry have been dedicated to designing solutions for precise trajectory forecasting. These efforts have produced a diverse range of approaches, raising questions about the differences between these methods and whether trajectory prediction challenges have been fully addressed. This paper reviews a substantial portion of recent trajectory prediction methods proposing a taxonomy to classify existing solutions. A general overview of the prediction pipeline is also provided, covering input and output modalities, modeling features, and prediction paradigms existing in the literature. In addition, the paper discusses active research areas within trajectory prediction, addresses the posed research questions, and highlights the remaining research gaps and challenges.</p></details> |  |
| **[Physics-informed mixture of experts network for interpretable battery degradation trajectory computation amid second-life complexities](http://arxiv.org/abs/2506.17755v1)** | 2025-06-21 | [papers-cool](https://papers.cool/arxiv/2506.17755v1) | <details><summary>Show</summary><p>Retired electric vehicle batteries offer immense potential to support low-carbon energy systems, but uncertainties in their degradation behavior and data inaccessibilities under second-life use pose major barriers to safe and scalable deployment. This work proposes a Physics-Informed Mixture of Experts (PIMOE) network that computes battery degradation trajectories using partial, field-accessible signals in a single cycle. PIMOE leverages an adaptive multi-degradation prediction module to classify degradation modes using expert weight synthesis underpinned by capacity-voltage and relaxation data, producing latent degradation trend embeddings. These are input to a use-dependent recurrent network for long-term trajectory prediction. Validated on 207 batteries across 77 use conditions and 67,902 cycles, PIMOE achieves an average mean absolute percentage (MAPE) errors of 0.88% with a 0.43 ms inference time. Compared to the state-of-the-art Informer and PatchTST, it reduces computational time and MAPE by 50%, respectively. Compatible with random state of charge region sampling, PIMOE supports 150-cycle forecasts with 1.50% average and 6.26% maximum MAPE, and operates effectively even with pruned 5MB training data. Broadly, PIMOE framework offers a deployable, history-free solution for battery degradation trajectory computation, redefining how second-life energy storage systems are assessed, optimized, and integrated into the sustainable energy landscape.</p></details> |  |
| **[Trajectory tracking control of USV with actuator constraints in the presence of disturbances](http://arxiv.org/abs/2506.17005v1)** | 2025-06-20 | [papers-cool](https://papers.cool/arxiv/2506.17005v1) | <details><summary>Show</summary><p>All practical systems often pose a problem of finite control capability, which can notably degrade the performance if not properly addressed. Since actuator input bounds are typically known, integrating actuator saturation considerations into the control law design process can lead to enhanced performance and more precise trajectory tracking. Also, the actuators cannot provide the demanded forces or torques instantaneously; hence, there is a limitation on the rate of magnitude. This work proposes nonlinear feedback controller designs developed using the Lyapunov stability and backstepping method while actively considering the actuator magnitude and rate constraints. The system dynamics are augmented with a smooth control input saturation model. Additionally, an observer is incorporated to estimate the disturbance vector. Through Lyapunov stability analysis, we demonstrate the system's stability under the proposed controller for the Uncrewed Surface Vessel (USV), ensuring adherence to actuator constraints provided their initial values fall within the prescribed bounds. Extensive numerical simulations performed by considering various trajectories and multiple initial conditions demonstrate the effectiveness of the controller in maintaining tracking performance without violating actuator constraints. This work also relaxes the assumption of equally capable actuators to be used to control the motion of USVs, affirming the viability of the controller in practical applications.</p></details> |  |
| **[TrajSceneLLM: A Multimodal Perspective on Semantic GPS Trajectory Analysis](http://arxiv.org/abs/2506.16401v1)** | 2025-06-19 | [papers-cool](https://papers.cool/arxiv/2506.16401v1) | <details><summary>Show</summary><p>GPS trajectory data reveals valuable patterns of human mobility and urban dynamics, supporting a variety of spatial applications. However, traditional methods often struggle to extract deep semantic representations and incorporate contextual map information. We propose TrajSceneLLM, a multimodal perspective for enhancing semantic understanding of GPS trajectories. The framework integrates visualized map images (encoding spatial context) and textual descriptions generated through LLM reasoning (capturing temporal sequences and movement dynamics). Separate embeddings are generated for each modality and then concatenated to produce trajectory scene embeddings with rich semantic content which are further paired with a simple MLP classifier. We validate the proposed framework on Travel Mode Identification (TMI), a critical task for analyzing travel choices and understanding mobility behavior. Our experiments show that these embeddings achieve significant performance improvement, highlighting the advantage of our LLM-driven method in capturing deep spatio-temporal dependencies and reducing reliance on handcrafted features. This semantic enhancement promises significant potential for diverse downstream applications and future research in geospatial artificial intelligence. The source code and dataset are publicly available at: https://github.com/februarysea/TrajSceneLLM.</p></details> | <details><summary>Under...</summary><p>Under review for ACM SIGSPATIAL 2025</p></details> |
| **[VideoGAN-based Trajectory Proposal for Automated Vehicles](http://arxiv.org/abs/2506.16209v1)** | 2025-06-19 | [papers-cool](https://papers.cool/arxiv/2506.16209v1) | <details><summary>Show</summary><p>Being able to generate realistic trajectory options is at the core of increasing the degree of automation of road vehicles. While model-driven, rule-based, and classical learning-based methods are widely used to tackle these tasks at present, they can struggle to effectively capture the complex, multimodal distributions of future trajectories. In this paper we investigate whether a generative adversarial network (GAN) trained on videos of bird's-eye view (BEV) traffic scenarios can generate statistically accurate trajectories that correctly capture spatial relationships between the agents. To this end, we propose a pipeline that uses low-resolution BEV occupancy grid videos as training data for a video generative model. From the generated videos of traffic scenarios we extract abstract trajectory data using single-frame object detection and frame-to-frame object matching. We particularly choose a GAN architecture for the fast training and inference times with respect to diffusion models. We obtain our best results within 100 GPU hours of training, with inference times under 20\,ms. We demonstrate the physical realism of the proposed trajectories in terms of distribution alignment of spatial and dynamic parameters with respect to the ground truth videos from the Waymo Open Motion Dataset.</p></details> |  |
| **[Enhanced Trust Region Sequential Convex Optimization for Multi-Drone Thermal Screening Trajectory Planning in Urban Environments](http://arxiv.org/abs/2506.06012v2)** | 2025-06-19 | [papers-cool](https://papers.cool/arxiv/2506.06012v2) | <details><summary>Show</summary><p>The rapid detection of abnormal body temperatures in urban populations is essential for managing public health risks, especially during outbreaks of infectious diseases. Multi-drone thermal screening systems offer promising solutions for fast, large-scale, and non-intrusive human temperature monitoring. However, trajectory planning for multiple drones in complex urban environments poses significant challenges, including collision avoidance, coverage efficiency, and constrained flight environments. In this study, we propose an enhanced trust region sequential convex optimization (TR-SCO) algorithm for optimal trajectory planning of multiple drones performing thermal screening tasks. Our improved algorithm integrates a refined convex optimization formulation within a trust region framework, effectively balancing trajectory smoothness, obstacle avoidance, altitude constraints, and maximum screening coverage. Simulation results demonstrate that our approach significantly improves trajectory optimality and computational efficiency compared to conventional convex optimization methods. This research provides critical insights and practical contributions toward deploying efficient multi-drone systems for real-time thermal screening in urban areas. For reader who are interested in our research, we release our source code at https://github.com/Cherry0302/Enhanced-TR-SCO.</p></details> |  |
| **[Autonomous Trajectory Optimization for UAVs in Disaster Zone Using Henry Gas Optimization Scheme](http://arxiv.org/abs/2506.15910v1)** | 2025-06-18 | [papers-cool](https://papers.cool/arxiv/2506.15910v1) | <details><summary>Show</summary><p>The unmanned aerial vehicles (UAVs) in a disaster-prone environment plays important role in assisting the rescue services and providing the internet connectivity with the outside world. However, in such a complex environment the selection of optimum trajectory of UAVs is of utmost importance. UAV trajectory optimization deals with finding the shortest path in the minimal possible time. In this paper, a cluster optimization scheme (COS) is proposed using the Henry gas optimization (HGO) metaheuristic algorithm to identify the shortest path having minimal transportation cost and algorithm complexity. The mathematical model is designed for COS using the HGO algorithm and compared with the state-of-the-art metaheuristic algorithms such as particle swarm optimization (PSO), grey wolf optimization (GWO), cuckoo search algorithm (CSA) and barnacles mating optimizer (BMO). In order to prove the robustness of the proposed model, four different scenarios are evaluated that includes ambient environment, constrict environment, tangled environment, and complex environment. In all the aforementioned scenarios, the HGO algorithm outperforms the existing algorithms. Particularly, in the ambient environment, the HGO algorithm achieves a 39.3% reduction in transportation cost and a 16.8% reduction in computational time as compared to the PSO algorithm. Hence, the HGO algorithm can be used for autonomous trajectory optimization of UAVs in smart cities.</p></details> | 12 pages, 9 figuers |
| **[TrajDiff: Diffusion Bridge Network with Semantic Alignment for Trajectory Similarity Computation](http://arxiv.org/abs/2506.15898v1)** | 2025-06-18 | [papers-cool](https://papers.cool/arxiv/2506.15898v1) | <details><summary>Show</summary><p>With the proliferation of location-tracking technologies, massive volumes of trajectory data are continuously being collected. As a fundamental task in trajectory data mining, trajectory similarity computation plays a critical role in a wide range of real-world applications. However, existing learning-based methods face three challenges: First, they ignore the semantic gap between GPS and grid features in trajectories, making it difficult to obtain meaningful trajectory embeddings. Second, the noise inherent in the trajectories, as well as the noise introduced during grid discretization, obscures the true motion patterns of the trajectories. Third, existing methods focus solely on point-wise and pair-wise losses, without utilizing the global ranking information obtained by sorting all trajectories according to their similarity to a given trajectory. To address the aforementioned challenges, we propose a novel trajectory similarity computation framework, named TrajDiff. Specifically, the semantic alignment module relies on cross-attention and an attention score mask mechanism with adaptive fusion, effectively eliminating semantic discrepancies between data at two scales and generating a unified representation. Additionally, the DDBM-based Noise-robust Pre-Training introduces the transfer patterns between any two trajectories into the model training process, enhancing the model's noise robustness. Finally, the overall ranking-aware regularization shifts the model's focus from a local to a global perspective, enabling it to capture the holistic ordering information among trajectories. Extensive experiments on three publicly available datasets show that TrajDiff consistently outperforms state-of-the-art baselines. In particular, it achieves an average HR@1 gain of 33.38% across all three evaluation metrics and datasets.</p></details> |  |
| **[MENSA: A Multi-Event Network for Survival Analysis with Trajectory-based Likelihood Estimation](http://arxiv.org/abs/2409.06525v3)** | 2025-06-18 | [papers-cool](https://papers.cool/arxiv/2409.06525v3) | <details><summary>Show</summary><p>We introduce MENSA, a novel deep learning model for multi-event survival analysis, which predicts the time until an instance experiences multiple distinct events based on its features. MENSA learns a shared representation of the input features while capturing the complex dependence structures between events. In practice, it optimizes the sum of the traditional negative log-likelihood across events and a novel trajectory-based likelihood, which encourages the model to learn the temporal order in which events occur. Experiments on real-world clinical datasets demonstrate that MENSA improves risk and time-to-event prediction compared to state-of-the-art models across single-event, competing-risk, and multi-event settings. Moreover, MENSA achieves this with fewer parameters and lower computational cost (FLOPs) than several deep learning baselines, particularly in high-dimensional feature spaces (more than 100 features).</p></details> |  |
| **[Probabilistic Trajectory GOSPA: A Metric for Uncertainty-Aware Multi-Object Tracking Performance Evaluation](http://arxiv.org/abs/2506.15148v1)** | 2025-06-18 | [papers-cool](https://papers.cool/arxiv/2506.15148v1) | <details><summary>Show</summary><p>This paper presents a generalization of the trajectory general optimal sub-pattern assignment (GOSPA) metric for evaluating multi-object tracking algorithms that provide trajectory estimates with track-level uncertainties. This metric builds on the recently introduced probabilistic GOSPA metric to account for both the existence and state estimation uncertainties of individual object states. Similar to trajectory GOSPA (TGOSPA), it can be formulated as a multidimensional assignment problem, and its linear programming relaxation--also a valid metric--is computable in polynomial time. Additionally, this metric retains the interpretability of TGOSPA, and we show that its decomposition yields intuitive costs terms associated to expected localization error and existence probability mismatch error for properly detected objects, expected missed and false detection error, and track switch error. The effectiveness of the proposed metric is demonstrated through a simulation study.</p></details> | 7 pages, 4 figures |
| **[Joint UAV Trajectory Planning and LEO Satellite Selection for Data Offloading in Space-Air-Ground Integrated Networks](http://arxiv.org/abs/2506.12750v2)** | 2025-06-18 | [papers-cool](https://papers.cool/arxiv/2506.12750v2) | <details><summary>Show</summary><p>With the development of low earth orbit (LEO) satellites and unmanned aerial vehicles (UAVs), the space-air-ground integrated network (SAGIN) becomes a major trend in the next-generation networks. However, due to the instability of heterogeneous communication and time-varying characteristics of SAGIN, it is challenging to meet the remote Internet of Things (IoT) demands for data collection and offloading. In this paper, we investigate a two-phase hierarchical data uplink model in SAGIN. Specifically, UAVs optimize trajectories to enable efficient data collection from IoT devices, and then they transmit the data to LEO satellites with computing capabilities for further processing. The problem is formulated to minimize the total energy consumption for IoT devices, UAVs, and LEO satellites. Since the problem is in the form of mixed-integer nonlinear programming and intractable to solve directly, we decompose it into two phases. In the IoT-UAV phase, we design the algorithm to jointly optimize the IoT pairing, power allocation, and UAVs trajectories. Considering the high dynamic characteristics of LEO satellites, a real-time LEO satellite selection mechanism joint with the Satellite Tool Kit is proposed in the UAV-LEO phase. Finally, simulation results show the effectiveness of the proposed algorithms, with about 10% less energy consumption compared with the benchmark algorithm.</p></details> |  |
| **[Improved Image Reconstruction and Diffusion Parameter Estimation Using a Temporal Convolutional Network Model of Gradient Trajectory Errors](http://arxiv.org/abs/2506.14995v1)** | 2025-06-17 | [papers-cool](https://papers.cool/arxiv/2506.14995v1) | <details><summary>Show</summary><p>Summary: Errors in gradient trajectories introduce significant artifacts and distortions in magnetic resonance images, particularly in non-Cartesian imaging sequences, where imperfect gradient waveforms can greatly reduce image quality. Purpose: Our objective is to develop a general, nonlinear gradient system model that can accurately predict gradient distortions using convolutional networks. Methods: A set of training gradient waveforms were measured on a small animal imaging system, and used to train a temporal convolutional network to predict the gradient waveforms produced by the imaging system. Results: The trained network was able to accurately predict nonlinear distortions produced by the gradient system. Network prediction of gradient waveforms was incorporated into the image reconstruction pipeline and provided improvements in image quality and diffusion parameter mapping compared to both the nominal gradient waveform and the gradient impulse response function. Conclusion: Temporal convolutional networks can more accurately model gradient system behavior than existing linear methods and may be used to retrospectively correct gradient errors.</p></details> |  |
| **[FlowAlign: Trajectory-Regularized, Inversion-Free Flow-based Image Editing](http://arxiv.org/abs/2505.23145v2)** | 2025-06-17 | [papers-cool](https://papers.cool/arxiv/2505.23145v2) | <details><summary>Show</summary><p>Recent inversion-free, flow-based image editing methods such as FlowEdit leverages a pre-trained noise-to-image flow model such as Stable Diffusion 3, enabling text-driven manipulation by solving an ordinary differential equation (ODE). While the lack of exact latent inversion is a core advantage of these methods, it often results in unstable editing trajectories and poor source consistency. To address this limitation, we propose FlowAlign, a novel inversion-free flow-based framework for consistent image editing with principled trajectory control. FlowAlign introduces a flow-matching loss as a regularization mechanism to promote smoother and more stable trajectories during the editing process. Notably, the flow-matching loss is shown to explicitly balance semantic alignment with the edit prompt and structural consistency with the source image along the trajectory. Furthermore, FlowAlign naturally supports reverse editing by simply reversing the ODE trajectory, highlighting the reversible and consistent nature of the transformation. Extensive experiments demonstrate that FlowAlign outperforms existing methods in both source preservation and editing controllability.</p></details> |  |
| **[SceneAware: Scene-Constrained Pedestrian Trajectory Prediction with LLM-Guided Walkability](http://arxiv.org/abs/2506.14144v1)** | 2025-06-17 | [papers-cool](https://papers.cool/arxiv/2506.14144v1) | <details><summary>Show</summary><p>Accurate prediction of pedestrian trajectories is essential for applications in robotics and surveillance systems. While existing approaches primarily focus on social interactions between pedestrians, they often overlook the rich environmental context that significantly shapes human movement patterns. In this paper, we propose SceneAware, a novel framework that explicitly incorporates scene understanding to enhance trajectory prediction accuracy. Our method leverages a Vision Transformer~(ViT) scene encoder to process environmental context from static scene images, while Multi-modal Large Language Models~(MLLMs) generate binary walkability masks that distinguish between accessible and restricted areas during training. We combine a Transformer-based trajectory encoder with the ViT-based scene encoder, capturing both temporal dynamics and spatial constraints. The framework integrates collision penalty mechanisms that discourage predicted trajectories from violating physical boundaries, ensuring physically plausible predictions. SceneAware is implemented in both deterministic and stochastic variants. Comprehensive experiments on the ETH/UCY benchmark datasets show that our approach outperforms state-of-the-art methods, with more than 50\% improvement over previous models. Our analysis based on different trajectory categories shows that the model performs consistently well across various types of pedestrian movement. This highlights the importance of using explicit scene information and shows that our scene-aware approach is both effective and reliable in generating accurate and physically plausible predictions. Code is available at: https://github.com/juho127/SceneAware.</p></details> |  |
| **[Opt2Skill: Imitating Dynamically-feasible Whole-Body Trajectories for Versatile Humanoid Loco-Manipulation](http://arxiv.org/abs/2409.20514v5)** | 2025-06-17 | [papers-cool](https://papers.cool/arxiv/2409.20514v5) | <details><summary>Show</summary><p>Humanoid robots are designed to perform diverse loco-manipulation tasks. However, they face challenges due to their high-dimensional and unstable dynamics, as well as the complex contact-rich nature of the tasks. Model-based optimal control methods offer flexibility to define precise motion but are limited by high computational complexity and accurate contact sensing. On the other hand, reinforcement learning (RL) handles high-dimensional spaces with strong robustness but suffers from inefficient learning, unnatural motion, and sim-to-real gaps. To address these challenges, we introduce Opt2Skill, an end-to-end pipeline that combines model-based trajectory optimization with RL to achieve robust whole-body loco-manipulation. Opt2Skill generates dynamic feasible and contact-consistent reference motions for the Digit humanoid robot using differential dynamic programming (DDP) and trains RL policies to track these optimal trajectories. Our results demonstrate that Opt2Skill outperforms baselines that rely on human demonstrations and inverse kinematics-based references, both in motion tracking and task success rates. Furthermore, we show that incorporating trajectories with torque information improves contact force tracking in contact-involved tasks, such as wiping a table. We have successfully transferred our approach to real-world applications.</p></details> |  |
| **[Sequence Modeling for Time-Optimal Quadrotor Trajectory Optimization with Sampling-based Robustness Analysis](http://arxiv.org/abs/2506.13915v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13915v1) | <details><summary>Show</summary><p>Time-optimal trajectories drive quadrotors to their dynamic limits, but computing such trajectories involves solving non-convex problems via iterative nonlinear optimization, making them prohibitively costly for real-time applications. In this work, we investigate learning-based models that imitate a model-based time-optimal trajectory planner to accelerate trajectory generation. Given a dataset of collision-free geometric paths, we show that modeling architectures can effectively learn the patterns underlying time-optimal trajectories. We introduce a quantitative framework to analyze local analytic properties of the learned models, and link them to the Backward Reachable Tube of the geometric tracking controller. To enhance robustness, we propose a data augmentation scheme that applies random perturbations to the input paths. Compared to classical planners, our method achieves substantial speedups, and we validate its real-time feasibility on a hardware quadrotor platform. Experiments demonstrate that the learned models generalize to previously unseen path lengths. The code for our approach can be found here: https://github.com/maokat12/lbTOPPQuad</p></details> |  |
| **[Mixed Bernstein-Fourier Approximants for Optimal Trajectory Generation with Periodic Behavior](http://arxiv.org/abs/2504.17969v2)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2504.17969v2) | <details><summary>Show</summary><p>Efficient trajectory generation is critical for autonomous systems, yet current numerical methods often struggle to handle periodic behaviors effectively, especially when equidistant time nodes are required. This paper introduces a novel mixed Bernstein-Fourier approximation framework tailored explicitly for optimal motion planning. Our proposed methodology leverages the uniform convergence properties of Bernstein polynomials for nonperiodic behaviors while effectively capturing periodic dynamics through Fourier series. Theoretical results are established, including uniform convergence proofs for approximations of functions, derivatives, and integrals, as well as detailed error bound analyses. We further introduce a regulated least squares approach for determining approximation coefficients, enhancing numerical stability and practical applicability. Within an optimal control context, we establish feasibility and consistency of approximated solutions to their continuous counterparts. We also extend the covector mapping theorem, providing theoretical guarantees for approximating dual variables crucial in verifying the necessary optimality conditions from Pontryagin's Maximum Principle. Comprehensive numerical examples illustrate the method's superior performance, demonstrating substantial improvements in computational efficiency and precision in scenarios with complex periodic constraints and dynamics. Our mixed Bernstein-Fourier methodology thus presents a robust, theoretically grounded, and computationally efficient approach for advanced optimal trajectory planning in autonomous systems.</p></details> | 49 pages, 9 figures |
| **[Vid-CamEdit: Video Camera Trajectory Editing with Generative Rendering from Estimated Geometry](http://arxiv.org/abs/2506.13697v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13697v1) | <details><summary>Show</summary><p>We introduce Vid-CamEdit, a novel framework for video camera trajectory editing, enabling the re-synthesis of monocular videos along user-defined camera paths. This task is challenging due to its ill-posed nature and the limited multi-view video data for training. Traditional reconstruction methods struggle with extreme trajectory changes, and existing generative models for dynamic novel view synthesis cannot handle in-the-wild videos. Our approach consists of two steps: estimating temporally consistent geometry, and generative rendering guided by this geometry. By integrating geometric priors, the generative model focuses on synthesizing realistic details where the estimated geometry is uncertain. We eliminate the need for extensive 4D training data through a factorized fine-tuning framework that separately trains spatial and temporal components using multi-view image and video data. Our method outperforms baselines in producing plausible videos from novel camera trajectories, especially in extreme extrapolation scenarios on real-world footage.</p></details> | <details><summary>Our p...</summary><p>Our project page can be found at https://cvlab-kaist.github.io/Vid-CamEdit/</p></details> |
| **[High-gain model-following control for trajectory tracking](http://arxiv.org/abs/2506.13463v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13463v1) | <details><summary>Show</summary><p>We consider trajectory tracking for minimum-phase nonlinear systems in Byrnes-Isidori form using the model-following control (MFC) architecture. The tracking problem is motivated by a hierarchical control concept where a higher-level instance provides the reference trajectory at run-time. We present a computational efficient implementation of the feedback linearisation MFC design, and apply high-gain feedback in the process control loop (PCL) to achieve practical tracking in presence of Lipschitz perturbations. Our main results establish ultimate boundedness of the tracking error and give a constructive bound for the high-gain scaling parameter to achieve arbitrary tracking precision. Further we establish that the peaking phenomenon can be attenuated using MFC. We demonstrate the results via an automotive case study considering advanced engine-based cruise control.</p></details> |  |
| **[Observability-Aware Active Calibration of Multi-Sensor Extrinsics for Ground Robots via Online Trajectory Optimization](http://arxiv.org/abs/2506.13420v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13420v1) | <details><summary>Show</summary><p>Accurate calibration of sensor extrinsic parameters for ground robotic systems (i.e., relative poses) is crucial for ensuring spatial alignment and achieving high-performance perception. However, existing calibration methods typically require complex and often human-operated processes to collect data. Moreover, most frameworks neglect acoustic sensors, thereby limiting the associated systems' auditory perception capabilities. To alleviate these issues, we propose an observability-aware active calibration method for ground robots with multimodal sensors, including a microphone array, a LiDAR (exteroceptive sensors), and wheel encoders (proprioceptive sensors). Unlike traditional approaches, our method enables active trajectory optimization for online data collection and calibration, contributing to the development of more intelligent robotic systems. Specifically, we leverage the Fisher information matrix (FIM) to quantify parameter observability and adopt its minimum eigenvalue as an optimization metric for trajectory generation via B-spline curves. Through planning and replanning of robot trajectory online, the method enhances the observability of multi-sensor extrinsic parameters. The effectiveness and advantages of our method have been demonstrated through numerical simulations and real-world experiments. For the benefit of the community, we have also open-sourced our code and data at https://github.com/AISLAB-sustech/Multisensor-Calibration.</p></details> | <details><summary>Accep...</summary><p>Accepted and to appear in the IEEE Sensors Journal</p></details> |
| **[The Butterfly Effect: Neural Network Training Trajectories Are Highly Sensitive to Initial Conditions](http://arxiv.org/abs/2506.13234v1)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.13234v1) | <details><summary>Show</summary><p>Neural network training is inherently sensitive to initialization and the randomness induced by stochastic gradient descent. However, it is unclear to what extent such effects lead to meaningfully different networks, either in terms of the models' weights or the underlying functions that were learned. In this work, we show that during the initial "chaotic" phase of training, even extremely small perturbations reliably causes otherwise identical training trajectories to diverge-an effect that diminishes rapidly over training time. We quantify this divergence through (i) $L^2$ distance between parameters, (ii) the loss barrier when interpolating between networks, (iii) $L^2$ and barrier between parameters after permutation alignment, and (iv) representational similarity between intermediate activations; revealing how perturbations across different hyperparameter or fine-tuning settings drive training trajectories toward distinct loss minima. Our findings provide insights into neural network training stability, with practical implications for fine-tuning, model merging, and diversity of model ensembles.</p></details> | <details><summary>Publi...</summary><p>Published in ICML 2025. The first two authors contributed equally. 29 pages, 28 figures</p></details> |
| **[Intra-Trajectory Consistency for Reward Modeling](http://arxiv.org/abs/2506.09096v3)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2506.09096v3) | <details><summary>Show</summary><p>Reward models are critical for improving large language models (LLMs), particularly in reinforcement learning from human feedback (RLHF) or inference-time verification. Current reward modeling typically relies on scores of overall responses to learn the outcome rewards for the responses. However, since the response-level scores are coarse-grained supervision signals, the reward model struggles to identify the specific components within a response trajectory that truly correlate with the scores, leading to poor generalization on unseen responses. In this paper, we propose to leverage generation probabilities to establish reward consistency between processes in the response trajectory, which allows the response-level supervisory signal to propagate across processes, thereby providing additional fine-grained signals for reward learning. Building on analysis under the Bayesian framework, we develop an intra-trajectory consistency regularization to enforce that adjacent processes with higher next-token generation probability maintain more consistent rewards. We apply the proposed regularization to the advanced outcome reward model, improving its performance on RewardBench. Besides, we show that the reward model trained with the proposed regularization induces better DPO-aligned policies and achieves better best-of-N (BON) inference-time verification results. Our code is provided in https://github.com/chaoyang101/ICRM.</p></details> | Under review |
| **[Efficient Estimation of Relaxed Model Parameters for Robust UAV Trajectory Optimization](http://arxiv.org/abs/2411.10941v4)** | 2025-06-16 | [papers-cool](https://papers.cool/arxiv/2411.10941v4) | <details><summary>Show</summary><p>Online trajectory optimization and optimal control methods are crucial for enabling sustainable unmanned aerial vehicle (UAV) services, such as agriculture, environmental monitoring, and transportation, where available actuation and energy are limited. However, optimal controllers are highly sensitive to model mismatch, which can occur due to loaded equipment, packages to be delivered, or pre-existing variability in fundamental structural and thrust-related parameters. To circumvent this problem, optimal controllers can be paired with parameter estimators to improve their trajectory planning performance and perform adaptive control. However, UAV platforms are limited in terms of onboard processing power, oftentimes making nonlinear parameter estimation too computationally expensive to consider. To address these issues, we propose a relaxed, affine-in-parameters multirotor model along with an efficient optimal parameter estimator. We convexify the nominal Moving Horizon Parameter Estimation (MHPE) problem into a linear-quadratic form (LQ-MHPE) via an affine-in-parameter relaxation on the nonlinear dynamics, resulting in fast quadratic programs (QPs) that facilitate adaptive Model Predictve Control (MPC) in real time. We compare this approach to the equivalent nonlinear estimator in Monte Carlo simulations, demonstrating a decrease in average solve time and trajectory optimality cost by 98.2% and 23.9-56.2%, respectively.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 5 figures. Published in IEEE Sustech 2025, see https://ieeexplore.ieee.org/document/11025659</p></details> |
| **[Using iterated local alignment to aggregate trajectory data into a traffic flow map](http://arxiv.org/abs/2406.17500v5)** | 2025-06-15 | [papers-cool](https://papers.cool/arxiv/2406.17500v5) | <details><summary>Show</summary><p>Vehicle trajectories are a promising GNSS (Global Navigation Satellite System) data source to compute multi-scale traffic flow maps ranging from the city/regional level to the road level. The main obstacle is that trajectory data are prone to measurement noise. While this is negligible for city level, large-scale flow aggregation, it poses substantial difficulties for road level, small-scale aggregation. To overcome these difficulties, we introduce innovative local alignment algorithms, where we infer road segments to serve as local reference segments, and proceed to align nearby road segments to them. We deploy these algorithms in an iterative workflow to compute locally aligned flow maps. By applying this workflow to synthetic and empirical trajectories, we verify that our locally aligned flow maps provide high levels of accuracy and spatial resolution of flow aggregation at multiple scales for static and interactive maps.</p></details> |  |
| **[Constraint-Guided Prediction Refinement via Deterministic Diffusion Trajectories](http://arxiv.org/abs/2506.12911v1)** | 2025-06-15 | [papers-cool](https://papers.cool/arxiv/2506.12911v1) | <details><summary>Show</summary><p>Many real-world machine learning tasks require outputs that satisfy hard constraints, such as physical conservation laws, structured dependencies in graphs, or column-level relationships in tabular data. Existing approaches rely either on domain-specific architectures and losses or on strong assumptions on the constraint space, restricting their applicability to linear or convex constraints. We propose a general-purpose framework for constraint-aware refinement that leverages denoising diffusion implicit models (DDIMs). Starting from a coarse prediction, our method iteratively refines it through a deterministic diffusion trajectory guided by a learned prior and augmented by constraint gradient corrections. The approach accommodates a wide class of non-convex and nonlinear equality constraints and can be applied post hoc to any base model. We demonstrate the method in two representative domains: constrained adversarial attack generation on tabular data with column-level dependencies and in AC power flow prediction under Kirchhoff's laws. Across both settings, our diffusion-guided refinement improves both constraint satisfaction and performance while remaining lightweight and model-agnostic.</p></details> |  |
| **[TrojanTO: Action-Level Backdoor Attacks against Trajectory Optimization Models](http://arxiv.org/abs/2506.12815v1)** | 2025-06-15 | [papers-cool](https://papers.cool/arxiv/2506.12815v1) | <details><summary>Show</summary><p>Recent advances in Trajectory Optimization (TO) models have achieved remarkable success in offline reinforcement learning. However, their vulnerabilities against backdoor attacks are poorly understood. We find that existing backdoor attacks in reinforcement learning are based on reward manipulation, which are largely ineffective against the TO model due to its inherent sequence modeling nature. Moreover, the complexities introduced by high-dimensional action spaces further compound the challenge of action manipulation. To address these gaps, we propose TrojanTO, the first action-level backdoor attack against TO models. TrojanTO employs alternating training to enhance the connection between triggers and target actions for attack effectiveness. To improve attack stealth, it utilizes precise poisoning via trajectory filtering for normal performance and batch poisoning for trigger consistency. Extensive evaluations demonstrate that TrojanTO effectively implants backdoor attacks across diverse tasks and attack objectives with a low attack budget (0.3\% of trajectories). Furthermore, TrojanTO exhibits broad applicability to DT, GDT, and DC, underscoring its scalability across diverse TO model architectures.</p></details> | 23 pages, 6 figures |
| **[Towards Physics-informed Diffusion for Anomaly Detection in Trajectories](http://arxiv.org/abs/2506.06999v2)** | 2025-06-14 | [papers-cool](https://papers.cool/arxiv/2506.06999v2) | <details><summary>Show</summary><p>Given trajectory data, a domain-specific study area, and a user-defined threshold, we aim to find anomalous trajectories indicative of possible GPS spoofing (e.g., fake trajectory). The problem is societally important to curb illegal activities in international waters, such as unauthorized fishing and illicit oil transfers. The problem is challenging due to advances in AI generated in deep fakes generation (e.g., additive noise, fake trajectories) and lack of adequate amount of labeled samples for ground-truth verification. Recent literature shows promising results for anomalous trajectory detection using generative models despite data sparsity. However, they do not consider fine-scale spatiotemporal dependencies and prior physical knowledge, resulting in higher false-positive rates. To address these limitations, we propose a physics-informed diffusion model that integrates kinematic constraints to identify trajectories that do not adhere to physical laws. Experimental results on real-world datasets in the maritime and urban domains show that the proposed framework results in higher prediction accuracy and lower estimation error rate for anomaly detection and trajectory generation methods, respectively. Our implementation is available at https://github.com/arunshar/Physics-Informed-Diffusion-Probabilistic-Model.</p></details> |  |
| **[Generalizable Trajectory Prediction via Inverse Reinforcement Learning with Mamba-Graph Architecture](http://arxiv.org/abs/2506.12474v1)** | 2025-06-14 | [papers-cool](https://papers.cool/arxiv/2506.12474v1) | <details><summary>Show</summary><p>Accurate driving behavior modeling is fundamental to safe and efficient trajectory prediction, yet remains challenging in complex traffic scenarios. This paper presents a novel Inverse Reinforcement Learning (IRL) framework that captures human-like decision-making by inferring diverse reward functions, enabling robust cross-scenario adaptability. The learned reward function is utilized to maximize the likelihood of output by the encoder-decoder architecture that combines Mamba blocks for efficient long-sequence dependency modeling with graph attention networks to encode spatial interactions among traffic agents. Comprehensive evaluations on urban intersections and roundabouts demonstrate that the proposed method not only outperforms various popular approaches in prediction accuracy but also achieves 2 times higher generalization performance to unseen scenarios compared to other IRL-based method.</p></details> |  |
| **[Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review](http://arxiv.org/abs/2506.14831v1)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2506.14831v1) | <details><summary>Show</summary><p>With the emergence of powerful data-driven methods in human trajectory prediction (HTP), gaining a finer understanding of multi-agent interactions lies within hand's reach, with important implications in areas such as autonomous navigation and crowd modeling. This survey reviews some of the most recent advancements in deep learning-based multi-agent trajectory prediction, focusing on studies published between 2020 and 2024. We categorize the existing methods based on their architectural design, their input representations, and their overall prediction strategies, placing a particular emphasis on models evaluated using the ETH/UCY benchmark. Furthermore, we highlight key challenges and future research directions in the field of multi-agent HTP.</p></details> | 30 pages |
| **[Private Continuous-Time Synthetic Trajectory Generation via Mean-Field Langevin Dynamics](http://arxiv.org/abs/2506.12203v1)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2506.12203v1) | <details><summary>Show</summary><p>We provide an algorithm to privately generate continuous-time data (e.g. marginals from stochastic differential equations), which has applications in highly sensitive domains involving time-series data such as healthcare. We leverage the connections between trajectory inference and continuous-time synthetic data generation, along with a computational method based on mean-field Langevin dynamics. As discretized mean-field Langevin dynamics and noisy particle gradient descent are equivalent, DP results for noisy SGD can be applied to our setting. We provide experiments that generate realistic trajectories on a synthesized variation of hand-drawn MNIST data while maintaining meaningful privacy guarantees. Crucially, our method has strong utility guarantees under the setting where each person contributes data for \emph{only one time point}, while prior methods require each person to contribute their \emph{entire temporal trajectory}--directly improving the privacy characteristics by construction.</p></details> |  |
| **[Uncertainty-Aware Trajectory Prediction via Rule-Regularized Heteroscedastic Deep Classification](http://arxiv.org/abs/2504.13111v2)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2504.13111v2) | <details><summary>Show</summary><p>Deep learning-based trajectory prediction models have demonstrated promising capabilities in capturing complex interactions. However, their out-of-distribution generalization remains a significant challenge, particularly due to unbalanced data and a lack of enough data and diversity to ensure robustness and calibration. To address this, we propose SHIFT (Spectral Heteroscedastic Informed Forecasting for Trajectories), a novel framework that uniquely combines well-calibrated uncertainty modeling with informative priors derived through automated rule extraction. SHIFT reformulates trajectory prediction as a classification task and employs heteroscedastic spectral-normalized Gaussian processes to effectively disentangle epistemic and aleatoric uncertainties. We learn informative priors from training labels, which are automatically generated from natural language driving rules, such as stop rules and drivability constraints, using a retrieval-augmented generation framework powered by a large language model. Extensive evaluations over the nuScenes dataset, including challenging low-data and cross-location scenarios, demonstrate that SHIFT outperforms state-of-the-art methods, achieving substantial gains in uncertainty calibration and displacement metrics. In particular, our model excels in complex scenarios, such as intersections, where uncertainty is inherently higher. Project page: https://kumarmanas.github.io/SHIFT/.</p></details> | <details><summary>17 Pa...</summary><p>17 Pages, 9 figures. Accepted to Robotics: Science and Systems(RSS), 2025</p></details> |
| **[Explaining Recovery Trajectories of Older Adults Post Lower-Limb Fracture Using Modality-wise Multiview Clustering and Large Language Models](http://arxiv.org/abs/2506.12156v1)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2506.12156v1) | <details><summary>Show</summary><p>Interpreting large volumes of high-dimensional, unlabeled data in a manner that is comprehensible to humans remains a significant challenge across various domains. In unsupervised healthcare data analysis, interpreting clustered data can offer meaningful insights into patients' health outcomes, which hold direct implications for healthcare providers. This paper addresses the problem of interpreting clustered sensor data collected from older adult patients recovering from lower-limb fractures in the community. A total of 560 days of multimodal sensor data, including acceleration, step count, ambient motion, GPS location, heart rate, and sleep, alongside clinical scores, were remotely collected from patients at home. Clustering was first carried out separately for each data modality to assess the impact of feature sets extracted from each modality on patients' recovery trajectories. Then, using context-aware prompting, a large language model was employed to infer meaningful cluster labels for the clusters derived from each modality. The quality of these clusters and their corresponding labels was validated through rigorous statistical testing and visualization against clinical scores collected alongside the multimodal sensor data. The results demonstrated the statistical significance of most modality-specific cluster labels generated by the large language model with respect to clinical scores, confirming the efficacy of the proposed method for interpreting sensor data in an unsupervised manner. This unsupervised data analysis approach, relying solely on sensor data, enables clinicians to identify at-risk patients and take timely measures to improve health outcomes.</p></details> | <details><summary>15 pa...</summary><p>15 pages, 2 figures, 3 tables</p></details> |
| **[Graph-Based Floor Separation Using Node Embeddings and Clustering of WiFi Trajectories](http://arxiv.org/abs/2505.08088v2)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2505.08088v2) | <details><summary>Show</summary><p>Indoor positioning systems (IPSs) are increasingly vital for location-based services in complex multi-storey environments. This study proposes a novel graph-based approach for floor separation using Wi-Fi fingerprint trajectories, addressing the challenge of vertical localization in indoor settings. We construct a graph where nodes represent Wi-Fi fingerprints, and edges are weighted by signal similarity and contextual transitions. Node2Vec is employed to generate low-dimensional embeddings, which are subsequently clustered using K-means to identify distinct floors. Evaluated on the Huawei University Challenge 2021 dataset, our method outperforms traditional community detection algorithms, achieving an accuracy of 68.97\%, an F1-score of 61.99\%, and an Adjusted Rand Index of 57.19\%. By publicly releasing the preprocessed dataset and implementation code, this work contributes to advancing research in indoor positioning. The proposed approach demonstrates robustness to signal noise and architectural complexities, offering a scalable solution for floor-level localization.</p></details> |  |
| **[TrajAgent: An LLM-based Agent Framework for Automated Trajectory Modeling via Collaboration of Large and Small Models](http://arxiv.org/abs/2410.20445v3)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2410.20445v3) | <details><summary>Show</summary><p>Trajectory modeling, which includes research on trajectory data pattern mining and future prediction, has widespread applications in areas such as life services, urban transportation, and public administration. Numerous methods have been proposed to address specific problems within trajectory modeling. However, the heterogeneity of data and the diversity of trajectory tasks make effective and reliable trajectory modeling an important yet highly challenging endeavor, even for domain experts. In this paper, we propose \textit{TrajAgent}, a agent framework powered by large language models (LLMs), designed to facilitate robust and efficient trajectory modeling through automation modeling. This framework leverages and optimizes diverse specialized models to address various trajectory modeling tasks across different datasets effectively. In \textit{TrajAgent}, we first develop \textit{UniEnv}, an execution environment with a unified data and model interface, to support the execution and training of various models. Building on \textit{UniEnv}, we introduce an agentic workflow designed for automatic trajectory modeling across various trajectory tasks and data. Furthermore, we introduce collaborative learning schema between LLM-based agents and small speciallized models, to enhance the performance of the whole framework effectively. Extensive experiments on four tasks using four real-world datasets demonstrate the effectiveness of \textit{TrajAgent} in automated trajectory modeling, achieving a performance improvement of 2.38\%-34.96\% over baseline methods.</p></details> | <details><summary>the c...</summary><p>the code will be openly accessible at: https://github.com/tsinghua-fib-lab/TrajAgent</p></details> |
| **[DiffTORI: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning](http://arxiv.org/abs/2402.05421v5)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2402.05421v5) | <details><summary>Show</summary><p>This paper introduces DiffTORI, which utilizes Differentiable Trajectory Optimization as the policy representation to generate actions for deep Reinforcement and Imitation learning. Trajectory optimization is a powerful and widely used algorithm in control, parameterized by a cost and a dynamics function. The key to our approach is to leverage the recent progress in differentiable trajectory optimization, which enables computing the gradients of the loss with respect to the parameters of trajectory optimization. As a result, the cost and dynamics functions of trajectory optimization can be learned end-to-end. DiffTORI addresses the ``objective mismatch'' issue of prior model-based RL algorithms, as the dynamics model in DiffTORI is learned to directly maximize task performance by differentiating the policy gradient loss through the trajectory optimization process. We further benchmark DiffTORI for imitation learning on standard robotic manipulation task suites with high-dimensional sensory observations and compare our method to feed-forward policy classes as well as Energy-Based Models (EBM) and Diffusion. Across 15 model-based RL tasks and 35 imitation learning tasks with high-dimensional image and point cloud inputs, DiffTORI outperforms prior state-of-the-art methods in both domains. Our code is available at https://github.com/wkwan7/DiffTORI.</p></details> | <details><summary>NeurI...</summary><p>NeurIPS 2024 (Spotlight)</p></details> |
| **[Generalization Bound of Gradient Flow through Training Trajectory and Data-dependent Kernel](http://arxiv.org/abs/2506.11357v1)** | 2025-06-12 | [papers-cool](https://papers.cool/arxiv/2506.11357v1) | <details><summary>Show</summary><p>Gradient-based optimization methods have shown remarkable empirical success, yet their theoretical generalization properties remain only partially understood. In this paper, we establish a generalization bound for gradient flow that aligns with the classical Rademacher complexity bounds for kernel methods-specifically those based on the RKHS norm and kernel trace-through a data-dependent kernel called the loss path kernel (LPK). Unlike static kernels such as NTK, the LPK captures the entire training trajectory, adapting to both data and optimization dynamics, leading to tighter and more informative generalization guarantees. Moreover, the bound highlights how the norm of the training loss gradients along the optimization trajectory influences the final generalization performance. The key technical ingredients in our proof combine stability analysis of gradient flow with uniform convergence via Rademacher complexity. Our bound recovers existing kernel regression bounds for overparameterized neural networks and shows the feature learning capability of neural networks compared to kernel methods. Numerical experiments on real-world datasets validate that our bounds correlate well with the true generalization gap.</p></details> |  |
| **[Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving](http://arxiv.org/abs/2506.11234v1)** | 2025-06-12 | [papers-cool](https://papers.cool/arxiv/2506.11234v1) | <details><summary>Show</summary><p>We present Poutine, a 3B-parameter vision-language model (VLM) tailored for end-to-end autonomous driving in long-tail driving scenarios. Poutine is trained in two stages. To obtain strong base driving capabilities, we train Poutine-Base in a self-supervised vision-language-trajectory (VLT) next-token prediction fashion on 83 hours of CoVLA nominal driving and 11 hours of Waymo long-tail driving. Accompanying language annotations are auto-generated with a 72B-parameter VLM. Poutine is obtained by fine-tuning Poutine-Base with Group Relative Policy Optimization (GRPO) using less than 500 preference-labeled frames from the Waymo validation set. We show that both VLT pretraining and RL fine-tuning are critical to attain strong driving performance in the long-tail. Poutine-Base achieves a rater-feedback score (RFS) of 8.12 on the validation set, nearly matching Waymo's expert ground-truth RFS. The final Poutine model achieves an RFS of 7.99 on the official Waymo test set, placing 1st in the 2025 Waymo Vision-Based End-to-End Driving Challenge by a significant margin. These results highlight the promise of scalable VLT pre-training and lightweight RL fine-tuning to enable robust and generalizable autonomy.</p></details> |  |
| **[Improved error bounds for Koopman operator and reconstructed trajectories approximations with kernel-based methods](http://arxiv.org/abs/2506.09266v2)** | 2025-06-12 | [papers-cool](https://papers.cool/arxiv/2506.09266v2) | <details><summary>Show</summary><p>In this article, we propose a new error bound for Koopman operator approximation using Kernel Extended Dynamic Mode Decomposition. The new estimate is $O(N^{-1/2})$, with a constant related to the probability of success of the bound, given by Hoeffding's inequality, similar to other methodologies, such as Philipp et al. Furthermore, we propose a \textit{lifting back} operator to obtain trajectories generated by embedding the initial state and iterating a linear system in a higher dimension. This naturally yields an $O(N^{-1/2})$ error bound for mean trajectories. Finally, we show numerical results including an example of nonlinear system, exhibiting successful approximation with exponential decay faster than $-1/2$, as suggested by the theoretical results.</p></details> | 24 pages, 6 figures |
| **[A composition of simplified physics-based model with neural operator for trajectory-level seismic response predictions of structural systems](http://arxiv.org/abs/2506.10569v1)** | 2025-06-12 | [papers-cool](https://papers.cool/arxiv/2506.10569v1) | <details><summary>Show</summary><p>Accurate prediction of nonlinear structural responses is essential for earthquake risk assessment and management. While high-fidelity nonlinear time history analysis provides the most comprehensive and accurate representation of the responses, it becomes computationally prohibitive for complex structural system models and repeated simulations under varying ground motions. To address this challenge, we propose a composite learning framework that integrates simplified physics-based models with a Fourier neural operator to enable efficient and accurate trajectory-level seismic response prediction. In the proposed architecture, a simplified physics-based model, obtained from techniques such as linearization, modal reduction, or solver relaxation, serves as a preprocessing operator to generate structural response trajectories that capture coarse dynamic characteristics. A neural operator is then trained to correct the discrepancy between these initial approximations and the true nonlinear responses, allowing the composite model to capture hysteretic and path-dependent behaviors. Additionally, a linear regression-based postprocessing scheme is introduced to further refine predictions and quantify associated uncertainty with negligible additional computational effort. The proposed approach is validated on three representative structural systems subjected to synthetic or recorded ground motions. Results show that the proposed approach consistently improves prediction accuracy over baseline models, particularly in data-scarce regimes. These findings demonstrate the potential of physics-guided operator learning for reliable and data-efficient modeling of nonlinear structural seismic responses.</p></details> |  |
| **[Policy-Based Trajectory Clustering in Offline Reinforcement Learning](http://arxiv.org/abs/2506.09202v2)** | 2025-06-12 | [papers-cool](https://papers.cool/arxiv/2506.09202v2) | <details><summary>Show</summary><p>We introduce a novel task of clustering trajectories from offline reinforcement learning (RL) datasets, where each cluster center represents the policy that generated its trajectories. By leveraging the connection between the KL-divergence of offline trajectory distributions and a mixture of policy-induced distributions, we formulate a natural clustering objective. To solve this, we propose Policy-Guided K-means (PG-Kmeans) and Centroid-Attracted Autoencoder (CAAE). PG-Kmeans iteratively trains behavior cloning (BC) policies and assigns trajectories based on policy generation probabilities, while CAAE resembles the VQ-VAE framework by guiding the latent representations of trajectories toward the vicinity of specific codebook entries to achieve clustering. Theoretically, we prove the finite-step convergence of PG-Kmeans and identify a key challenge in offline trajectory clustering: the inherent ambiguity of optimal solutions due to policy-induced conflicts, which can result in multiple equally valid but structurally distinct clusterings. Experimentally, we validate our methods on the widely used D4RL dataset and custom GridWorld environments. Our results show that both PG-Kmeans and CAAE effectively partition trajectories into meaningful clusters. They offer a promising framework for policy-based trajectory clustering, with broad applications in offline RL and beyond.</p></details> |  |
| **[Chain-of-Action: Trajectory Autoregressive Modeling for Robotic Manipulation](http://arxiv.org/abs/2506.09990v1)** | 2025-06-11 | [papers-cool](https://papers.cool/arxiv/2506.09990v1) | <details><summary>Show</summary><p>We present Chain-of-Action (CoA), a novel visuo-motor policy paradigm built upon Trajectory Autoregressive Modeling. Unlike conventional approaches that predict next step action(s) forward, CoA generates an entire trajectory by explicit backward reasoning with task-specific goals through an action-level Chain-of-Thought (CoT) process. This process is unified within a single autoregressive structure: (1) the first token corresponds to a stable keyframe action that encodes the task-specific goals; and (2) subsequent action tokens are generated autoregressively, conditioned on the initial keyframe and previously predicted actions. This backward action reasoning enforces a global-to-local structure, allowing each local action to be tightly constrained by the final goal. To further realize the action reasoning structure, CoA incorporates four complementary designs: continuous action token representation; dynamic stopping for variable-length trajectory generation; reverse temporal ensemble; and multi-token prediction to balance action chunk modeling with global structure. As a result, CoA gives strong spatial generalization capabilities while preserving the flexibility and simplicity of a visuo-motor policy. Empirically, we observe CoA achieves the state-of-the-art performance across 60 RLBench tasks and 8 real-world manipulation tasks.</p></details> |  |
| **[ECAM: A Contrastive Learning Approach to Avoid Environmental Collision in Trajectory Forecasting](http://arxiv.org/abs/2506.09626v1)** | 2025-06-11 | [papers-cool](https://papers.cool/arxiv/2506.09626v1) | <details><summary>Show</summary><p>Human trajectory forecasting is crucial in applications such as autonomous driving, robotics and surveillance. Accurate forecasting requires models to consider various factors, including social interactions, multi-modal predictions, pedestrian intention and environmental context. While existing methods account for these factors, they often overlook the impact of the environment, which leads to collisions with obstacles. This paper introduces ECAM (Environmental Collision Avoidance Module), a contrastive learning-based module to enhance collision avoidance ability with the environment. The proposed module can be integrated into existing trajectory forecasting models, improving their ability to generate collision-free predictions. We evaluate our method on the ETH/UCY dataset and quantitatively and qualitatively demonstrate its collision avoidance capabilities. Our experiments show that state-of-the-art methods significantly reduce (-40/50%) the collision rate when integrated with the proposed module. The code is available at https://github.com/CVML-CFU/ECAM.</p></details> | IJCNN 2025 |
| **[Design and Validation of an Intention-Aware Probabilistic Framework for Trajectory Prediction: Integrating COLREGS, Grounding Hazards, and Planned Routes](http://arxiv.org/abs/2504.00731v2)** | 2025-06-11 | [papers-cool](https://papers.cool/arxiv/2504.00731v2) | <details><summary>Show</summary><p>Collision avoidance capability is an essential component in an autonomous vessel navigation system. To this end, an accurate prediction of dynamic obstacle trajectories is vital. Traditional approaches to trajectory prediction face limitations in generalizability and often fail to account for the intentions of other vessels. While recent research has considered incorporating the intentions of dynamic obstacles, these efforts are typically based on the own-ship's interpretation of the situation. The current state-of-the-art in this area is a Dynamic Bayesian Network (DBN) model, which infers target vessel intentions by considering multiple underlying causes and allowing for different interpretations of the situation by different vessels. However, since its inception, there have not been any significant structural improvements to this model. In this paper, we propose enhancing the DBN model by incorporating considerations for grounding hazards and vessel waypoint information. The proposed model is validated using real vessel encounters extracted from historical Automatic Identification System (AIS) data.</p></details> | <details><summary>IMPOR...</summary><p>IMPORTANT: This preprint is not the final version. The peer-reviewed and updated version is published in Ocean Engineering journal [https://doi.org/10.1016/j.oceaneng.2025.121564]</p></details> |
| **[TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization](http://arxiv.org/abs/2506.08440v2)** | 2025-06-11 | [papers-cool](https://papers.cool/arxiv/2506.08440v2) | <details><summary>Show</summary><p>Recent advances in Vision-Language-Action (VLA) model have demonstrated strong generalization capabilities across diverse scenes, tasks, and robotic platforms when pretrained at large-scale datasets. However, these models still require task-specific fine-tuning in novel environments, a process that relies almost exclusively on supervised fine-tuning (SFT) using static trajectory datasets. Such approaches neither allow robot to interact with environment nor do they leverage feedback from live execution. Also, their success is critically dependent on the size and quality of the collected trajectories. Reinforcement learning (RL) offers a promising alternative by enabling closed-loop interaction and aligning learned policies directly with task objectives. In this work, we draw inspiration from the ideas of GRPO and propose the Trajectory-wise Group Relative Policy Optimization (TGRPO) method. By fusing step-level and trajectory-level advantage signals, this method improves GRPO's group-level advantage estimation, thereby making the algorithm more suitable for online reinforcement learning training of VLA. Experimental results on ten manipulation tasks from the libero-object benchmark demonstrate that TGRPO consistently outperforms various baseline methods, capable of generating more robust and efficient policies across multiple tested scenarios. Our source codes are available at: https://github.com/hahans/TGRPO</p></details> |  |
| **[What is the Cost of Differential Privacy for Deep Learning-Based Trajectory Generation?](http://arxiv.org/abs/2506.09312v1)** | 2025-06-11 | [papers-cool](https://papers.cool/arxiv/2506.09312v1) | <details><summary>Show</summary><p>While location trajectories offer valuable insights, they also reveal sensitive personal information. Differential Privacy (DP) offers formal protection, but achieving a favourable utility-privacy trade-off remains challenging. Recent works explore deep learning-based generative models to produce synthetic trajectories. However, current models lack formal privacy guarantees and rely on conditional information derived from real data during generation. This work investigates the utility cost of enforcing DP in such models, addressing three research questions across two datasets and eleven utility metrics. (1) We evaluate how DP-SGD, the standard DP training method for deep learning, affects the utility of state-of-the-art generative models. (2) Since DP-SGD is limited to unconditional models, we propose a novel DP mechanism for conditional generation that provides formal guarantees and assess its impact on utility. (3) We analyse how model types - Diffusion, VAE, and GAN - affect the utility-privacy trade-off. Our results show that DP-SGD significantly impacts performance, although some utility remains if the datasets is sufficiently large. The proposed DP mechanism improves training stability, particularly when combined with DP-SGD, for unstable models such as GANs and on smaller datasets. Diffusion models yield the best utility without guarantees, but with DP-SGD, GANs perform best, indicating that the best non-private model is not necessarily optimal when targeting formal guarantees. In conclusion, DP trajectory generation remains a challenging task, and formal guarantees are currently only feasible with large datasets and in constrained use cases.</p></details> |  |
| **[Evaluating Generative Vehicle Trajectory Models for Traffic Intersection Dynamics](http://arxiv.org/abs/2506.08963v1)** | 2025-06-10 | [papers-cool](https://papers.cool/arxiv/2506.08963v1) | <details><summary>Show</summary><p>Traffic Intersections are vital to urban road networks as they regulate the movement of people and goods. However, they are regions of conflicting trajectories and are prone to accidents. Deep Generative models of traffic dynamics at signalized intersections can greatly help traffic authorities better understand the efficiency and safety aspects. At present, models are evaluated on computational metrics that primarily look at trajectory reconstruction errors. They are not evaluated online in a `live' microsimulation scenario. Further, these metrics do not adequately consider traffic engineering-specific concerns such as red-light violations, unallowed stoppage, etc. In this work, we provide a comprehensive analytics tool to train, run, and evaluate models with metrics that give better insights into model performance from a traffic engineering point of view. We train a state-of-the-art multi-vehicle trajectory forecasting model on a large dataset collected by running a calibrated scenario of a real-world urban intersection. We then evaluate the performance of the prediction models, online in a microsimulator, under unseen traffic conditions. We show that despite using ideally-behaved trajectories as input, and achieving low trajectory reconstruction errors, the generated trajectories show behaviors that break traffic rules. We introduce new metrics to evaluate such undesired behaviors and present our results.</p></details> |  |
| **[IntTrajSim: Trajectory Prediction for Simulating Multi-Vehicle driving at Signalized Intersections](http://arxiv.org/abs/2506.08957v1)** | 2025-06-10 | [papers-cool](https://papers.cool/arxiv/2506.08957v1) | <details><summary>Show</summary><p>Traffic simulators are widely used to study the operational efficiency of road infrastructure, but their rule-based approach limits their ability to mimic real-world driving behavior. Traffic intersections are critical components of the road infrastructure, both in terms of safety risk (nearly 28% of fatal crashes and 58% of nonfatal crashes happen at intersections) as well as the operational efficiency of a road corridor. This raises an important question: can we create a data-driven simulator that can mimic the macro- and micro-statistics of the driving behavior at a traffic intersection? Deep Generative Modeling-based trajectory prediction models provide a good starting point to model the complex dynamics of vehicles at an intersection. But they are not tested in a "live" micro-simulation scenario and are not evaluated on traffic engineering-related metrics. In this study, we propose traffic engineering-related metrics to evaluate generative trajectory prediction models and provide a simulation-in-the-loop pipeline to do so. We also provide a multi-headed self-attention-based trajectory prediction model that incorporates the signal information, which outperforms our previous models on the evaluation metrics.</p></details> |  |
| **[TraGraph-GS: Trajectory Graph-based Gaussian Splatting for Arbitrary Large-Scale Scene Rendering](http://arxiv.org/abs/2506.08704v1)** | 2025-06-10 | [papers-cool](https://papers.cool/arxiv/2506.08704v1) | <details><summary>Show</summary><p>High-quality novel view synthesis for large-scale scenes presents a challenging dilemma in 3D computer vision. Existing methods typically partition large scenes into multiple regions, reconstruct a 3D representation using Gaussian splatting for each region, and eventually merge them for novel view rendering. They can accurately render specific scenes, yet they do not generalize effectively for two reasons: (1) rigid spatial partition techniques struggle with arbitrary camera trajectories, and (2) the merging of regions results in Gaussian overlap to distort texture details. To address these challenges, we propose TraGraph-GS, leveraging a trajectory graph to enable high-precision rendering for arbitrarily large-scale scenes. We present a spatial partitioning method for large-scale scenes based on graphs, which incorporates a regularization constraint to enhance the rendering of textures and distant objects, as well as a progressive rendering strategy to mitigate artifacts caused by Gaussian overlap. Experimental results demonstrate its superior performance both on four aerial and four ground datasets and highlight its remarkable efficiency: our method achieves an average improvement of 1.86 dB in PSNR on aerial datasets and 1.62 dB on ground datasets compared to state-of-the-art approaches.</p></details> |  |
| **[MoSiC: Optimal-Transport Motion Trajectory for Dense Self-Supervised Learning](http://arxiv.org/abs/2506.08694v1)** | 2025-06-10 | [papers-cool](https://papers.cool/arxiv/2506.08694v1) | <details><summary>Show</summary><p>Dense self-supervised learning has shown great promise for learning pixel- and patch-level representations, but extending it to videos remains challenging due to the complexity of motion dynamics. Existing approaches struggle as they rely on static augmentations that fail under object deformations, occlusions, and camera movement, leading to inconsistent feature learning over time. We propose a motion-guided self-supervised learning framework that clusters dense point tracks to learn spatiotemporally consistent representations. By leveraging an off-the-shelf point tracker, we extract long-range motion trajectories and optimize feature clustering through a momentum-encoder-based optimal transport mechanism. To ensure temporal coherence, we propagate cluster assignments along tracked points, enforcing feature consistency across views despite viewpoint changes. Integrating motion as an implicit supervisory signal, our method learns representations that generalize across frames, improving robustness in dynamic scenes and challenging occlusion scenarios. By initializing from strong image-pretrained models and leveraging video data for training, we improve state-of-the-art by 1% to 6% on six image and video datasets and four evaluation benchmarks. The implementation is publicly available at our GitHub repository: https://github.com/SMSD75/MoSiC/tree/main</p></details> | preprint |
| **[FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL](http://arxiv.org/abs/2410.15876v4)** | 2025-06-10 | [papers-cool](https://papers.cool/arxiv/2410.15876v4) | <details><summary>Show</summary><p>Multi-agent reinforcement learning has demonstrated significant potential in addressing complex cooperative tasks across various real-world applications. However, existing MARL approaches often rely on the restrictive assumption that the number of entities (e.g., agents, obstacles) remains constant between training and inference. This overlooks scenarios where entities are dynamically removed or added during the inference trajectory -- a common occurrence in real-world environments like search and rescue missions and dynamic combat situations. In this paper, we tackle the challenge of intra-trajectory dynamic entity composition under zero-shot out-of-domain (OOD) generalization, where such dynamic changes cannot be anticipated beforehand. Our empirical studies reveal that existing MARL methods suffer significant performance degradation and increased uncertainty in these scenarios. In response, we propose FlickerFusion, a novel OOD generalization method that acts as a universally applicable augmentation technique for MARL backbone methods. FlickerFusion stochastically drops out parts of the observation space, emulating being in-domain when inferenced OOD. The results show that FlickerFusion not only achieves superior inference rewards but also uniquely reduces uncertainty vis-\`a-vis the backbone, compared to existing methods. Benchmarks, implementations, and model weights are organized and open-sourced at flickerfusion305.github.io, accompanied by ample demo video renderings.</p></details> | ICLR 2025 |
| **[Safe and Economical UAV Trajectory Planning in Low-Altitude Airspace: A Hybrid DRL-LLM Approach with Compliance Awareness](http://arxiv.org/abs/2506.08532v1)** | 2025-06-10 | [papers-cool](https://papers.cool/arxiv/2506.08532v1) | <details><summary>Show</summary><p>The rapid growth of the low-altitude economy has driven the widespread adoption of unmanned aerial vehicles (UAVs). This growing deployment presents new challenges for UAV trajectory planning in complex urban environments. However, existing studies often overlook key factors, such as urban airspace constraints and economic efficiency, which are essential in low-altitude economy contexts. Deep reinforcement learning (DRL) is regarded as a promising solution to these issues, while its practical adoption remains limited by low learning efficiency. To overcome this limitation, we propose a novel UAV trajectory planning framework that combines DRL with large language model (LLM) reasoning to enable safe, compliant, and economically viable path planning. Experimental results demonstrate that our method significantly outperforms existing baselines across multiple metrics, including data collection rate, collision avoidance, successful landing, regulatory compliance, and energy efficiency. These results validate the effectiveness of our approach in addressing UAV trajectory planning key challenges under constraints of the low-altitude economy networking.</p></details> |  |
| **[ATI: Any Trajectory Instruction for Controllable Video Generation](http://arxiv.org/abs/2505.22944v3)** | 2025-06-10 | [papers-cool](https://papers.cool/arxiv/2505.22944v3) | <details><summary>Show</summary><p>We propose a unified framework for motion control in video generation that seamlessly integrates camera movement, object-level translation, and fine-grained local motion using trajectory-based inputs. In contrast to prior methods that address these motion types through separate modules or task-specific designs, our approach offers a cohesive solution by projecting user-defined trajectories into the latent space of pre-trained image-to-video generation models via a lightweight motion injector. Users can specify keypoints and their motion paths to control localized deformations, entire object motion, virtual camera dynamics, or combinations of these. The injected trajectory signals guide the generative process to produce temporally consistent and semantically aligned motion sequences. Our framework demonstrates superior performance across multiple video motion control tasks, including stylized motion effects (e.g., motion brushes), dynamic viewpoint changes, and precise local motion manipulation. Experiments show that our method provides significantly better controllability and visual quality compared to prior approaches and commercial solutions, while remaining broadly compatible with various state-of-the-art video generation backbones. Project page: https://anytraj.github.io/.</p></details> |  |
| **[Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction](http://arxiv.org/abs/2506.07860v1)** | 2025-06-09 | [papers-cool](https://papers.cool/arxiv/2506.07860v1) | <details><summary>Show</summary><p>In this paper, we present a real-time egocentric trajectory prediction system for table tennis using event cameras. Unlike standard cameras, which suffer from high latency and motion blur at fast ball speeds, event cameras provide higher temporal resolution, allowing more frequent state updates, greater robustness to outliers, and accurate trajectory predictions using just a short time window after the opponent's impact. We collect a dataset of ping-pong game sequences, including 3D ground-truth trajectories of the ball, synchronized with sensor data from the Meta Project Aria glasses and event streams. Our system leverages foveated vision, using eye-gaze data from the glasses to process only events in the viewer's fovea. This biologically inspired approach improves ball detection performance and significantly reduces computational latency, as it efficiently allocates resources to the most perceptually relevant regions, achieving a reduction factor of 10.81 on the collected trajectories. Our detection pipeline has a worst-case total latency of 4.5 ms, including computation and perception - significantly lower than a frame-based 30 FPS system, which, in the worst case, takes 66 ms solely for perception. Finally, we fit a trajectory prediction model to the estimated states of the ball, enabling 3D trajectory forecasting in the future. To the best of our knowledge, this is the first approach to predict table tennis trajectories from an egocentric perspective using event cameras.</p></details> | <details><summary>IEEE/...</summary><p>IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Nashville (TN), USA, 2025; 5th International Workshop on Event-Based Vision</p></details> |
| **[Addition in Four Movements: Mapping Layer-wise Information Trajectories in LLMs](http://arxiv.org/abs/2506.07824v1)** | 2025-06-09 | [papers-cool](https://papers.cool/arxiv/2506.07824v1) | <details><summary>Show</summary><p>Multi-digit addition is a clear probe of the computational power of large language models. To dissect the internal arithmetic processes in LLaMA-3-8B-Instruct, we combine linear probing with logit-lens inspection. Inspired by the step-by-step manner in which humans perform addition, we propose and analyze a coherent four-stage trajectory in the forward pass:Formula-structure representations become linearly decodable first, while the answer token is still far down the candidate list.Core computational features then emerge prominently.At deeper activation layers, numerical abstractions of the result become clearer, enabling near-perfect detection and decoding of the individual digits in the sum.Near the output, the model organizes and generates the final content, with the correct token reliably occupying the top rank.This trajectory suggests a hierarchical process that favors internal computation over rote memorization. We release our code and data to facilitate reproducibility.</p></details> | <details><summary>12 pa...</summary><p>12 pages, including appendix, 7 figures. EMNLP 2025 submission (ARR May 2025 cycle, reviews pending)</p></details> |
| **[Learning Efficient and Effective Trajectories for Differential Equation-based Image Restoration](http://arxiv.org/abs/2410.04811v2)** | 2025-06-09 | [papers-cool](https://papers.cool/arxiv/2410.04811v2) | <details><summary>Show</summary><p>The differential equation-based image restoration approach aims to establish learnable trajectories connecting high-quality images to a tractable distribution, e.g., low-quality images or a Gaussian distribution. In this paper, we reformulate the trajectory optimization of this kind of method, focusing on enhancing both reconstruction quality and efficiency. Initially, we navigate effective restoration paths through a reinforcement learning process, gradually steering potential trajectories toward the most precise options. Additionally, to mitigate the considerable computational burden associated with iterative sampling, we propose cost-aware trajectory distillation to streamline complex paths into several manageable steps with adaptable sizes. Moreover, we fine-tune a foundational diffusion model (FLUX) with 12B parameters by using our algorithms, producing a unified framework for handling 7 kinds of image restoration tasks. Extensive experiments showcase the $\textit{significant}$ superiority of the proposed method, achieving a maximum PSNR improvement of 2.1 dB over state-of-the-art methods, while also greatly enhancing visual perceptual quality. Project page: https://zhu-zhiyu.github.io/FLUX-IR/.</p></details> |  |
| **[Trajectory World Models for Heterogeneous Environments](http://arxiv.org/abs/2502.01366v2)** | 2025-06-09 | [papers-cool](https://papers.cool/arxiv/2502.01366v2) | <details><summary>Show</summary><p>Heterogeneity in sensors and actuators across environments poses a significant challenge to building large-scale pre-trained world models on top of this low-dimensional sensor information. In this work, we explore pre-training world models for heterogeneous environments by addressing key transfer barriers in both data diversity and model flexibility. We introduce UniTraj, a unified dataset comprising over one million trajectories from 80 environments, designed to scale data while preserving critical diversity. Additionally, we propose TrajWorld, a novel architecture capable of flexibly handling varying sensor and actuator information and capturing environment dynamics in-context. Pre-training TrajWorld on UniTraj yields substantial gains in transition prediction, achieves a new state-of-the-art for off-policy evaluation, and also delivers superior online performance of model predictive control. To the best of our knowledge, this work, for the first time, demonstrates the transfer benefits of world models across heterogeneous and complex control environments. Code and data are available at https://github.com/thuml/TrajWorld.</p></details> | <details><summary>ICML ...</summary><p>ICML 2025. Code is available at https://github.com/thuml/TrajWorld</p></details> |
| **[Aircraft Trajectory Dataset Augmentation in Latent Space](http://arxiv.org/abs/2506.07585v1)** | 2025-06-09 | [papers-cool](https://papers.cool/arxiv/2506.07585v1) | <details><summary>Show</summary><p>Aircraft trajectory modeling plays a crucial role in Air Traffic Management (ATM) and is important for various downstream tasks, including conflict detection and landing time prediction. Dataset augmentation through the addition of synthetically generated trajectory data is necessary to develop a more robust aircraft trajectory model and ensure that the trajectory dataset is sufficient and balanced. In this work, we propose a novel framework called ATRADA for aircraft trajectory dataset augmentation. In the proposed framework, a Transformer encoder learns the underlying patterns in the original trajectory dataset and converts each data point into a context vector in the learned latent space. The converted dataset in the latent space is projected into reduced dimensions using principal component analysis (PCA), and a Gaussian mixture model (GMM) is applied to fit the probability distribution of the data points in the reduced-dimensional space. Finally, new samples are drawn from the fitted GMM, the dimension of the samples is reverted to the original dimension, and they are decoded with a Multi-Layer Perceptron (MLP). Several experiments demonstrate that the framework effectively generates new, high-quality synthetic aircraft trajectory data, which were compared to the results of several baselines.</p></details> |  |
| **[DONUT: A Decoder-Only Model for Trajectory Prediction](http://arxiv.org/abs/2506.06854v1)** | 2025-06-07 | [papers-cool](https://papers.cool/arxiv/2506.06854v1) | <details><summary>Show</summary><p>Predicting the motion of other agents in a scene is highly relevant for autonomous driving, as it allows a self-driving car to anticipate. Inspired by the success of decoder-only models for language modeling, we propose DONUT, a Decoder-Only Network for Unrolling Trajectories. Different from existing encoder-decoder forecasting models, we encode historical trajectories and predict future trajectories with a single autoregressive model. This allows the model to make iterative predictions in a consistent manner, and ensures that the model is always provided with up-to-date information, enhancing the performance. Furthermore, inspired by multi-token prediction for language modeling, we introduce an 'overprediction' strategy that gives the network the auxiliary task of predicting trajectories at longer temporal horizons. This allows the model to better anticipate the future, and further improves the performance. With experiments, we demonstrate that our decoder-only approach outperforms the encoder-decoder baseline, and achieves new state-of-the-art results on the Argoverse 2 single-agent motion forecasting benchmark.</p></details> |  |
| **[A Third-Order Gaussian Process Trajectory Representation Framework with Closed-Form Kinematics for Continuous-Time Motion Estimation](http://arxiv.org/abs/2410.22931v4)** | 2025-06-07 | [papers-cool](https://papers.cool/arxiv/2410.22931v4) | <details><summary>Show</summary><p>In this paper, we propose a third-order, i.e., white-noise-on-jerk, Gaussian Process (GP) Trajectory Representation (TR) framework for continuous-time (CT) motion estimation (ME) tasks. Our framework features a unified trajectory representation that encapsulates the kinematic models of both $SO(3)\times\mathbb{R}^3$ and $SE(3)$ pose representations. This encapsulation strategy allows users to use the same implementation of measurement-based factors for either choice of pose representation, which facilitates experimentation and comparison to achieve the best model for the ME task. In addition, unique to our framework, we derive the kinematic models with the closed-form temporal derivatives of the local variable of $SO(3)$ and $SE(3)$, which so far has only been approximated based on the Taylor expansion in the literature. Our experiments show that these kinematic models can improve the estimation accuracy in high-speed scenarios. All analytical Jacobians of the interpolated states with respect to the support states of the trajectory representation, as well as the motion prior factors, are also provided for accelerated Gauss-Newton (GN) optimization. Our experiments demonstrate the efficacy and efficiency of the framework in various motion estimation tasks such as localization, calibration, and odometry, facilitating fast prototyping for ME researchers. We release the source code for the benefit of the community. Our project is available at https://github.com/brytsknguyen/gptr.</p></details> | <details><summary>The s...</summary><p>The source code has been released. All feedbacks are welcome</p></details> |
| **[The Inverse Problem for Single Trajectories of Rough Differential Equations](http://arxiv.org/abs/2201.10300v2)** | 2025-06-07 | [papers-cool](https://papers.cool/arxiv/2201.10300v2) | <details><summary>Show</summary><p>Motivated by the need to develop a general framework for performing statistical inference for discretely observed random rough differential equations, our aim is to construct a geometric $p$-rough path ${\bf X}$ whose response $Y$, when driving a rough differential equation, matches the observed trajectory $y$. We call this the \textit{continuous inverse problem} and start by rigorously defining its solution. We then develop a framework where the solution can be constructed as a limit of solutions to appropriately designed \textit{discrete inverse problems}, so that convergence holds in $p$-variation. Our approach is based on calibrating the bounded variation paths whose limit defines the rough path `lift' of path $X$ to rough path ${\bf X}$ to the observed trajectory $y$. Moreover, we develop a general numerical algorithm for constructing the solution to the discrete inverse problem. The core idea of the algorithm is to use the signature representation of the path, iterating between the response and the control, each time correcting according to the required properties. We apply our framework to the case where the geometric $p$-rough path ${\bf X}$ is defined as the limit of piecewise linear paths in the $p$-variation topology. We express the discrete inverse problem for a fixed observation rate as a solution to a system of equations driven by piecewise linear paths and prove convergence to the solution of the continuous inverse problem for observation time $\delta\to 0$. Finally, we show that, in this context, the numerical algorithm for solving the discrete inverse problem simplifies to an iterative simultaneous update of the local gradients and we prove that it converges in $p$-variation uniformly with respect to $\delta$.</p></details> | <details><summary>Exten...</summary><p>Extended updated version - 41 pages, 10 figures</p></details> |
| **[Generalized Trajectory Scoring for End-to-end Multimodal Planning](http://arxiv.org/abs/2506.06664v1)** | 2025-06-07 | [papers-cool](https://papers.cool/arxiv/2506.06664v1) | <details><summary>Show</summary><p>End-to-end multi-modal planning is a promising paradigm in autonomous driving, enabling decision-making with diverse trajectory candidates. A key component is a robust trajectory scorer capable of selecting the optimal trajectory from these candidates. While recent trajectory scorers focus on scoring either large sets of static trajectories or small sets of dynamically generated ones, both approaches face significant limitations in generalization. Static vocabularies provide effective coarse discretization but struggle to make fine-grained adaptation, while dynamic proposals offer detailed precision but fail to capture broader trajectory distributions. To overcome these challenges, we propose GTRS (Generalized Trajectory Scoring), a unified framework for end-to-end multi-modal planning that combines coarse and fine-grained trajectory evaluation. GTRS consists of three complementary innovations: (1) a diffusion-based trajectory generator that produces diverse fine-grained proposals; (2) a vocabulary generalization technique that trains a scorer on super-dense trajectory sets with dropout regularization, enabling its robust inference on smaller subsets; and (3) a sensor augmentation strategy that enhances out-of-domain generalization while incorporating refinement training for critical trajectory discrimination. As the winning solution of the Navsim v2 Challenge, GTRS demonstrates superior performance even with sub-optimal sensor inputs, approaching privileged methods that rely on ground-truth perception. Code will be available at https://github.com/NVlabs/GTRS.</p></details> | <details><summary>The 1...</summary><p>The 1st place solution of the End-to-end Driving Track at the CVPR 2025 Autonomous Grand Challenge</p></details> |
| **[Certified Human Trajectory Prediction](http://arxiv.org/abs/2403.13778v2)** | 2025-06-06 | [papers-cool](https://papers.cool/arxiv/2403.13778v2) | <details><summary>Show</summary><p>Predicting human trajectories is essential for the safe operation of autonomous vehicles, yet current data-driven models often lack robustness in case of noisy inputs such as adversarial examples or imperfect observations. Although some trajectory prediction methods have been developed to provide empirical robustness, these methods are heuristic and do not offer guaranteed robustness. In this work, we propose a certification approach tailored for trajectory prediction that provides guaranteed robustness. To this end, we address the unique challenges associated with trajectory prediction, such as unbounded outputs and multi-modality. To mitigate the inherent performance drop through certification, we propose a diffusion-based trajectory denoiser and integrate it into our method. Moreover, we introduce new certified performance metrics to reliably measure the trajectory prediction performance. Through comprehensive experiments, we demonstrate the accuracy and robustness of the certified predictors and highlight their advantages over the non-certified ones. The code is available online: https://s-attack.github.io/.</p></details> | CVPR 2025 |
| **[Reusing Trajectories in Policy Gradients Enables Fast Convergence](http://arxiv.org/abs/2506.06178v1)** | 2025-06-06 | [papers-cool](https://papers.cool/arxiv/2506.06178v1) | <details><summary>Show</summary><p>Policy gradient (PG) methods are a class of effective reinforcement learning algorithms, particularly when dealing with continuous control problems. These methods learn the parameters of parametric policies via stochastic gradient ascent, typically using on-policy trajectory data to estimate the policy gradient. However, such reliance on fresh data makes them sample-inefficient. Indeed, vanilla PG methods require $O(\epsilon^{-2})$ trajectories to reach an $\epsilon$-approximate stationary point. A common strategy to improve efficiency is to reuse off-policy information from past iterations, such as previous gradients or trajectories. While gradient reuse has received substantial theoretical attention, leading to improved rates of $O(\epsilon^{-3/2})$, the reuse of past trajectories remains largely unexplored from a theoretical perspective. In this work, we provide the first rigorous theoretical evidence that extensive reuse of past off-policy trajectories can significantly accelerate convergence in PG methods. We introduce a power mean correction to the multiple importance weighting estimator and propose RPG (Retrospective Policy Gradient), a PG algorithm that combines old and new trajectories for policy updates. Through a novel analysis, we show that, under established assumptions, RPG achieves a sample complexity of $\widetilde{O}(\epsilon^{-1})$, the best known rate in the literature. We further validate empirically our approach against PG methods with state-of-the-art rates.</p></details> |  |
| **[UAV-UGV Cooperative Trajectory Optimization and Task Allocation for Medical Rescue Tasks in Post-Disaster Environments](http://arxiv.org/abs/2506.06136v1)** | 2025-06-06 | [papers-cool](https://papers.cool/arxiv/2506.06136v1) | <details><summary>Show</summary><p>In post-disaster scenarios, rapid and efficient delivery of medical resources is critical and challenging due to severe damage to infrastructure. To provide an optimized solution, we propose a cooperative trajectory optimization and task allocation framework leveraging unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). This study integrates a Genetic Algorithm (GA) for efficient task allocation among multiple UAVs and UGVs, and employs an informed-RRT* (Rapidly-exploring Random Tree Star) algorithm for collision-free trajectory generation. Further optimization of task sequencing and path efficiency is conducted using Covariance Matrix Adaptation Evolution Strategy (CMA-ES). Simulation experiments conducted in a realistic post-disaster environment demonstrate that our proposed approach significantly improves the overall efficiency of medical rescue operations compared to traditional strategies, showing substantial reductions in total mission completion time and traveled distance. Additionally, the cooperative utilization of UAVs and UGVs effectively balances their complementary advantages, highlighting the system' s scalability and practicality for real-world deployment.</p></details> |  |
| **[Multidimensional Adaptive Coefficient for Inference Trajectory Optimization in Flow and Diffusion](http://arxiv.org/abs/2404.14161v3)** | 2025-06-06 | [papers-cool](https://papers.cool/arxiv/2404.14161v3) | <details><summary>Show</summary><p>Flow and diffusion models have demonstrated strong performance and training stability across various tasks but lack two critical properties of simulation-based methods: freedom of dimensionality and adaptability to different inference trajectories. To address this limitation, we propose the Multidimensional Adaptive Coefficient (MAC), a plug-in module for flow and diffusion models that extends conventional unidimensional coefficients to multidimensional ones and enables inference trajectory-wise adaptation. MAC is trained via simulation-based feedback through adversarial refinement. Empirical results across diverse frameworks and datasets demonstrate that MAC enhances generative quality with high training efficiency. Consequently, our work offers a new perspective on inference trajectory optimality, encouraging future research to move beyond vector field design and to leverage training-efficient, simulation-based optimization.</p></details> | ICML 2025 Paper |
| **[Trajectory Optimization for UAV-Based Medical Delivery with Temporal Logic Constraints and Convex Feasible Set Collision Avoidance](http://arxiv.org/abs/2506.06038v1)** | 2025-06-06 | [papers-cool](https://papers.cool/arxiv/2506.06038v1) | <details><summary>Show</summary><p>This paper addresses the problem of trajectory optimization for unmanned aerial vehicles (UAVs) performing time-sensitive medical deliveries in urban environments. Specifically, we consider a single UAV with 3 degree-of-freedom dynamics tasked with delivering blood packages to multiple hospitals, each with a predefined time window and priority. Mission objectives are encoded using Signal Temporal Logic (STL), enabling the formal specification of spatial-temporal constraints. To ensure safety, city buildings are modeled as 3D convex obstacles, and obstacle avoidance is handled through a Convex Feasible Set (CFS) method. The entire planning problem-combining UAV dynamics, STL satisfaction, and collision avoidance-is formulated as a convex optimization problem that ensures tractability and can be solved efficiently using standard convex programming techniques. Simulation results demonstrate that the proposed method generates dynamically feasible, collision-free trajectories that satisfy temporal mission goals, providing a scalable and reliable approach for autonomous UAV-based medical logistics.</p></details> | 7 pages, 4 figures |
| **[State-Covering Trajectory Stitching for Diffusion Planners](http://arxiv.org/abs/2506.00895v2)** | 2025-06-06 | [papers-cool](https://papers.cool/arxiv/2506.00895v2) | <details><summary>Show</summary><p>Diffusion-based generative models are emerging as powerful tools for long-horizon planning in reinforcement learning (RL), particularly with offline datasets. However, their performance is fundamentally limited by the quality and diversity of training data. This often restricts their generalization to tasks outside their training distribution or longer planning horizons. To overcome this challenge, we propose State-Covering Trajectory Stitching (SCoTS), a novel reward-free trajectory augmentation method that incrementally stitches together short trajectory segments, systematically generating diverse and extended trajectories. SCoTS first learns a temporal distance-preserving latent representation that captures the underlying temporal structure of the environment, then iteratively stitches trajectory segments guided by directional exploration and novelty to effectively cover and expand this latent space. We demonstrate that SCoTS significantly improves the performance and generalization capabilities of diffusion planners on offline goal-conditioned benchmarks requiring stitching and long-horizon reasoning. Furthermore, augmented trajectories generated by SCoTS significantly improve the performance of widely used offline goal-conditioned RL algorithms across diverse environments.</p></details> |  |
| **[Trajectory Entropy: Modeling Game State Stability from Multimodality Trajectory Prediction](http://arxiv.org/abs/2506.05810v1)** | 2025-06-06 | [papers-cool](https://papers.cool/arxiv/2506.05810v1) | <details><summary>Show</summary><p>Complex interactions among agents present a significant challenge for autonomous driving in real-world scenarios. Recently, a promising approach has emerged, which formulates the interactions of agents as a level-k game framework. It effectively decouples agent policies by hierarchical game levels. However, this framework ignores both the varying driving complexities among agents and the dynamic changes in agent states across game levels, instead treating them uniformly. Consequently, redundant and error-prone computations are introduced into this framework. To tackle the issue, this paper proposes a metric, termed as Trajectory Entropy, to reveal the game status of agents within the level-k game framework. The key insight stems from recognizing the inherit relationship between agent policy uncertainty and the associated driving complexity. Specifically, Trajectory Entropy extracts statistical signals representing uncertainty from the multimodality trajectory prediction results of agents in the game. Then, the signal-to-noise ratio of this signal is utilized to quantify the game status of agents. Based on the proposed Trajectory Entropy, we refine the current level-k game framework through a simple gating mechanism, significantly improving overall accuracy while reducing computational costs. Our method is evaluated on the Waymo and nuPlan datasets, in terms of trajectory prediction, open-loop and closed-loop planning tasks. The results demonstrate the state-of-the-art performance of our method, with precision improved by up to 19.89% for prediction and up to 16.48% for planning.</p></details> | 10 pages |

## City
| **Title** | **Date** | **KiMi** | **Abstract** | **Comment** |
| --- | --- | --- | --- | --- |
| **[Real-Time Agile Software Management for Edge and Fog Computing Based Smart City Infrastructure](http://arxiv.org/abs/2506.12616v1)** | 2025-06-14 | [papers-cool](https://papers.cool/arxiv/2506.12616v1) | <details><summary>Show</summary><p>The evolution of smart cities demands scalable, secure, and energy-efficient architectures for real-time data processing. With the number of IoT devices expected to exceed 40 billion by 2030, traditional cloud-based systems are increasingly constrained by bandwidth, latency, and energy limitations. This paper leverages the ROOF (Real-time Onsite Operations Facilitation) framework with decentralized computing at intermediary fog and peripheral edge network layers to reduce latency by processing data near its point of origin. ROOF features fog caching to avoid redundancy, ultra-low-power wireless transmission for energy savings, and AI-driven resource allocation for efficiency. Security is enhanced through TLS encryption, blockchain-based authentication, and edge-level access control. Case studies from Bhubaneswar, Barcelona and Copenhagen validate the use of ROOF in traffic systems and environmental monitoring. The paper concludes by outlining key challenges and prospects of AI-driven analytics in smart urban infrastructure.</p></details> | <details><summary>The p...</summary><p>The paper has been published at the Fifth International Conference on Computing and Communication Networks (ICCCN 2025), Volume 1</p></details> |
| **[Collaboration Between the City and Machine Learning Community is Crucial to Efficient Autonomous Vehicles Routing](http://arxiv.org/abs/2502.13188v2)** | 2025-06-14 | [papers-cool](https://papers.cool/arxiv/2502.13188v2) | <details><summary>Show</summary><p>Autonomous vehicles (AVs), possibly using Multi-Agent Reinforcement Learning (MARL) for simultaneous route optimization, may destabilize traffic networks, with human drivers potentially experiencing longer travel times. We study this interaction by simulating human drivers and AVs. Our experiments with standard MARL algorithms reveal that, both in simplified and complex networks, policies often fail to converge to an optimal solution or require long training periods. This problem is amplified by the fact that we cannot rely entirely on simulated training, as there are no accurate models of human routing behavior. At the same time, real-world training in cities risks destabilizing urban traffic systems, increasing externalities, such as $CO_2$ emissions, and introducing non-stationarity as human drivers will adapt unpredictably to AV behaviors. In this position paper, we argue that city authorities must collaborate with the ML community to monitor and critically evaluate the routing algorithms proposed by car companies toward fair and system-efficient routing algorithms and regulatory standards.</p></details> |  |
| **[Improving Public Service Chatbot Design and Civic Impact: Investigation of Citizens' Perceptions of a Metro City 311 Chatbot](http://arxiv.org/abs/2506.12259v1)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2506.12259v1) | <details><summary>Show</summary><p>As governments increasingly adopt digital tools, public service chatbots have emerged as a growing communication channel. This paper explores the design considerations and engagement opportunities of public service chatbots, using a 311 chatbot from a metropolitan city as a case study. Our qualitative study consisted of official survey data and 16 interviews examining stakeholder experiences and design preferences for the chatbot. We found two key areas of concern regarding these public chatbots: individual-level and community-level. At the individual level, citizens experience three key challenges: interpretation, transparency, and social contextualization. Moreover, the current chatbot design prioritizes the efficient completion of individual tasks but neglects the broader community perspective. It overlooks how individuals interact and discuss problems collectively within their communities. To address these concerns, we offer design opportunities for creating more intelligent, transparent, community-oriented chatbots that better engage individuals and their communities.</p></details> |  |
| **[Bi-directional Mapping of Morphology Metrics and 3D City Blocks for Enhanced Characterization and Generation of Urban Form](http://arxiv.org/abs/2412.15801v2)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2412.15801v2) | <details><summary>Show</summary><p>Urban morphology, examining city spatial configurations, links urban design to sustainability. Morphology metrics play a fundamental role in performance-driven computational urban design (CUD) which integrates urban form generation, performance evaluation and optimization. However, a critical gap remains between performance evaluation and complex urban form generation, caused by the disconnection between morphology metrics and urban form, particularly in metric-to-form workflows. It prevents the application of optimized metrics to generate improved urban form with enhanced urban performance. Formulating morphology metrics that not only effectively characterize complex urban forms but also enable the reconstruction of diverse forms is of significant importance. This paper highlights the importance of establishing a bi-directional mapping between morphology metrics and complex urban form to enable the integration of urban form generation with performance evaluation. We present an approach that can 1) formulate morphology metrics to both characterize urban forms and in reverse, retrieve diverse similar 3D urban forms, and 2) evaluate the effectiveness of morphology metrics in representing 3D urban form characteristics of blocks by comparison. We demonstrate the methodology with 3D urban models of New York City, covering 14,248 blocks. We use neural networks and information retrieval for morphology metric encoding, urban form clustering and morphology metric evaluation. We identified an effective set of morphology metrics for characterizing block-scale urban forms through comparison. The proposed methodology tightly couples complex urban forms with morphology metrics, hence it can enable a seamless and bidirectional relationship between urban form generation and optimization in performance-driven urban design towards sustainable urban design and planning.</p></details> |  |
| **[Improving Acoustic Scene Classification with City Features](http://arxiv.org/abs/2503.16862v2)** | 2025-06-13 | [papers-cool](https://papers.cool/arxiv/2503.16862v2) | <details><summary>Show</summary><p>Acoustic scene recordings are often collected from a diverse range of cities. Most existing acoustic scene classification (ASC) approaches focus on identifying common acoustic scene patterns across cities to enhance generalization. However, the potential acoustic differences introduced by city-specific environmental and cultural factors are overlooked. In this paper, we hypothesize that the city-specific acoustic features are beneficial for the ASC task rather than being treated as noise or bias. To this end, we propose City2Scene, a novel framework that leverages city features to improve ASC. Unlike conventional approaches that may discard or suppress city information, City2Scene transfers the city-specific knowledge from pre-trained city classification models to scene classification model using knowledge distillation. We evaluate City2Scene on three datasets of DCASE Challenge Task 1, which include both scene and city labels. Experimental results demonstrate that city features provide valuable information for classifying scenes. By distilling city-specific knowledge, City2Scene effectively improves accuracy across a variety of lightweight CNN backbones, achieving competitive performance to the top-ranked solutions of DCASE Challenge in recent years.</p></details> |  |
| **[Enhancing Traffic Accident Classifications: Application of NLP Methods for City Safety](http://arxiv.org/abs/2506.12092v1)** | 2025-06-11 | [papers-cool](https://papers.cool/arxiv/2506.12092v1) | <details><summary>Show</summary><p>A comprehensive understanding of traffic accidents is essential for improving city safety and informing policy decisions. In this study, we analyze traffic incidents in Munich to identify patterns and characteristics that distinguish different types of accidents. The dataset consists of both structured tabular features, such as location, time, and weather conditions, as well as unstructured free-text descriptions detailing the circumstances of each accident. Each incident is categorized into one of seven predefined classes. To assess the reliability of these labels, we apply NLP methods, including topic modeling and few-shot learning, which reveal inconsistencies in the labeling process. These findings highlight potential ambiguities in accident classification and motivate a refined predictive approach. Building on these insights, we develop a classification model that achieves high accuracy in assigning accidents to their respective categories. Our results demonstrate that textual descriptions contain the most informative features for classification, while the inclusion of tabular data provides only marginal improvements. These findings emphasize the critical role of free-text data in accident analysis and highlight the potential of transformer-based models in improving classification reliability.</p></details> | <details><summary>18 pa...</summary><p>18 pages, 4 tables, 4 figures. This paper will appear in the ECML-PKDD 2025 Applied Data Science (ADS) track</p></details> |
| **[A Framework for Ethical Judgment of Smart City Applications](http://arxiv.org/abs/2506.05172v1)** | 2025-06-05 | [papers-cool](https://papers.cool/arxiv/2506.05172v1) | <details><summary>Show</summary><p>As modern cities increasingly adopt a variety of sensors and Internet of Things (IoT) technologies to collect and analyze data about residents, environments, and public services, they are fostering greater interactions among smart city applications, residents, governments, and businesses. This trend makes it essential for regulators to focus on these interactions to manage smart city practices effectively and prevent unethical outcomes. To facilitate ethical analysis for smart city applications, this paper introduces a judgment framework that examines various scenarios where ethical issues may arise. Employing a multi-agent approach, the framework incorporates diverse social entities and applies logic-based ethical rules to identify potential violations. Through a rights-based analysis, we developed a set of 13 ethical principles and rules to guide ethical practices in smart cities. We utilized two specification languages, Prototype Verification System (PVS) and Alloy, to model our multi-agent system. Our analysis suggests that Alloy may be more efficient for formalizing smart cities and conducting ethical rule checks, particularly with the assistance of a human evaluator. Simulations of a real-world smart city application demonstrate that our ethical judgment framework effectively detects unethical outcomes and can be extended for practical use.</p></details> |  |
| **[Voyager: Real-Time Splatting City-Scale 3D Gaussians on Your Phone](http://arxiv.org/abs/2506.02774v2)** | 2025-06-04 | [papers-cool](https://papers.cool/arxiv/2506.02774v2) | <details><summary>Show</summary><p>3D Gaussian Splatting (3DGS) is an emerging technique for photorealistic 3D scene rendering. However, rendering city-scale 3DGS scenes on mobile devices, e.g., your smartphones, remains a significant challenge due to the limited resources on mobile devices. A natural solution is to offload computation to the cloud; however, naively streaming rendered frames from the cloud to the client introduces high latency and requires bandwidth far beyond the capacity of current wireless networks. In this paper, we propose an effective solution to enable city-scale 3DGS rendering on mobile devices. Our key insight is that, under normal user motion, the number of newly visible Gaussians per second remains roughly constant. Leveraging this, we stream only the necessary Gaussians to the client. Specifically, on the cloud side, we propose asynchronous level-of-detail search to identify the necessary Gaussians for the client. On the client side, we accelerate rendering via a lookup table-based rasterization. Combined with holistic runtime optimizations, our system can deliver low-latency, city-scale 3DGS rendering on mobile devices. Compared to existing solutions, Voyager achieves over 100$\times$ reduction on data transfer and up to 8.9$\times$ speedup while retaining comparable rendering quality.</p></details> |  |
| **[A Pretrained Probabilistic Transformer for City-Scale Traffic Volume Prediction](http://arxiv.org/abs/2506.02654v1)** | 2025-06-03 | [papers-cool](https://papers.cool/arxiv/2506.02654v1) | <details><summary>Show</summary><p>City-scale traffic volume prediction plays a pivotal role in intelligent transportation systems, yet remains a challenge due to the inherent incompleteness and bias in observational data. Although deep learning-based methods have shown considerable promise, most existing approaches produce deterministic point estimates, thereby neglecting the uncertainty arising from unobserved traffic flows. Furthermore, current models are typically trained in a city-specific manner, which hinders their generalizability and limits scalability across diverse urban contexts. To overcome these limitations, we introduce TrafficPPT, a Pretrained Probabilistic Transformer designed to model traffic volume as a distributional aggregation of trajectories. Our framework fuses heterogeneous data sources-including real-time observations, historical trajectory data, and road network topology-enabling robust and uncertainty-aware traffic inference. TrafficPPT is initially pretrained on large-scale simulated data spanning multiple urban scenarios, and later fine-tuned on target cities to ensure effective domain adaptation. Experiments on real-world datasets show that TrafficPPT consistently surpasses state-of-the-art baselines, particularly under conditions of extreme data sparsity. Code will be open.</p></details> |  |
| **[Data and Technology for Equitable Public Administration: Understanding City Government Employees' Challenges and Needs](http://arxiv.org/abs/2505.21682v1)** | 2025-05-27 | [papers-cool](https://papers.cool/arxiv/2505.21682v1) | <details><summary>Show</summary><p>City governments in the United States are increasingly pressured to adopt emerging technologies. Yet, these systems often risk biased and disparate outcomes. Scholars studying public sector technology design have converged on the need to ground these systems in the goals and organizational contexts of employees using them. We expand our understanding of employees' contexts by focusing on the equity practices of city government employees to surface important equity considerations around public sector data and technology use. Through semi-structured interviews with thirty-six employees from ten departments of a U.S. city government, our findings reveal challenges employees face when operationalizing equity, perspectives on data needs for advancing equity goals, and the design space for acceptable government technology. We discuss what it looks like to foreground equity in data use and technology design, and considerations for how to support city government employees in operationalizing equity with and without official equity offices.</p></details> | <details><summary>Accep...</summary><p>Accepted to ACM CSCW 2025</p></details> |
| **[DynamicVL: Benchmarking Multimodal Large Language Models for Dynamic City Understanding](http://arxiv.org/abs/2505.21076v1)** | 2025-05-27 | [papers-cool](https://papers.cool/arxiv/2505.21076v1) | <details><summary>Show</summary><p>Multimodal large language models have demonstrated remarkable capabilities in visual understanding, but their application to long-term Earth observation analysis remains limited, primarily focusing on single-temporal or bi-temporal imagery. To address this gap, we introduce DVL-Suite, a comprehensive framework for analyzing long-term urban dynamics through remote sensing imagery. Our suite comprises 15,063 high-resolution (1.0m) multi-temporal images spanning 42 megacities in the U.S. from 2005 to 2023, organized into two components: DVL-Bench and DVL-Instruct. The DVL-Bench includes seven urban understanding tasks, from fundamental change detection (pixel-level) to quantitative analyses (regional-level) and comprehensive urban narratives (scene-level), capturing diverse urban dynamics including expansion/transformation patterns, disaster assessment, and environmental challenges. We evaluate 17 state-of-the-art multimodal large language models and reveal their limitations in long-term temporal understanding and quantitative analysis. These challenges motivate the creation of DVL-Instruct, a specialized instruction-tuning dataset designed to enhance models' capabilities in multi-temporal Earth observation. Building upon this dataset, we develop DVLChat, a baseline model capable of both image-level question-answering and pixel-level segmentation, facilitating a comprehensive understanding of city dynamics through language interactions.</p></details> |  |
| **[Larger cities, more commuters, more crime? The role of inter-city commuting in the scaling of urban crime](http://arxiv.org/abs/2505.20822v1)** | 2025-05-27 | [papers-cool](https://papers.cool/arxiv/2505.20822v1) | <details><summary>Show</summary><p>Cities attract a daily influx of non-resident commuters, reflecting their role in wider urban networks -- not as isolated places. However, it remains unclear how this inter-connectivity shapes the way crime scales with population, given that larger cities tend to receive more commuters and experience more crime. Here, we investigate how inter-city commuting relates to the population--crime relationship. We find that larger cities receive proportionately more commuters, which in turn is associated with higher crime levels. Specifically, each 1% increase in inbound commuters corresponds to a 0.32% rise in theft and 0.20% rise in burglary, holding population constant. We show that models incorporating both population and commuter inflows better explain crime variation than population-only models. These findings underscore the importance of considering how cities are connected -- not just their population size -- in disentangling the population--crime relationship.</p></details> | 16 pages, 2 figures |
| **[Smart Waste Management System for Makkah City using Artificial Intelligence and Internet of Things](http://arxiv.org/abs/2505.19040v1)** | 2025-05-25 | [papers-cool](https://papers.cool/arxiv/2505.19040v1) | <details><summary>Show</summary><p>Waste management is a critical global issue with significant environmental and public health implications. It has become more destructive during large-scale events such as the annual pilgrimage to Makkah, Saudi Arabia, one of the world's largest religious gatherings. This event's popularity has attracted millions worldwide, leading to significant and un-predictable accumulation of waste. Such a tremendous number of visitors leads to in-creased waste management issues at the Grand Mosque and other holy sites, highlighting the need for an effective solution other than traditional methods based on rigid collection schedules. To address this challenge, this research proposed an innovative solution that is context-specific and tailored to the unique requirements of pilgrimage season: a Smart Waste Management System, called TUHR, that utilizes the Internet of Things and Artificial Intelligence. This system encompasses ultrasonic sensors that monitor waste levels in each container at the performance sites. Once the container reaches full capacity, the sensor communicates with the microcontroller, which alerts the relevant authorities. Moreover, our system can detect harmful substances such as gas from the gas detector sensor. Such a proactive and dynamic approach promises to mitigate the environmental and health risks associated with waste accumulation and enhance the cleanliness of these sites. It also delivers economic benefits by reducing unnecessary gasoline consumption and optimizing waste management resources. Importantly, this research aligns with the principles of smart cities and exemplifies the innovative, sustainable, and health-conscious approach that Saudi Arabia is implementing as part of its Vision 2030 initiative.</p></details> | 10 pages, 5 figures |
| **[Safety-Prioritized, Reinforcement Learning-Enabled Traffic Flow Optimization in a 3D City-Wide Simulation Environment](http://arxiv.org/abs/2506.03161v1)** | 2025-05-23 | [papers-cool](https://papers.cool/arxiv/2506.03161v1) | <details><summary>Show</summary><p>Traffic congestion and collisions represent significant economic, environmental, and social challenges worldwide. Traditional traffic management approaches have shown limited success in addressing these complex, dynamic problems. To address the current research gaps, three potential tools are developed: a comprehensive 3D city-wide simulation environment that integrates both macroscopic and microscopic traffic dynamics; a collision model; and a reinforcement learning framework with custom reward functions prioritizing safety over efficiency. Unity game engine-based simulation is used for direct collision modeling. A custom reward enabled reinforcement learning method, proximal policy optimization (PPO) model, yields substantial improvements over baseline results, reducing the number of serious collisions, number of vehicle-vehicle collisions, and total distance travelled by over 3 times the baseline values. The model also improves fuel efficiency by 39% and reduces carbon emissions by 88%. Results establish feasibility for city-wide 3D traffic simulation applications incorporating the vision-zero safety principles of the Department of Transportation, including physics-informed, adaptable, realistic collision modeling, as well as appropriate reward modeling for real-world traffic signal light control towards reducing collisions, optimizing traffic flow and reducing greenhouse emissions.</p></details> | <details><summary>18 pa...</summary><p>18 pages, figures at end, methods at end. Format/order can be changed if necessary</p></details> |
| **[CityEQA: A Hierarchical LLM Agent on Embodied Question Answering Benchmark in City Space](http://arxiv.org/abs/2502.12532v3)** | 2025-05-22 | [papers-cool](https://papers.cool/arxiv/2502.12532v3) | <details><summary>Show</summary><p>Embodied Question Answering (EQA) has primarily focused on indoor environments, leaving the complexities of urban settings-spanning environment, action, and perception-largely unexplored. To bridge this gap, we introduce CityEQA, a new task where an embodied agent answers open-vocabulary questions through active exploration in dynamic city spaces. To support this task, we present CityEQA-EC, the first benchmark dataset featuring 1,412 human-annotated tasks across six categories, grounded in a realistic 3D urban simulator. Moreover, we propose Planner-Manager-Actor (PMA), a novel agent tailored for CityEQA. PMA enables long-horizon planning and hierarchical task execution: the Planner breaks down the question answering into sub-tasks, the Manager maintains an object-centric cognitive map for spatial reasoning during the process control, and the specialized Actors handle navigation, exploration, and collection sub-tasks. Experiments demonstrate that PMA achieves 60.7% of human-level answering accuracy, significantly outperforming competitive baselines. While promising, the performance gap compared to humans highlights the need for enhanced visual reasoning in CityEQA. This work paves the way for future advancements in urban spatial intelligence. Dataset and code are available at https://github.com/BiluYong/CityEQA.git.</p></details> |  |
| **[Satellites Reveal Mobility: A Commuting Origin-destination Flow Generator for Global Cities](http://arxiv.org/abs/2505.15870v1)** | 2025-05-21 | [papers-cool](https://papers.cool/arxiv/2505.15870v1) | <details><summary>Show</summary><p>Commuting Origin-destination~(OD) flows, capturing daily population mobility of citizens, are vital for sustainable development across cities around the world. However, it is challenging to obtain the data due to the high cost of travel surveys and privacy concerns. Surprisingly, we find that satellite imagery, publicly available across the globe, contains rich urban semantic signals to support high-quality OD flow generation, with over 98\% expressiveness of traditional multisource hard-to-collect urban sociodemographic, economics, land use, and point of interest data. This inspires us to design a novel data generator, GlODGen, which can generate OD flow data for any cities of interest around the world. Specifically, GlODGen first leverages Vision-Language Geo-Foundation Models to extract urban semantic signals related to human mobility from satellite imagery. These features are then combined with population data to form region-level representations, which are used to generate OD flows via graph diffusion models. Extensive experiments on 4 continents and 6 representative cities show that GlODGen has great generalizability across diverse urban environments on different continents and can generate OD flow data for global cities highly consistent with real-world mobility data. We implement GlODGen as an automated tool, seamlessly integrating data acquisition and curation, urban semantic feature extraction, and OD flow generation together. It has been released at https://github.com/tsinghua-fib-lab/generate-od-pubtools.</p></details> | 26 pages, 8 figures |
| **[Exploring the interplay between population profile and optimal routes in U.S. cities](http://arxiv.org/abs/2505.12510v1)** | 2025-05-18 | [papers-cool](https://papers.cool/arxiv/2505.12510v1) | <details><summary>Show</summary><p>Cities have developed over time alongside advancements in civilization, focusing on efficient travel and reducing costs. Many studies have examined the distinctive features of urban road networks, such as their length, efficiency, connection to population density, and other properties. However, the relationship between car routes and population in city structures remains unclear. In this study, we used the center of mass for each city tract, defined by the US Census, as the origins and destinations for our itineraries. We calculated travel time, and both Euclidean and travel distances for sixty major cities. We discovered that the total sum of all routes adheres to an urban law. The distribution of these car journeys follows Weibull functions, suggesting that the urban center plays a crucial role in optimizing routes across multiple cities. We also developed a simple point pattern model for the population, which aligns with the well-known decreasing exponential density expression. Our findings show that the interplay between population and path optimization influences city structure through its center. This study offers a new perspective on the fundamental principles that shape urban design.</p></details> | <details><summary>15 pa...</summary><p>15 pages, 5 figures. This version was prior to peer review. Final version can be accessed via its doi</p></details> |
| **[Legacy Procurement Practices Shape How U.S. Cities Govern AI: Understanding Government Employees' Practices, Challenges, and Needs](http://arxiv.org/abs/2411.04994v3)** | 2025-05-13 | [papers-cool](https://papers.cool/arxiv/2411.04994v3) | <details><summary>Show</summary><p>Most AI tools adopted by governments are not developed internally, but instead are acquired from third-party vendors in a process called public procurement. In this paper, we conduct the first empirical study of how United States cities' procurement practices shape critical decisions surrounding public sector AI. We conduct semi-structured interviews with 19 city employees who oversee AI procurement across 7 U.S. cities. We found that cities' legacy procurement practices, which are shaped by decades-old laws and norms, establish infrastructure that determines which AI is purchased, and which actors hold decision-making power over procured AI. We characterize the emerging actions cities have taken to adapt their purchasing practices to address algorithmic harms. From employees' reflections on real-world AI procurements, we identify three key challenges that motivate but are not fully addressed by existing AI procurement reform initiatives. Based on these findings, we discuss implications and opportunities for the FAccT community to support cities in foreseeing and preventing AI harms throughout the public procurement processes.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 2 column format. In proceedings of ACM FAccT 2025</p></details> |
| **[Opportunities and Applications of GenAI in Smart Cities: A User-Centric Survey](http://arxiv.org/abs/2505.08034v1)** | 2025-05-12 | [papers-cool](https://papers.cool/arxiv/2505.08034v1) | <details><summary>Show</summary><p>The proliferation of IoT in cities, combined with Digital Twins, creates a rich data foundation for Smart Cities aimed at improving urban life and operations. Generative AI (GenAI) significantly enhances this potential, moving beyond traditional AI analytics and predictions by processing multimodal content and generating novel outputs like text and simulations. Using specialized or foundational models, GenAI's natural language abilities such as Natural Language Understanding (NLU) and Natural Language Generation (NLG) can power tailored applications and unified interfaces, dramatically lowering barriers for users interacting with complex smart city systems. In this paper, we focus on GenAI applications based on conversational interfaces within the context of three critical user archetypes in a Smart City - Citizens, Operators and Planners. We identify and review GenAI models and techniques that have been proposed or deployed for various urban subsystems in the contexts of these user archetypes. We also consider how GenAI can be built on the existing data foundation of official city records, IoT data streams and Urban Digital Twins. We believe this work represents the first comprehensive summarization of GenAI techniques for Smart Cities from the lens of the critical users in a Smart City.</p></details> | <details><summary>Accep...</summary><p>Accepted in IEEE COMPSAC 2025</p></details> |
| **[The City that Never Settles: Simulation-based LiDAR Dataset for Long-Term Place Recognition Under Extreme Structural Changes](http://arxiv.org/abs/2505.05076v1)** | 2025-05-08 | [papers-cool](https://papers.cool/arxiv/2505.05076v1) | <details><summary>Show</summary><p>Large-scale construction and demolition significantly challenge long-term place recognition (PR) by drastically reshaping urban and suburban environments. Existing datasets predominantly reflect limited or indoor-focused changes, failing to adequately represent extensive outdoor transformations. To bridge this gap, we introduce the City that Never Settles (CNS) dataset, a simulation-based dataset created using the CARLA simulator, capturing major structural changes-such as building construction and demolition-across diverse maps and sequences. Additionally, we propose TCR_sym, a symmetric version of the original TCR metric, enabling consistent measurement of structural changes irrespective of source-target ordering. Quantitative comparisons demonstrate that CNS encompasses more extensive transformations than current real-world benchmarks. Evaluations of state-of-the-art LiDAR-based PR methods on CNS reveal substantial performance degradation, underscoring the need for robust algorithms capable of handling significant environmental changes. Our dataset is available at https://github.com/Hyunho111/CNS_dataset.</p></details> |  |
| **[Towards Time Sensitive Networking on Smart Cities: Techniques, Challenges, and Solutions](http://arxiv.org/abs/2312.03635v2)** | 2025-05-07 | [papers-cool](https://papers.cool/arxiv/2312.03635v2) | <details><summary>Show</summary><p>Smart cities transform urban landscapes with interconnected nodes and sensors. The search for seamless communication in time-critical scenarios has become evident during this evolution. With the escalating complexity of urban environments, envisioning a future with a blend of autonomous and conventional systems, each demanding distinct quality-of-service considerations, services in smart cities vary in criticality levels and necessitate differentiated traffic handling, prioritizing critical flows without compromising the network's reliability or failing on hard real-time requirements. To tackle these challenges, in this article, we discuss a time-sensitive networking approach, which presents multi-faceted challenges, notably interoperability among diverse technologies and standards at the scale of a smart city network. TSN emerges as a promising toolkit, encompassing synchronization, latency management, redundancy, and configuration functionalities crucial for addressing smart city challenges. Moreover, the article scrutinizes how TSN, predominantly utilized in domains like automotive and industry, can be tailored to suit the intricate needs of smart cities, emphasizing the necessity for adaptability and scalability in network design. This survey consolidates current research on TSN, outlining its potential in fortifying critical machine-to-machine communications within smart cities while highlighting future challenges, potential solutions, and a roadmap for integrating TSN effectively into the fabric of urban connectivity.</p></details> |  |
| **[Event-aware analysis of cross-city visitor flows using large language models and social media data](http://arxiv.org/abs/2505.03847v1)** | 2025-05-05 | [papers-cool](https://papers.cool/arxiv/2505.03847v1) | <details><summary>Show</summary><p>Public events, such as music concerts and fireworks displays, can cause irregular surges in cross-city travel demand, leading to potential overcrowding, travel delays, and public safety concerns. To better anticipate and accommodate such demand surges, it is essential to estimate cross-city visitor flows with awareness of public events. Although prior studies typically focused on the effects of a single mega event or disruptions around a single venue, this study introduces a generalizable framework to analyze visitor flows under diverse and concurrent events. We propose to leverage large language models (LLMs) to extract event features from multi-source online information and massive user-generated content on social media platforms. Specifically, social media popularity metrics are designed to capture the effects of online promotion and word-of-mouth in attracting visitors. An event-aware machine learning model is then adopted to uncover the specific impacts of different event features and ultimately predict visitor flows for upcoming events. Using Hong Kong as a case study, the framework is applied to predict daily flows of mainland Chinese visitors arriving at the city, achieving a testing R-squared of over 85%. We further investigate the heterogeneous event impacts on visitor numbers across different event types and major travel modes. Both promotional popularity and word-of-mouth popularity are found to be associated with increased visitor flows, but the specific effects vary by the event type. This association is more pronounced among visitors arriving by metro and high-speed rail, while it has less effect on air travelers. The findings can facilitate coordinated measures across government agencies and guide specialized transport policies, such as shuttle transit services to event venues, and comprehensive on-site traffic management strategies.</p></details> |  |
| **[A Robust Deep Networks based Multi-Object MultiCamera Tracking System for City Scale Traffic](http://arxiv.org/abs/2505.00534v1)** | 2025-05-01 | [papers-cool](https://papers.cool/arxiv/2505.00534v1) | <details><summary>Show</summary><p>Vision sensors are becoming more important in Intelligent Transportation Systems (ITS) for traffic monitoring, management, and optimization as the number of network cameras continues to rise. However, manual object tracking and matching across multiple non-overlapping cameras pose significant challenges in city-scale urban traffic scenarios. These challenges include handling diverse vehicle attributes, occlusions, illumination variations, shadows, and varying video resolutions. To address these issues, we propose an efficient and cost-effective deep learning-based framework for Multi-Object Multi-Camera Tracking (MO-MCT). The proposed framework utilizes Mask R-CNN for object detection and employs Non-Maximum Suppression (NMS) to select target objects from overlapping detections. Transfer learning is employed for re-identification, enabling the association and generation of vehicle tracklets across multiple cameras. Moreover, we leverage appropriate loss functions and distance measures to handle occlusion, illumination, and shadow challenges. The final solution identification module performs feature extraction using ResNet-152 coupled with Deep SORT based vehicle tracking. The proposed framework is evaluated on the 5th AI City Challenge dataset (Track 3), comprising 46 camera feeds. Among these 46 camera streams, 40 are used for model training and validation, while the remaining six are utilized for model testing. The proposed framework achieves competitive performance with an IDF1 score of 0.8289, and precision and recall scores of 0.9026 and 0.8527 respectively, demonstrating its effectiveness in robust and accurate vehicle tracking.</p></details> |  |
| **[Mapping a Movement: Exploring a Proposed Police Training Facility in Atlanta and the Stop Cop City Movement through Online Maps](http://arxiv.org/abs/2504.20886v1)** | 2025-04-29 | [papers-cool](https://papers.cool/arxiv/2504.20886v1) | <details><summary>Show</summary><p>In 2021, the City of Atlanta and Atlanta Police Foundation launched plans to build a large police training facility in the South River Forest in unincorporated DeKalb County, GA. Residents of Atlanta and DeKalb County, environmental activists, police and prison abolitionists, and other activists and concerned individuals formed the movement in opposition to the facility, known as the Stop Cop City / Defend the Atlanta Forest movement. Social media and digital maps became common tools for communicating information about the facility and the movement. Here, we examine online maps about the facility and the opposition movement, originating from grassroots organizations, the City of Atlanta, news media outlets, the Atlanta Police Foundation, and individuals. We gather and examine 32 publicly available maps collected through the Google Search API, Twitter (now X), Instagram and reddit. Using a framework of critical cartography, we conduct a content analysis of these maps to identify the mapping technologies and techniques (data, cartographic elements, styles) used by different stakeholders and roles that maps and mapping technologies can play in social movements. We examine the extent to which these maps provide data to confirm or contradict concerns raised by grassroots organizations and local residents about the facility. We find that stakeholders and mapmakers use geospatial tools in different ways and likely have varied access to mapping technologies. We argue that documenting the use of maps to communicate information about a contentious project can help enumerate community positions and perspectives, and we advocate for accessible mapmaking tools. We conclude by discussing the implications of accessibility of mapping technology and posting maps to social media, and share example map images that extend the geographic information systems (GIS) techniques seen in the retrieved maps.</p></details> | <details><summary>Suppl...</summary><p>Supplementary material available at https://doi.org/10.7910/DVN/PCQ294</p></details> |
| **[Effective and Efficient Cross-City Traffic Knowledge Transfer: A Privacy-Preserving Perspective](http://arxiv.org/abs/2503.11963v3)** | 2025-04-24 | [papers-cool](https://papers.cool/arxiv/2503.11963v3) | <details><summary>Show</summary><p>Traffic prediction targets forecasting future traffic conditions using historical traffic data, serving a critical role in urban computing and transportation management. To mitigate the scarcity of traffic data while maintaining data privacy, numerous Federated Traffic Knowledge Transfer (FTT) approaches have been developed, which use transfer learning and federated learning to transfer traffic knowledge from data-rich cities to data-scarce cities, enhancing traffic prediction capabilities for the latter. However, current FTT approaches face challenges such as privacy leakage, cross-city data distribution discrepancies, low data quality, and inefficient knowledge transfer, limiting their privacy protection, effectiveness, robustness, and efficiency in real-world applications. To this end, we propose FedTT, an effective, efficient, and privacy-aware cross-city traffic knowledge transfer framework that transforms the traffic data domain from the data-rich cities and trains traffic models using the transformed data for the data-scarce cities. First, to safeguard data privacy, we propose a traffic secret transmission method that securely transmits and aggregates traffic domain-transformed data from source cities using a lightweight secret aggregation approach. Second, to mitigate the impact of traffic data distribution discrepancies on model performance, we introduce a traffic domain adapter to uniformly transform traffic data from the source cities' domains to that of the target city. Third, to improve traffic data quality, we design a traffic view imputation method to fill in and predict missing traffic data. Finally, to enhance transfer efficiency, FedTT is equipped with a federated parallel training method that enables the simultaneous training of multiple modules. Extensive experiments using 4 real-life datasets demonstrate that FedTT outperforms the 14 state-of-the-art baselines.</p></details> |  |
| **[Urban Metaverse: The Smart City in the Industrial Metaverse. Opportunities of the metaverse for real-time, interactive, and inclusive infrastructure applications in urban areas](http://arxiv.org/abs/2503.04729v2)** | 2025-04-20 | [papers-cool](https://papers.cool/arxiv/2503.04729v2) | <details><summary>Show</summary><p>The Urban Metaverse describes an immersive 3D environment that connects the physical world of the city and its citizens with its digital data and systems. Physical and digital realities merge, opening up new possibilities for the design and use of the city. This trend study serves as a source of inspiration and guidance for city and community leaders, urban planners, IT professionals, and anyone interested in the future of urban spaces. It helps to understand the opportunities and challenges of the urban metaverse as an evolution of the Smart City and to set the course for sustainable and innovative urban development. To this end, the study analyzes the opportunities that the urban metaverse offers for urban administration and the everyday life of citizens, presents key technologies, and highlights the socio-economic challenges of implementation. The focus is on the potential of the urban metaverse to optimize the planning and operation of urban infrastructures, to promote inclusion and civic participation, and to enhance the innovative capacity of cities and municipalities. The study develops four recommendations for the implementation of metaverse applications in an urban context: 1. user-centered design, 2. ubiquitous accessibility, 3. proactive design of the regulatory framework, and 4. development of viable business models.</p></details> | <details><summary>Updat...</summary><p>Updated English version, April 2025</p></details> |
| **[HAECcity: Open-Vocabulary Scene Understanding of City-Scale Point Clouds with Superpoint Graph Clustering](http://arxiv.org/abs/2504.13590v1)** | 2025-04-18 | [papers-cool](https://papers.cool/arxiv/2504.13590v1) | <details><summary>Show</summary><p>Traditional 3D scene understanding techniques are generally predicated on hand-annotated label sets, but in recent years a new class of open-vocabulary 3D scene understanding techniques has emerged. Despite the success of this paradigm on small scenes, existing approaches cannot scale efficiently to city-scale 3D datasets. In this paper, we present Hierarchical vocab-Agnostic Expert Clustering (HAEC), after the latin word for 'these', a superpoint graph clustering based approach which utilizes a novel mixture of experts graph transformer for its backbone. We administer this highly scalable approach to the first application of open-vocabulary scene understanding on the SensatUrban city-scale dataset. We also demonstrate a synthetic labeling pipeline which is derived entirely from the raw point clouds with no hand-annotation. Our technique can help unlock complex operations on dense urban 3D scenes and open a new path forward in the processing of digital twins.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication through the upcoming CVPR Workshop on open scene understanding with foundation models (OPENSUN3D)</p></details> |
| **[RADLER: Radar Object Detection Leveraging Semantic 3D City Models and Self-Supervised Radar-Image Learning](http://arxiv.org/abs/2504.12167v1)** | 2025-04-16 | [papers-cool](https://papers.cool/arxiv/2504.12167v1) | <details><summary>Show</summary><p>Semantic 3D city models are worldwide easy-accessible, providing accurate, object-oriented, and semantic-rich 3D priors. To date, their potential to mitigate the noise impact on radar object detection remains under-explored. In this paper, we first introduce a unique dataset, RadarCity, comprising 54K synchronized radar-image pairs and semantic 3D city models. Moreover, we propose a novel neural network, RADLER, leveraging the effectiveness of contrastive self-supervised learning (SSL) and semantic 3D city models to enhance radar object detection of pedestrians, cyclists, and cars. Specifically, we first obtain the robust radar features via a SSL network in the radar-image pretext task. We then use a simple yet effective feature fusion strategy to incorporate semantic-depth features from semantic 3D city models. Having prior 3D information as guidance, RADLER obtains more fine-grained details to enhance radar object detection. We extensively evaluate RADLER on the collected RadarCity dataset and demonstrate average improvements of 5.46% in mean avarage precision (mAP) and 3.51% in mean avarage recall (mAR) over previous radar object detection methods. We believe this work will foster further research on semantic-guided and map-supported radar object detection. Our project page is publicly available athttps://gpp-communication.github.io/RADLER .</p></details> | <details><summary>The p...</summary><p>The paper accepted for CVPRW '25 (PBVS 2025 - the Perception Beyond the Visible Spectrum)</p></details> |
| **[VoxCity: A Seamless Framework for Open Geospatial Data Integration, Grid-Based Semantic 3D City Model Generation, and Urban Environment Simulation](http://arxiv.org/abs/2504.13934v1)** | 2025-04-15 | [papers-cool](https://papers.cool/arxiv/2504.13934v1) | <details><summary>Show</summary><p>Three-dimensional urban environment simulation is a powerful tool for informed urban planning. However, the intensive manual effort required to prepare input 3D city models has hindered its widespread adoption. To address this challenge, we present VoxCity, an open-source Python package that provides a one-stop solution for grid-based 3D city model generation and urban environment simulation for cities worldwide. VoxCity's `generator' subpackage automatically downloads building heights, tree canopy heights, land cover, and terrain elevation within a specified target area, and voxelizes buildings, trees, land cover, and terrain to generate an integrated voxel city model. The `simulator' subpackage enables users to conduct environmental simulations, including solar radiation and view index analyses. Users can export the generated models using several file formats compatible with external software, such as ENVI-met (INX), Blender, and Rhino (OBJ). We generated 3D city models for eight global cities, and demonstrated the calculation of solar irradiance, sky view index, and green view index. We also showcased microclimate simulation and 3D rendering visualization through ENVI-met and Rhino, respectively, through the file export function. Additionally, we reviewed openly available geospatial data to create guidelines to help users choose appropriate data sources depending on their target areas and purposes. VoxCity can significantly reduce the effort and time required for 3D city model preparation and promote the utilization of urban environment simulations. This contributes to more informed urban and architectural design that considers environmental impacts, and in turn, fosters sustainable and livable cities. VoxCity is released openly at https://github.com/kunifujiwara/VoxCity.</p></details> |  |
| **[Enhancing Tourism Recommender Systems for Sustainable City Trips Using Retrieval-Augmented Generation](http://arxiv.org/abs/2409.18003v2)** | 2025-04-12 | [papers-cool](https://papers.cool/arxiv/2409.18003v2) | <details><summary>Show</summary><p>Tourism Recommender Systems (TRS) have traditionally focused on providing personalized travel suggestions, often prioritizing user preferences without considering broader sustainability goals. Integrating sustainability into TRS has become essential with the increasing need to balance environmental impact, local community interests, and visitor satisfaction. This paper proposes a novel approach to enhancing TRS for sustainable city trips using Large Language Models (LLMs) and a modified Retrieval-Augmented Generation (RAG) pipeline. We enhance the traditional RAG system by incorporating a sustainability metric based on a city's popularity and seasonal demand during the prompt augmentation phase. This modification, called Sustainability Augmented Reranking (SAR), ensures the system's recommendations align with sustainability goals. Evaluations using popular open-source LLMs, such as Llama-3.1-Instruct-8B and Mistral-Instruct-7B, demonstrate that the SAR-enhanced approach consistently matches or outperforms the baseline (without SAR) across most metrics, highlighting the benefits of incorporating sustainability into TRS.</p></details> | <details><summary>Accep...</summary><p>Accepted at the RecSoGood 2024 Workshop co-located with the 18th ACM Conference on Recommender Systems (RecSys 2024)</p></details> |
| **[CityGen: Infinite and Controllable City Layout Generation](http://arxiv.org/abs/2312.01508v2)** | 2025-04-11 | [papers-cool](https://papers.cool/arxiv/2312.01508v2) | <details><summary>Show</summary><p>The recent surge in interest in city layout generation underscores its significance in urban planning and smart city development. The task involves procedurally or automatically generating spatial arrangements for urban elements such as roads, buildings, water, and vegetation. Previous methods, whether procedural modeling or deep learning-based approaches like VAEs and GANs, rely on complex priors, expert guidance, or initial layouts, and often lack diversity and interactivity. In this paper, we present CityGen, an end-to-end framework for infinite, diverse, and controllable city layout generation. Our framework introduces an infinite expansion module to extend local layouts to city-scale layouts and a multi-scale refinement module to upsample and refine them. We also designed a user-friendly control scheme, allowing users to guide generation through simple sketching. Additionally, we convert the 2D layout to 3D by synthesizing a height field, facilitating downstream applications. Extensive experiments demonstrate CityGen's state-of-the-art performance across various metrics, making it suitable for a wide range of downstream applications.</p></details> | <details><summary>Accep...</summary><p>Accepted to CVPR 2025 USM3D Workshop</p></details> |
| **[Quantum-Inspired Genetic Algorithm for Robust Source Separation in Smart City Acoustics](http://arxiv.org/abs/2504.07345v1)** | 2025-04-10 | [papers-cool](https://papers.cool/arxiv/2504.07345v1) | <details><summary>Show</summary><p>The cacophony of urban sounds presents a significant challenge for smart city applications that rely on accurate acoustic scene analysis. Effectively analyzing these complex soundscapes, often characterized by overlapping sound sources, diverse acoustic events, and unpredictable noise levels, requires precise source separation. This task becomes more complicated when only limited training data is available. This paper introduces a novel Quantum-Inspired Genetic Algorithm (p-QIGA) for source separation, drawing inspiration from quantum information theory to enhance acoustic scene analysis in smart cities. By leveraging quantum superposition for efficient solution space exploration and entanglement to handle correlated sources, p-QIGA achieves robust separation even with limited data. These quantum-inspired concepts are integrated into a genetic algorithm framework to optimize source separation parameters. The effectiveness of our approach is demonstrated on two datasets: the TAU Urban Acoustic Scenes 2020 Mobile dataset, representing typical urban soundscapes, and the Silent Cities dataset, capturing quieter urban environments during the COVID-19 pandemic. Experimental results show that the p-QIGA achieves accuracy comparable to state-of-the-art methods while exhibiting superior resilience to noise and limited training data, achieving up to 8.2 dB signal-to-distortion ratio (SDR) in noisy environments and outperforming baseline methods by up to 2 dB with only 10% of the training data. This research highlights the potential of p-QIGA to advance acoustic signal processing in smart cities, particularly for noise pollution monitoring and acoustic surveillance.</p></details> | <details><summary>6 pag...</summary><p>6 pages, 2 figures, IEEE International Conference on Communications (ICC 2025)</p></details> |
| **[Scalable Routing in a City-Scale Wi-Fi Network for Disaster Recovery](http://arxiv.org/abs/2504.06406v1)** | 2025-04-08 | [papers-cool](https://papers.cool/arxiv/2504.06406v1) | <details><summary>Show</summary><p>In this paper, we present a new city-scale decentralized mesh network system suited for disaster recovery and emergencies. When wide-area connectivity is unavailable or significantly degraded, our system, MapMesh, enables static access points and mobile devices equipped with Wi-Fi in a city to route packets via each other for intra-city connectivity and to/from any nodes that might have Internet access, e.g., via satellite. The chief contribution of our work is a new routing protocol that scales to millions of nodes, a significant improvement over prior work on wireless mesh and mobile ad hoc networks. Our approach uses detailed information about buildings from widely available maps--data that was unavailable at scale over a decade ago, but is widely available now--to compute paths in a scalable way.</p></details> |  |
| **[Estimating City-wide Operating Mode Distribution of Light-Duty Vehicles: A Neural Network-based Approach](http://arxiv.org/abs/2503.22118v2)** | 2025-04-04 | [papers-cool](https://papers.cool/arxiv/2503.22118v2) | <details><summary>Show</summary><p>Driving cycles are a set of driving conditions and are crucial for the existing emission estimation model to evaluate vehicle performance, fuel efficiency, and emissions, by matching them with average speed to calculate the operating modes, such as braking, idling, and cruising. While existing emission estimation models, such as the Motor Vehicle Emission Simulator (MOVES), are powerful tools, their reliance on predefined driving cycles can be limiting, as these cycles often do not accurately represent regional driving conditions, making the models less effective for city-wide analyses. To solve this problem, this paper proposes a modular neural network (NN)-based framework to estimate operating mode distributions bypassing the driving cycle development phase, utilizing macroscopic variables such as speed, flow, and link infrastructure attributes. The proposed method is validated using a well-calibrated microsimulation model of Brookline MA, the United States. The results indicate that the proposed framework outperforms the operating mode distribution calculated by MOVES based on default driving cycles, providing a closer match to the actual operating mode distribution derived from trajectory data. Specifically, the proposed model achieves an average RMSE of 0.04 in predicting operating mode distribution, compared to 0.08 for MOVES. The average error in emission estimation across pollutants is 8.57% for the proposed method, lower than the 32.86% error for MOVES. In particular, for the estimation of CO2, the proposed method has an error of just 4%, compared to 35% for MOVES. The proposed model can be utilized for real-time emissions monitoring by providing rapid and accurate emissions estimates with easily accessible inputs.</p></details> |  |
| **[Joint Estimation and Prediction of City-wide Delivery Demand: A Large Language Model Empowered Graph-based Learning Approach](http://arxiv.org/abs/2408.17258v3)** | 2025-03-27 | [papers-cool](https://papers.cool/arxiv/2408.17258v3) | <details><summary>Show</summary><p>The proliferation of e-commerce and urbanization has significantly intensified delivery operations in urban areas, boosting the volume and complexity of delivery demand. Data-driven predictive methods, especially those utilizing machine learning techniques, have emerged to handle these complexities in urban delivery demand management problems. One particularly pressing issue that has yet to be sufficiently addressed is the joint estimation and prediction of city-wide delivery demand, as well as the generalization of the model to new cities. To this end, we formulate this problem as a transferable graph-based spatiotemporal learning task. First, an individual-collective message-passing neural network model is formalized to capture the interaction between demand patterns of associated regions. Second, by exploiting recent advances in large language models (LLMs), we extract general geospatial knowledge encodings from the unstructured locational data using the embedding generated by LLMs. Last, to encourage the cross-city generalization of the model, we integrate the encoding into the demand predictor in a transferable way. Comprehensive empirical evaluation results on two real-world delivery datasets, including eight cities in China and the US, demonstrate that our model significantly outperforms state-of-the-art baselines in accuracy, efficiency, and transferability.</p></details> |  |
| **[Integrating multimedia documents in 3D city models for a better understanding of territories](http://arxiv.org/abs/2506.10003v1)** | 2025-03-20 | [papers-cool](https://papers.cool/arxiv/2506.10003v1) | <details><summary>Show</summary><p>Digital 3D representations of urban areas, through their growing availability, are a helpful tool to better understand a territory. However, they lack contextual information about, for example, the history or functionality of buildings. On another side, multimedia documents like images, videos or texts usually contain such information. Crossing these two types of data can therefore help in the analysis and understanding of the organization of our cities. This could also be used to develop document search based on spatial navigation, instead of the classical textual query. In this paper, we propose four approaches to integrate multimedia documents in a 3D urban scene, allowing to contextualize the scene with any type of media. We combine these integration approaches with user guidance modes that allows to guide the user through the consumption of these media and support its understanding of the territory. We demonstrate the usefulness of these techniques in the context of different projects within the Lyon area (France). The use of multimedia documents integrated into a digital tour allows, for example, the iconic buildings to be contextualised or to understand the evolution of a territory through time.</p></details> | 8 pages, 11 figures |
| **[Estimating the Number of Street Vendors in New York City](http://arxiv.org/abs/2406.00527v5)** | 2025-03-20 | [papers-cool](https://papers.cool/arxiv/2406.00527v5) | <details><summary>Show</summary><p>We estimate the number of street vendors in New York City. We first summarize the process by which vendors receive licenses and permits to legally operate in New York City. We then describe a survey that was administered by the Street Vendor Project while distributing Coronavirus relief aid to vendors operating in New York City both with and without a license or permit. Finally, we calculate the total number of vendors using ratio estimation. We find that approximately 23,000 street vendors operate in New York City: 20,500 mobile food vendors and 2,300 general merchandise vendors. One third are located in just six ZIP Codes: 11368 (16%), 11372 (3%), and 11354 (3%) in North and West Queens and 10036 (5%), 10019 (4%), and 10001 (3%) in the Chelsea and Clinton neighborhoods of Manhattan. We also provide a theoretical justification of our estimates based on the theory of point processes and a discussion of their accuracy and implications. In particular, our estimates suggest the American Community Survey fails to cover the majority of New York City street vendors.</p></details> |  |
| **[Food Delivery Time Prediction in Indian Cities Using Machine Learning Models](http://arxiv.org/abs/2503.15177v1)** | 2025-03-19 | [papers-cool](https://papers.cool/arxiv/2503.15177v1) | <details><summary>Show</summary><p>Accurate prediction of food delivery times significantly impacts customer satisfaction, operational efficiency, and profitability in food delivery services. However, existing studies primarily utilize static historical data and often overlook dynamic, real-time contextual factors crucial for precise prediction, particularly in densely populated Indian cities. This research addresses these gaps by integrating real-time contextual variables such as traffic density, weather conditions, local events, and geospatial data (restaurant and delivery location coordinates) into predictive models. We systematically compare various machine learning algorithms, including Linear Regression, Decision Trees, Bagging, Random Forest, XGBoost, and LightGBM, on a comprehensive food delivery dataset specific to Indian urban contexts. Rigorous data preprocessing and feature selection significantly enhanced model performance. Experimental results demonstrate that the LightGBM model achieves superior predictive accuracy, with an R2 score of 0.76 and Mean Squared Error (MSE) of 20.59, outperforming traditional baseline approaches. Our study thus provides actionable insights for improving logistics strategies in complex urban environments. The complete methodology and code are publicly available for reproducibility and further research.</p></details> | <details><summary>for c...</summary><p>for code implementation, check https://github.com/Vikranth3140/Food-Delivery-Time-Prediction</p></details> |
| **[Compositional Generative Model of Unbounded 4D Cities](http://arxiv.org/abs/2501.08983v2)** | 2025-03-14 | [papers-cool](https://papers.cool/arxiv/2501.08983v2) | <details><summary>Show</summary><p>3D scene generation has garnered growing attention in recent years and has made significant progress. Generating 4D cities is more challenging than 3D scenes due to the presence of structurally complex, visually diverse objects like buildings and vehicles, and heightened human sensitivity to distortions in urban environments. To tackle these issues, we propose CityDreamer4D, a compositional generative model specifically tailored for generating unbounded 4D cities. Our main insights are 1) 4D city generation should separate dynamic objects (e.g., vehicles) from static scenes (e.g., buildings and roads), and 2) all objects in the 4D scene should be composed of different types of neural fields for buildings, vehicles, and background stuff. Specifically, we propose Traffic Scenario Generator and Unbounded Layout Generator to produce dynamic traffic scenarios and static city layouts using a highly compact BEV representation. Objects in 4D cities are generated by combining stuff-oriented and instance-oriented neural fields for background stuff, buildings, and vehicles. To suit the distinct characteristics of background stuff and instances, the neural fields employ customized generative hash grids and periodic positional embeddings as scene parameterizations. Furthermore, we offer a comprehensive suite of datasets for city generation, including OSM, GoogleEarth, and CityTopia. The OSM dataset provides a variety of real-world city layouts, while the Google Earth and CityTopia datasets deliver large-scale, high-quality city imagery complete with 3D instance annotations. Leveraging its compositional design, CityDreamer4D supports a range of downstream applications, such as instance editing, city stylization, and urban simulation, while delivering state-of-the-art performance in generating realistic 4D cities.</p></details> |  |
| **[To Assess the Impact of Smart Cities on Urbanization Patterns in the United States](http://arxiv.org/abs/2503.11260v1)** | 2025-03-14 | [papers-cool](https://papers.cool/arxiv/2503.11260v1) | <details><summary>Show</summary><p>This paper investigates the relationship between smart city initiatives and evolving urbanization trends in the United States. The research addresses the critical issue of rapid urban growth in the U.S. and explores how innovations within the smart city paradigm influence urban development. Utilizing principles from Urban Complexity Theory, this study identifies four key variables relevant to smart cities and their impact on urbanization: smart city technology, government policy, environmental sustainability, and socioeconomic factors. A mixed-method approach, combining quantitative and qualitative methodologies, was employed. A web-based survey (n=50) utilizing a five-point Likert scale was conducted among residents of Manhattan, New York, and Capitol Hill, Seattle. Results indicate that the implementation of smart city technologies is significantly associated with shifts in population density, land use diversification, and enhanced infrastructure dynamics. Additionally, residents demonstrated preferences for smart cities based on efficient urban mobility, environmental sustainability, and personal socioeconomic improvements. The findings highlight essential considerations for urban planners, policymakers, and employers. This study concludes that incorporating the identified influential factors into strategic urban planning optimizes city development to better accommodate growing urban populations.</p></details> | 60 pages, 4 figures |
| **[City Models: Past, Present and Future Prospects](http://arxiv.org/abs/2503.09237v1)** | 2025-03-12 | [papers-cool](https://papers.cool/arxiv/2503.09237v1) | <details><summary>Show</summary><p>We attempt to take a comprehensive look at the challenges of representing the spatio-temporal structures and dynamic processes defining a city's overall characteristics. For the task of urban planning and urban operation, we take the stance that even if the necessary representations of these structures and processes can be achieved, the most important representation of the relevant mindsets of the citizens are, unfortunately, mostly neglected. After a review of major "traditional" urban models of structures behind urban scale, form, and dynamics, we turn to major recent modeling approaches triggered by recent advances in AI that enable multi-modal generative models. Some of these models can create representations of geometries, networks and images, and reason flexibly at a human-compatible semantic level. They provide huge amounts of knowledge extracted from Terabytes of text and image documents and cover the required rich representation spectrum including geographic knowledge by different knowledge sources, degrees of granularity and scales. We then discuss what these new opportunities mean for the modeling challenges posed by cities, in particular with regard to the role and impact of citizens and their interactions within the city infrastructure. We propose to integrate these possibilities with existing approaches, such as agent-based models, which opens up new modeling spaces including rich citizen models which are able to also represent social interactions. Finally, we put forward some thoughts about a vision of a "social AI in a city ecosystem" that adds relevant citizen models to state-of-the-art structural and process models. This extended city representation will enable urban planners to establish citizen-oriented planning of city infrastructures for human culture, city resilience and sustainability.</p></details> | 8 figures |
| **[Artificial Intelligence for Secured Information Systems in Smart Cities: Collaborative IoT Computing with Deep Reinforcement Learning and Blockchain](http://arxiv.org/abs/2409.16444v2)** | 2025-03-11 | [papers-cool](https://papers.cool/arxiv/2409.16444v2) | <details><summary>Show</summary><p>The accelerated expansion of the Internet of Things (IoT) has raised critical challenges associated with privacy, security, and data integrity, specifically in infrastructures such as smart cities or smart manufacturing. Blockchain technology provides immutable, scalable, and decentralized solutions to address these challenges, and integrating deep reinforcement learning (DRL) into the IoT environment offers enhanced adaptability and decision-making. This paper investigates the integration of blockchain and DRL to optimize mobile transmission and secure data exchange in IoT-assisted smart cities. Through the clustering and categorization of IoT application systems, the combination of DRL and blockchain is shown to enhance the performance of IoT networks by maintaining privacy and security. Based on the review of papers published between 2015 and 2024, we have classified the presented approaches and offered practical taxonomies, which provide researchers with critical perspectives and highlight potential areas for future exploration and research. Our investigation shows how combining blockchain's decentralized framework with DRL can address privacy and security issues, improve mobile transmission efficiency, and guarantee robust, privacy-preserving IoT systems. Additionally, we explore blockchain integration for DRL and outline the notable applications of DRL technology. By addressing the challenges of machine learning and blockchain integration, this study proposes novel perspectives for researchers and serves as a foundational exploration from an interdisciplinary standpoint.</p></details> |  |
| **[Invisible Walls in Cities: Leveraging Large Language Models to Predict Urban Segregation Experience with Social Media Content](http://arxiv.org/abs/2503.04773v2)** | 2025-03-10 | [papers-cool](https://papers.cool/arxiv/2503.04773v2) | <details><summary>Show</summary><p>Understanding experienced segregation in urban daily life is crucial for addressing societal inequalities and fostering inclusivity. The abundance of user-generated reviews on social media encapsulates nuanced perceptions and feelings associated with different places, offering rich insights into segregation. However, leveraging this data poses significant challenges due to its vast volume, ambiguity, and confluence of diverse perspectives. To tackle these challenges, we propose using Large Language Models (LLMs) to automate online review mining for segregation prediction. We design a Reflective LLM Coder to digest social media content into insights consistent with real-world feedback, and eventually produce a codebook capturing key dimensions that signal segregation experience, such as cultural resonance and appeal, accessibility and convenience, and community engagement and local involvement. Guided by the codebook, LLMs can generate both informative review summaries and ratings for segregation prediction. Moreover, we design a REasoning-and-EMbedding (RE'EM) framework, which combines the reasoning and embedding capabilities of language models to integrate multi-channel features for segregation prediction. Experiments on real-world data demonstrate that our framework greatly improves prediction accuracy, with a 22.79% elevation in R2 and a 9.33% reduction in MSE. The derived codebook is generalizable across three different cities, consistently improving prediction accuracy. Moreover, our user study confirms that the codebook-guided summaries provide cognitive gains for human participants in perceiving POIs' social inclusiveness. Our study marks an important step toward understanding implicit social barriers and inequalities, demonstrating the great potential of promoting social inclusiveness with AI.</p></details> | 11 pages, 6 figures |
| **[Socioeconomic centers in cities worldwide](http://arxiv.org/abs/2503.06445v1)** | 2025-03-09 | [papers-cool](https://papers.cool/arxiv/2503.06445v1) | <details><summary>Show</summary><p>Urban centers serve as engines of regional development, yet accurately defining and identifying the socioeconomic centers of cities globally remains a big challenge. Existing mapping efforts are often limited to large cities in developed regions and rely on data sources that are unavailable in many developing countries. This data scarcity hinders the establishment of consistent urban indicators, such as accessibility, to assess progress towards the United Nations Sustainable Development Goals (SDGs). Here, we develop and validate a global map of the socioeconomic centers of cities for 2020 by integrating nighttime light and population density data within an advanced geospatial modeling framework. Our analysis reveals that monocentric cities -- the standard urban model -- still dominate our planet, accounting for over 80% of cities worldwide. However, these monocentric cities encompass only approximately 20% of the total urbanized area, urban population, and nighttime light intensity; this 80/20 pattern underscores significant disparities in urban development. Further analysis, combined with socioeconomic datasets, reveals a marked difference between developed and developing regions: high-income countries exhibit greater polycentricity than low-income countries, demonstrating a positive correlation between urban sprawl and economic growth. Our global dataset and findings provide critical insights into urban structure and development, with important implications for urban planning, policymaking, and the formulation of indicators for urban sustainability assessment.</p></details> |  |
| **[Causality Enhanced Origin-Destination Flow Prediction in Data-Scarce Cities](http://arxiv.org/abs/2503.06398v1)** | 2025-03-09 | [papers-cool](https://papers.cool/arxiv/2503.06398v1) | <details><summary>Show</summary><p>Accurate origin-destination (OD) flow prediction is of great importance to developing cities, as it can contribute to optimize urban structures and layouts. However, with the common issues of missing regional features and lacking OD flow data, it is quite daunting to predict OD flow in developing cities. To address this challenge, we propose a novel Causality-Enhanced OD Flow Prediction (CE-OFP), a unified framework that aims to transfer urban knowledge between cities and achieve accuracy improvements in OD flow predictions across data-scarce cities. In specific, we propose a novel reinforcement learning model to discover universal causalities among urban features in data-rich cities and build corresponding causal graphs. Then, we further build Causality-Enhanced Variational Auto-Encoder (CE-VAE) to incorporate causal graphs for effective feature reconstruction in data-scarce cities. Finally, with the reconstructed features, we devise a knowledge distillation method with a graph attention network to migrate the OD prediction model from data-rich cities to data-scare cities. Extensive experiments on two pairs of real-world datasets validate that the proposed CE-OFP remarkably outperforms state-of-the-art baselines, which can reduce the RMSE of OD flow prediction for data-scarce cities by up to 11%.</p></details> |  |
| **[Principles for Open Data Curation: A Case Study with the New York City 311 Service Request Data](http://arxiv.org/abs/2502.08649v2)** | 2025-03-08 | [papers-cool](https://papers.cool/arxiv/2502.08649v2) | <details><summary>Show</summary><p>In the early 21st century, the open data movement began to transform societies and governments by promoting transparency, innovation, and public engagement. The City of New York (NYC) has been at the forefront of this movement since the enactment of the Open Data Law in 2012, creating the NYC Open Data portal. The portal currently hosts 2,700 datasets, serving as a crucial resource for research across various domains, including health, urban development, and transportation. However, the effective use of open data relies heavily on data quality and usability, challenges that remain insufficiently addressed in the literature. This paper examines these challenges via a case study of the NYC 311 Service Request dataset, identifying key issues in data validity, consistency, and curation efficiency. We propose a set of data curation principles, tailored for government-released open data, to address these challenges. Our findings highlight the importance of harmonized field definitions, streamlined storage, and automated quality checks, offering practical guidelines for improving the reliability and utility of open datasets.</p></details> |  |
| **[A modeling framework to support the electrification of private transport in African cities: a case study of Addis Ababa](http://arxiv.org/abs/2503.03671v1)** | 2025-03-05 | [papers-cool](https://papers.cool/arxiv/2503.03671v1) | <details><summary>Show</summary><p>The electrification of road transport, as the predominant mode of transportation in Africa, represents a great opportunity to reduce greenhouse gas emissions and dependence on costly fuel imports. However, it introduces major challenges for local energy infrastructures, including the deployment of charging stations and the impact on often fragile electricity grids. Despite its importance, research on electric mobility planning in Africa remains limited, while existing planning tools rely on detailed local mobility data that is often unavailable, especially for privately owned passenger vehicles. In this study, we introduce a novel framework designed to support private vehicle electrification in data-scarce regions and apply it to Addis Ababa, simulating the mobility patterns and charging needs of 100,000 electric vehicles. Our analysis indicate that these vehicles generate a daily charging demand of approximately 350 MWh and emphasize the significant influence of the charging location on the spatial and temporal distribution of this demand. Notably, charging at public places can help smooth the charging demand throughout the day, mitigating peak charging loads on the electricity grid. We also estimate charging station requirements, finding that workplace charging requires approximately one charging point per three electric vehicles, while public charging requires only one per thirty. Finally, we demonstrate that photovoltaic energy can cover a substantial share of the charging needs, emphasizing the potential for renewable energy integration. This study lays the groundwork for electric mobility planning in Addis Ababa while offering a transferable framework for other African cities.</p></details> |  |
| **[Revolutionizing Traffic Management with AI-Powered Machine Vision: A Step Toward Smart Cities](http://arxiv.org/abs/2503.02967v1)** | 2025-03-04 | [papers-cool](https://papers.cool/arxiv/2503.02967v1) | <details><summary>Show</summary><p>The rapid urbanization of cities and increasing vehicular congestion have posed significant challenges to traffic management and safety. This study explores the transformative potential of artificial intelligence (AI) and machine vision technologies in revolutionizing traffic systems. By leveraging advanced surveillance cameras and deep learning algorithms, this research proposes a system for real-time detection of vehicles, traffic anomalies, and driver behaviors. The system integrates geospatial and weather data to adapt dynamically to environmental conditions, ensuring robust performance in diverse scenarios. Using YOLOv8 and YOLOv11 models, the study achieves high accuracy in vehicle detection and anomaly recognition, optimizing traffic flow and enhancing road safety. These findings contribute to the development of intelligent traffic management solutions and align with the vision of creating smart cities with sustainable and efficient urban infrastructure.</p></details> | <details><summary>6 pag...</summary><p>6 pages, 1 figure, 2 tables, accepted to 1th AITC conference in University Of Isfahan</p></details> |
| **[Heatwave increases nighttime light intensity in hyperdense cities of the Global South: A double machine learning study](http://arxiv.org/abs/2503.00557v1)** | 2025-03-01 | [papers-cool](https://papers.cool/arxiv/2503.00557v1) | <details><summary>Show</summary><p>Heatwaves, intensified by climate change and rapid urbanisation, pose significant threats to urban systems, particularly in the Global South, where adaptive capacity is constrained. This study investigates the relationship between heatwaves and nighttime light (NTL) radiance, a proxy of nighttime economic activity, in four hyperdense cities: Delhi, Guangzhou, Cairo, and Sao Paulo. We hypothesised that heatwaves increase nighttime activity. Using a double machine learning (DML) framework, we analysed data from 2013 to 2019 to quantify the impact of heatwaves on NTL while controlling for local climatic confounders. Results revealed a statistically significant increase in NTL intensity during heatwaves, with Cairo, Delhi, and Guangzhou showing elevated NTL on the third day, while S\~ao Paulo exhibits a delayed response on the fourth day. Sensitivity analyses confirmed the robustness of these findings, indicating that prolonged heat stress prompts urban populations to shift activities to night. Heterogeneous responses across cities highlight the possible influence of urban morphology and adaptive capacity to heatwave impacts. Our findings provide a foundation for policymakers to develop data-driven heat adaptation strategies, ensuring that cities remain liveable and economically resilient in an increasingly warming world.</p></details> | 4 figures 2 tables |
| **[Generative Gaussian Splatting for Unbounded 3D City Generation](http://arxiv.org/abs/2406.06526v3)** | 2025-02-27 | [papers-cool](https://papers.cool/arxiv/2406.06526v3) | <details><summary>Show</summary><p>3D city generation with NeRF-based methods shows promising generation results but is computationally inefficient. Recently 3D Gaussian Splatting (3D-GS) has emerged as a highly efficient alternative for object-level 3D generation. However, adapting 3D-GS from finite-scale 3D objects and humans to infinite-scale 3D cities is non-trivial. Unbounded 3D city generation entails significant storage overhead (out-of-memory issues), arising from the need to expand points to billions, often demanding hundreds of Gigabytes of VRAM for a city scene spanning 10km^2. In this paper, we propose GaussianCity, a generative Gaussian Splatting framework dedicated to efficiently synthesizing unbounded 3D cities with a single feed-forward pass. Our key insights are two-fold: 1) Compact 3D Scene Representation: We introduce BEV-Point as a highly compact intermediate representation, ensuring that the growth in VRAM usage for unbounded scenes remains constant, thus enabling unbounded city generation. 2) Spatial-aware Gaussian Attribute Decoder: We present spatial-aware BEV-Point decoder to produce 3D Gaussian attributes, which leverages Point Serializer to integrate the structural and contextual characteristics of BEV points. Extensive experiments demonstrate that GaussianCity achieves state-of-the-art results in both drone-view and street-view 3D city generation. Notably, compared to CityDreamer, GaussianCity exhibits superior performance with a speedup of 60 times (10.72 FPS v.s. 0.18 FPS).</p></details> | <details><summary>CVPR ...</summary><p>CVPR 2025. Project Page: https://haozhexie.com/project/gaussian-city</p></details> |
| **[City riots fed by transnational and trans-topic web-of-influence](http://arxiv.org/abs/2502.17331v1)** | 2025-02-24 | [papers-cool](https://papers.cool/arxiv/2502.17331v1) | <details><summary>Show</summary><p>The sudden emergence of large-scale riots in otherwise unconnected cities across the UK in summer 2024 came as a shock for both government officials and citizens. Irrespective of these riots' specific trigger, a key question is how the capacity for such widespread city rioting might be foreseen through some precursor behavior that flags an emerging appetite for such rioting at scale. Here we show evidence that points toward particular online behavior which developed at scale well ahead of the riots, across the multi-platform landscape of hate/extremist communities. Our analysis of detailed multi-platform data reveals a web-of-influence that existed well before the riots, involving online hate and extremism communities locally, nationally, and globally. This web-of-influence fed would-be rioters in each city mainly through video platforms. This web-of-influence has a persistent resilience -- and hence still represents a significant local, national, and international threat in the future -- because of its feedback across regional-national-international scales and across topics such as immigration; and its use of multiple lesser-known platforms that put it beyond any single government or platform's reach. Going forward, our findings mean that if city administrators coordinate with each other across local-national-international divides, they can map this threat as we have done here and initiate deliberation programs that might then soften such pre-existing extremes at scale, perhaps using automated AI-based technology.</p></details> |  |
| **[City-Scale Multi-Camera Vehicle Tracking System with Improved Self-Supervised Camera Link Model](http://arxiv.org/abs/2405.11345v3)** | 2025-02-14 | [papers-cool](https://papers.cool/arxiv/2405.11345v3) | <details><summary>Show</summary><p>Multi-Target Multi-Camera Tracking (MTMCT) has broad applications and forms the basis for numerous future city-wide systems (e.g. traffic management, crash detection, etc.). However, the challenge of matching vehicle trajectories across different cameras based solely on feature extraction poses significant difficulties. This article introduces an innovative multi-camera vehicle tracking system that utilizes a self-supervised camera link model. In contrast to related works that rely on manual spatial-temporal annotations, our model automatically extracts crucial multi-camera relationships for vehicle matching. The camera link is established through a pre-matching process that evaluates feature similarities, pair numbers, and time variance for high-quality tracks. This process calculates the probability of spatial linkage for all camera combinations, selecting the highest scoring pairs to create camera links. Our approach significantly improves deployment times by eliminating the need for human annotation, offering substantial improvements in efficiency and cost-effectiveness when it comes to real-world application. This pairing process supports cross camera matching by setting spatial-temporal constraints, reducing the searching space for potential vehicle matches. According to our experimental results, the proposed method achieves a new state-of-the-art among automatic camera-link based methods in CityFlow V2 benchmarks with 61.07% IDF1 Score.</p></details> | <details><summary>Uploa...</summary><p>Upload the revised manuscript with the publisher's requirement</p></details> |
| **[Dynamic Incentive Allocation for City-scale Deep Decarbonization](http://arxiv.org/abs/2502.08877v1)** | 2025-02-13 | [papers-cool](https://papers.cool/arxiv/2502.08877v1) | <details><summary>Show</summary><p>Greenhouse gas emissions from the residential sector represent a significant fraction of global emissions. Governments and utilities have designed incentives to stimulate the adoption of decarbonization technologies such as rooftop PV and heat pumps. However, studies have shown that many of these incentives are inefficient since a substantial fraction of spending does not actually promote adoption, and incentives are not equitably distributed across socioeconomic groups. We present a novel data-driven approach that adopts a holistic, emissions-based and city-scale perspective on decarbonization. We propose an optimization model that dynamically allocates a total incentive budget to households to directly maximize city-wide carbon reduction. We leverage techniques for the multi-armed bandits problem to estimate human factors, such as a household's willingness to adopt new technologies given a certain incentive. We apply our proposed framework to a city in the Northeast U.S., using real household energy data, grid carbon intensity data, and future price scenarios. We show that our learning-based technique significantly outperforms an example status quo incentive scheme, achieving up to 32.23% higher carbon reductions. We show that our framework can accommodate equity-aware constraints to equitably allocate incentives across socioeconomic groups, achieving 78.84% of the carbon reductions of the optimal solution on average.</p></details> |  |
| **[Valeriepieris Circles Reveal City and Regional Boundaries in England and Wales](http://arxiv.org/abs/2502.07451v1)** | 2025-02-11 | [papers-cool](https://papers.cool/arxiv/2502.07451v1) | <details><summary>Show</summary><p>We propose a new method of determining regional and city boundaries based on the Valeriepieris circle, the smallest circle containing a given fraction of the data. By varying the fraction in the circle we can map complex spatial data to a simple model of concentric rings which we then fit to determine natural density cutoffs. We apply this method to population, occupation, economic and transport data from England and Wales, finding that the regions determined by this method affirm well known social facts such as the disproportionate wealth of London or the relative isolation of the North East and South West of England. We then show how different data sets give us different views of the same cities, providing insight into their development and dynamics.</p></details> | 13 Figures |
| **[A Smart City Infrastructure Ontology for Threats, Cybercrime, and Digital Forensic Investigation](http://arxiv.org/abs/2408.02023v2)** | 2025-02-07 | [papers-cool](https://papers.cool/arxiv/2408.02023v2) | <details><summary>Show</summary><p>Cybercrime and the market for cyber-related compromises are becoming attractive revenue sources for state-sponsored actors, cybercriminals and technical individuals affected by financial hardships. Due to burgeoning cybercrime on new technological frontiers, efforts have been made to assist digital forensic investigators (DFI) and law enforcement agencies (LEA) in their investigative efforts. Forensic tool innovations and ontology developments, such as the Unified Cyber Ontology (UCO) and Cyber-investigation Analysis Standard Expression (CASE), have been proposed to assist DFI and LEA. Although these tools and ontologies are useful, they lack extensive information sharing and tool interoperability features, and the ontologies lack the latest Smart City Infrastructure (SCI) context that was proposed. To mitigate the weaknesses in both solutions and to ensure a safer cyber-physical environment for all, we propose the Smart City Ontological Paradigm Expression (SCOPE), an expansion profile of the UCO and CASE ontology that implements SCI threat models, SCI digital forensic evidence, attack techniques, patterns and classifications from MITRE. We showcase how SCOPE could present complex data such as SCI-specific threats, cybercrime, investigation data and incident handling workflows via an incident scenario modelled after publicly reported real-world incidents attributed to Advanced Persistent Threat (APT) groups. We also make SCOPE available to the community so that threats, digital evidence and cybercrime in emerging trends such as SCI can be identified, represented, and shared collaboratively.</p></details> | <details><summary>Updat...</summary><p>Updated to include amendments from peer review process. Accepted in Forensic Science International: Digital Investigation</p></details> |
| **[Network-Wide Traffic Flow Estimation Across Multiple Cities with Global Open Multi-Source Data: A Large-Scale Case Study in Europe and North America](http://arxiv.org/abs/2502.03798v1)** | 2025-02-06 | [papers-cool](https://papers.cool/arxiv/2502.03798v1) | <details><summary>Show</summary><p>Network-wide traffic flow, which captures dynamic traffic volume on each link of a general network, is fundamental to smart mobility applications. However, the observed traffic flow from sensors is usually limited across the entire network due to the associated high installation and maintenance costs. To address this issue, existing research uses various supplementary data sources to compensate for insufficient sensor coverage and estimate the unobserved traffic flow. Although these studies have shown promising results, the inconsistent availability and quality of supplementary data across cities make their methods typically face a trade-off challenge between accuracy and generality. In this research, we first time advocate using the Global Open Multi-Source (GOMS) data within an advanced deep learning framework to break the trade-off. The GOMS data primarily encompass geographical and demographic information, including road topology, building footprints, and population density, which can be consistently collected across cities. More importantly, these GOMS data are either causes or consequences of transportation activities, thereby creating opportunities for accurate network-wide flow estimation. Furthermore, we use map images to represent GOMS data, instead of traditional tabular formats, to capture richer and more comprehensive geographical and demographic information. To address multi-source data fusion, we develop an attention-based graph neural network that effectively extracts and synthesizes information from GOMS maps while simultaneously capturing spatiotemporal traffic dynamics from observed traffic data. A large-scale case study across 15 cities in Europe and North America was conducted. The results demonstrate stable and satisfactory estimation accuracy across these cities, which suggests that the trade-off challenge can be successfully addressed using our approach.</p></details> |  |
| **[FuzzyLight: A Robust Two-Stage Fuzzy Approach for Traffic Signal Control Works in Real Cities](http://arxiv.org/abs/2501.15820v1)** | 2025-01-27 | [papers-cool](https://papers.cool/arxiv/2501.15820v1) | <details><summary>Show</summary><p>Effective traffic signal control (TSC) is crucial in mitigating urban congestion and reducing emissions. Recently, reinforcement learning (RL) has been the research trend for TSC. However, existing RL algorithms face several real-world challenges that hinder their practical deployment in TSC: (1) Sensor accuracy deteriorates with increased sensor detection range, and data transmission is prone to noise, potentially resulting in unsafe TSC decisions. (2) During the training of online RL, interactions with the environment could be unstable, potentially leading to inappropriate traffic signal phase (TSP) selection and traffic congestion. (3) Most current TSC algorithms focus only on TSP decisions, overlooking the critical aspect of phase duration, affecting safety and efficiency. To overcome these challenges, we propose a robust two-stage fuzzy approach called FuzzyLight, which integrates compressed sensing and RL for TSC deployment. FuzzyLight offers several key contributions: (1) It employs fuzzy logic and compressed sensing to address sensor noise and enhances the efficiency of TSP decisions. (2) It maintains stable performance during training and combines fuzzy logic with RL to generate precise phases. (3) It works in real cities across 22 intersections and demonstrates superior performance in both real-world and simulated environments. Experimental results indicate that FuzzyLight enhances traffic efficiency by 48% compared to expert-designed timings in the real world. Furthermore, it achieves state-of-the-art (SOTA) performance in simulated environments using six real-world datasets with transmission noise. The code and deployment video are available at the URL1</p></details> |  |
| **[Collaborative Imputation of Urban Time Series through Cross-city Meta-learning](http://arxiv.org/abs/2501.11306v1)** | 2025-01-20 | [papers-cool](https://papers.cool/arxiv/2501.11306v1) | <details><summary>Show</summary><p>Urban time series, such as mobility flows, energy consumption, and pollution records, encapsulate complex urban dynamics and structures. However, data collection in each city is impeded by technical challenges such as budget limitations and sensor failures, necessitating effective data imputation techniques that can enhance data quality and reliability. Existing imputation models, categorized into learning-based and analytics-based paradigms, grapple with the trade-off between capacity and generalizability. Collaborative learning to reconstruct data across multiple cities holds the promise of breaking this trade-off. Nevertheless, urban data's inherent irregularity and heterogeneity issues exacerbate challenges of knowledge sharing and collaboration across cities. To address these limitations, we propose a novel collaborative imputation paradigm leveraging meta-learned implicit neural representations (INRs). INRs offer a continuous mapping from domain coordinates to target values, integrating the strengths of both paradigms. By imposing embedding theory, we first employ continuous parameterization to handle irregularity and reconstruct the dynamical system. We then introduce a cross-city collaborative learning scheme through model-agnostic meta learning, incorporating hierarchical modulation and normalization techniques to accommodate multiscale representations and reduce variance in response to heterogeneity. Extensive experiments on a diverse urban dataset from 20 global cities demonstrate our model's superior imputation performance and generalizability, underscoring the effectiveness of collaborative imputation in resource-constrained settings.</p></details> |  |
| **[Connectivity for AI enabled cities -- A field survey based study of emerging economies](http://arxiv.org/abs/2501.09479v1)** | 2025-01-16 | [papers-cool](https://papers.cool/arxiv/2501.09479v1) | <details><summary>Show</summary><p>The impact of Artificial Intelligence (AI) is transforming various aspects of urban life, including, governance, policy and planning, healthcare, sustainability, economics, entrepreneurship, etc. Although AI immense potential for positively impacting urban living, its success depends on overcoming significant challenges, particularly in telecommunications infrastructure. Smart city applications, such as, federated learning, Internet of Things (IoT), and online financial services, require reliable Quality of Service (QoS) from telecommunications networks to ensure effective information transfer. However, with over three billion people underserved or lacking access to internet, many of these AI-driven applications are at risk of either remaining underutilized or failing altogether. Furthermore, many IoT and video-based applications in densely populated urban areas require high-quality connectivity. This paper explores these issues, focusing on the challenges that need to be mitigated to make AI succeed in emerging countries, where more than 80% of the world population resides and urban migration grows. In this context, an overview of a case study conducted in Kathmandu, Nepal, highlights citizens' aspirations for affordable, high-quality internet-based services. The findings underscore the pressing need for advanced telecommunication networks to meet diverse user requirements while addressing investment and infrastructure gaps. This discussion provides insights into bridging the digital divide and enabling AI's transformative potential in urban areas.</p></details> |  |
| **[CoNOAir: A Neural Operator for Forecasting Carbon Monoxide Evolution in Cities](http://arxiv.org/abs/2501.06007v2)** | 2025-01-13 | [papers-cool](https://papers.cool/arxiv/2501.06007v2) | <details><summary>Show</summary><p>Carbon Monoxide (CO) is a dominant pollutant in urban areas due to the energy generation from fossil fuels for industry, automobile, and domestic requirements. Forecasting the evolution of CO in real-time can enable the deployment of effective early warning systems and intervention strategies. However, the computational cost associated with the physics and chemistry-based simulation makes it prohibitive to implement such a model at the city and country scale. To address this challenge, here, we present a machine learning model based on neural operator, namely, Complex Neural Operator for Air Quality (CoNOAir), that can effectively forecast CO concentrations. We demonstrate this by developing a country-level model for short-term (hourly) and long-term (72-hour) forecasts of CO concentrations. Our model outperforms state-of-the-art models such as Fourier neural operators (FNO) and provides reliable predictions for both short and long-term forecasts. We further analyse the capability of the model to capture extreme events and generate forecasts in urban cities in India. Interestingly, we observe that the model predicts the next hour CO concentrations with R2 values greater than 0.95 for all the cities considered. The deployment of such a model can greatly assist the governing bodies to provide early warning, plan intervention strategies, and develop effective strategies by considering several what-if scenarios. Altogether, the present approach could provide a fillip to real-time predictions of CO pollution in urban cities.</p></details> | <details><summary>28 pa...</summary><p>28 pages, 14 figures, under submission process</p></details> |
| **[LDMapNet-U: An End-to-End System for City-Scale Lane-Level Map Updating](http://arxiv.org/abs/2501.02763v2)** | 2025-01-13 | [papers-cool](https://papers.cool/arxiv/2501.02763v2) | <details><summary>Show</summary><p>An up-to-date city-scale lane-level map is an indispensable infrastructure and a key enabling technology for ensuring the safety and user experience of autonomous driving systems. In industrial scenarios, reliance on manual annotation for map updates creates a critical bottleneck. Lane-level updates require precise change information and must ensure consistency with adjacent data while adhering to strict standards. Traditional methods utilize a three-stage approach-construction, change detection, and updating-which often necessitates manual verification due to accuracy limitations. This results in labor-intensive processes and hampers timely updates. To address these challenges, we propose LDMapNet-U, which implements a new end-to-end paradigm for city-scale lane-level map updating. By reconceptualizing the update task as an end-to-end map generation process grounded in historical map data, we introduce a paradigm shift in map updating that simultaneously generates vectorized maps and change information. To achieve this, a Prior-Map Encoding (PME) module is introduced to effectively encode historical maps, serving as a critical reference for detecting changes. Additionally, we incorporate a novel Instance Change Prediction (ICP) module that learns to predict associations with historical maps. Consequently, LDMapNet-U simultaneously achieves vectorized map element generation and change detection. To demonstrate the superiority and effectiveness of LDMapNet-U, extensive experiments are conducted using large-scale real-world datasets. In addition, LDMapNet-U has been successfully deployed in production at Baidu Maps since April 2024, supporting map updating for over 360 cities and significantly shortening the update cycle from quarterly to weekly. The updated maps serve hundreds of millions of users and are integrated into the autonomous driving systems of several leading vehicle companies.</p></details> | <details><summary>Accep...</summary><p>Accepted by KDD 2025, camera-ready version</p></details> |
| **[Parking Space Detection in the City of Granada](http://arxiv.org/abs/2501.06651v1)** | 2025-01-11 | [papers-cool](https://papers.cool/arxiv/2501.06651v1) | <details><summary>Show</summary><p>This paper addresses the challenge of parking space detection in urban areas, focusing on the city of Granada. Utilizing aerial imagery, we develop and apply semantic segmentation techniques to accurately identify parked cars, moving cars and roads. A significant aspect of our research is the creation of a proprietary dataset specific to Granada, which is instrumental in training our neural network model. We employ Fully Convolutional Networks, Pyramid Networks and Dilated Convolutions, demonstrating their effectiveness in urban semantic segmentation. Our approach involves comparative analysis and optimization of various models, including Dynamic U-Net, PSPNet and DeepLabV3+, tailored for the segmentation of aerial images. The study includes a thorough experimentation phase, using datasets such as UDD5 and UAVid, alongside our custom Granada dataset. We evaluate our models using metrics like Foreground Accuracy, Dice Coefficient and Jaccard Index. Our results indicate that DeepLabV3+ offers the most promising performance. We conclude with future directions, emphasizing the need for a dedicated neural network for parked car detection and the potential for application in other urban environments. This work contributes to the fields of urban planning and traffic management, providing insights into efficient utilization of parking spaces through advanced image processing techniques.</p></details> | 9 pages, 5 figures |
| **[Generalization of Urban Wind Environment Using Fourier Neural Operator Across Different Wind Directions and Cities](http://arxiv.org/abs/2501.05499v1)** | 2025-01-09 | [papers-cool](https://papers.cool/arxiv/2501.05499v1) | <details><summary>Show</summary><p>Simulation of urban wind environments is crucial for urban planning, pollution control, and renewable energy utilization. However, the computational requirements of high-fidelity computational fluid dynamics (CFD) methods make them impractical for real cities. To address these limitations, this study investigates the effectiveness of the Fourier Neural Operator (FNO) model in predicting flow fields under different wind directions and urban layouts. In this study, we investigate the effectiveness of the Fourier Neural Operator (FNO) model in predicting urban wind conditions under different wind directions and urban layouts. By training the model on velocity data from large eddy simulation data, we evaluate the performance of the model under different urban configurations and wind conditions. The results show that the FNO model can provide accurate predictions while significantly reducing the computational time by 99%. Our innovative approach of dividing the wind field into smaller spatial blocks for training improves the ability of the FNO model to capture wind frequency features effectively. The SDF data also provides important spatial building information, enhancing the model's ability to recognize physical boundaries and generate more realistic predictions. The proposed FNO approach enhances the AI model's generalizability for different wind directions and urban layouts.</p></details> |  |
| **[Towards resilient cities: A hybrid simulation framework for risk mitigation through data driven decision making](http://arxiv.org/abs/2501.04746v1)** | 2025-01-08 | [papers-cool](https://papers.cool/arxiv/2501.04746v1) | <details><summary>Show</summary><p>Providing a comprehensive view of the city operation and offering useful metrics for decision making is a well known challenge for urban risk analysis systems. Existing systems are, in many cases, generalizations of previous domain specific tools and or methodologies that may not cover all urban interdependencies and makes it difficult to have homogeneous indicators. In order to overcome this limitation while seeking for effective support to decision makers, this article introduces a novel hybrid simulation framework for risk mitigation. The framework is built on a proposed city concept that considers urban space as a Complex Adaptive System composed by interconnected Critical Infrastructures. In this concept, a Social System, which models daily patterns and social interactions of the citizens in the Urban Landscape, drives the CIs demand to configure the full city picture. The frameworks hybrid design integrates agent based and network based modeling by breaking down city agents into system dependent subagents, to enable both inter and intra system interaction simulation, respectively. A layered structure of indicators at different aggregation levels is also developed, to ensure that decisions are not only data driven but also explainable. Therefore, the proposed simulation framework can serve as a DSS tool that allows the quantitative analysis of the impact of threats at different levels. First, system level metrics can be used to get a broad view on the city resilience. Then, agent level metrics back those figures and provide better explainability. On implementation, the proposed framework enables component reusability (for eased coding), simulation federation (enabling the integration of existing system oriented simulators), discrete simulation in accelerated time (for rapid scenario simulation) and decision oriented visualization (for informed outputs).</p></details> | 24 pages |
| **[Neighborhood Disparities in Smart City Service Adoption](http://arxiv.org/abs/2501.04363v1)** | 2025-01-08 | [papers-cool](https://papers.cool/arxiv/2501.04363v1) | <details><summary>Show</summary><p>While local governments have invested heavily in smart city infrastructure, significant disparities in adopting these services remain in urban areas. The success of many user-facing smart city technologies requires understanding barriers to adoption, including persistent inequalities in urban areas. An analysis of a random sample telephone survey (n=489) in four neighborhoods of Tel Aviv merged with digital municipal services usage data found that neighborhood residency influences the reasons why residents adopt resident-facing smart city services, as well as individual-level factors. Structured Equation Modeling shows that neighborhood residency is related to digital proficiency and privacy perceptions beyond demographic factors and that those influence the adoption of smart-city services. We summarize the paper by discussing why and how place effects must be considered in further research in smart cities and the study and mitigation of digital inequality.</p></details> | 14 pages, 4 figures |
| **[Is social media hindering or helping Academic Performance? A case study of Walter Sisulu University Buffalo City Campus](http://arxiv.org/abs/2501.03611v1)** | 2025-01-07 | [papers-cool](https://papers.cool/arxiv/2501.03611v1) | <details><summary>Show</summary><p>Social media platforms are popular among higher education students and have seen increased usage for academic purposes, especially during the COVID-19 pandemic. However, excessive use of social media can negatively impact students' academic performance. This preliminary study examines social media's impact on students' academic performance at Walter Sisulu University (WSU), Buffalo City campus. Using a positivist paradigm and a quantitative approach, randomly sampled data were collected from 71 students through a survey to identify trends and generate preliminary insights. Results indicate that while social media can facilitate academic work, it predominantly acts as a distraction, negatively affecting academic performance, particularly for first-year students. Notably, 84.5% of the students spend more than four hours daily on social media, and 39.4% agree that it negatively impacts their assignment completion. The study underscores the need for students to balance their social media use and academic responsibilities, highlighting the importance of this issue. Recommendations for achieving this balance, such as adopting time management strategies and integrating social media into teaching methodologies, are discussed.</p></details> | 17 pages |
| **[Zoning in American Cities: Are Reforms Making a Difference? An AI-based Analysis](http://arxiv.org/abs/2502.00008v1)** | 2025-01-07 | [papers-cool](https://papers.cool/arxiv/2502.00008v1) | <details><summary>Show</summary><p>Cities are at the forefront of addressing global sustainability challenges, particularly those exacerbated by climate change. Traditional zoning codes, which often segregate land uses, have been linked to increased vehicular dependence, urban sprawl, and social disconnection, undermining broader social and environmental sustainability objectives. This study investigates the adoption and impact of form-based codes (FBCs), which aim to promote sustainable, compact, and mixed-use urban forms as a solution to these issues. Using Natural Language Processing (NLP) techniques, we analyzed zoning documents from over 2000 U.S. census-designated places to identify linguistic patterns indicative of FBC principles. Our findings reveal widespread adoption of FBCs across the country, with notable variations within regions. FBCs are associated with higher floor-to-area ratios, narrower and more consistent street setbacks, and smaller plots. We also find that places with FBCs have improved walkability, shorter commutes, and a higher share of multi-family housing. Our findings highlight the utility of NLP for evaluating zoning codes and underscore the potential benefits of form-based zoning reforms for enhancing urban sustainability.</p></details> | <details><summary>31 pa...</summary><p>31 pages, 6 figures, 1 table</p></details> |
| **[AMM: Adaptive Modularized Reinforcement Model for Multi-city Traffic Signal Control](http://arxiv.org/abs/2501.02548v1)** | 2025-01-05 | [papers-cool](https://papers.cool/arxiv/2501.02548v1) | <details><summary>Show</summary><p>Traffic signal control (TSC) is an important and widely studied direction. Recently, reinforcement learning (RL) methods have been used to solve TSC problems and achieve superior performance over conventional TSC methods. However, applying RL methods to the real world is challenging due to the huge cost of experiments in real-world traffic environments. One possible solution is TSC domain adaptation, which adapts trained models to target environments and reduces the number of interactions and the training cost. However, existing TSC domain adaptation methods still face two major issues: the lack of consideration for differences across cities and the low utilization of multi-city data. To solve aforementioned issues, we propose an approach named Adaptive Modularized Model (AMM). By modularizing TSC problems and network models, we overcome the challenge of possible changes in environmental observations. We also aggregate multi-city experience through meta-learning. We conduct extensive experiments on different cities and show that AMM can achieve excellent performance with limited interactions in target environments and outperform existing methods. We also demonstrate the feasibility and generalizability of our method.</p></details> |  |
| **[Modeling and Simulating Agent-Based City Migration Using Conway's Game of Life](http://arxiv.org/abs/2412.20691v1)** | 2024-12-30 | [papers-cool](https://papers.cool/arxiv/2412.20691v1) | <details><summary>Show</summary><p>Agent-based modeling (ABM) has become a cornerstone of complexity science, enabling the study of heterogeneous agents interacting within dynamic environments. Among ABM frameworks, John Conway's Game of Life (GoL) stands out for its simplicity and ability to generate emergent macroscopic patterns from basic microscopic rules. In this paper, we propose and implement a novel GoL-based framework to simulate urban migration dynamics. Using a grid-within-a-grid approach, our approach encodes probabilistic tendencies for out-migration due to densification and sparsification, simulating the evolution of population centers. By initializing GoL grids with different distributions and parameterizing migration preferences, we explore how urban structures emerge and stabilize over time. Through a series of experiments, we demonstrate that even with simple rules, this framework shows promise for understanding emergent urban phenomena, providing insights into city growth and structure. Methodologically, our framework offers a versatile and computationally efficient tool for studying urban migration patterns, contributing to the broader application of ABMs in computational urban social science.</p></details> |  |
| **[Transforming CCTV cameras into NO$_2$ sensors at city scale for adaptive policymaking](http://arxiv.org/abs/2501.00056v1)** | 2024-12-28 | [papers-cool](https://papers.cool/arxiv/2501.00056v1) | <details><summary>Show</summary><p>Air pollution in cities, especially NO\textsubscript{2}, is linked to numerous health problems, ranging from mortality to mental health challenges and attention deficits in children. While cities globally have initiated policies to curtail emissions, real-time monitoring remains challenging due to limited environmental sensors and their inconsistent distribution. This gap hinders the creation of adaptive urban policies that respond to the sequence of events and daily activities affecting pollution in cities. Here, we demonstrate how city CCTV cameras can act as a pseudo-NO\textsubscript{2} sensors. Using a predictive graph deep model, we utilised traffic flow from London's cameras in addition to environmental and spatial factors, generating NO\textsubscript{2} predictions from over 133 million frames. Our analysis of London's mobility patterns unveiled critical spatiotemporal connections, showing how specific traffic patterns affect NO\textsubscript{2} levels, sometimes with temporal lags of up to 6 hours. For instance, if trucks only drive at night, their effects on NO\textsubscript{2} levels are most likely to be seen in the morning when people commute. These findings cast doubt on the efficacy of some of the urban policies currently being implemented to reduce pollution. By leveraging existing camera infrastructure and our introduced methods, city planners and policymakers could cost-effectively monitor and mitigate the impact of NO\textsubscript{2} and other pollutants.</p></details> | 43 pages |
| **[Spatio-Temporal Differences in Bike Sharing Usage: A Tale of Six Cities](http://arxiv.org/abs/2412.19294v1)** | 2024-12-26 | [papers-cool](https://papers.cool/arxiv/2412.19294v1) | <details><summary>Show</summary><p>This study investigates the spatio-temporal patterns of Bike Sharing System (BSS) usage in six major cities: New York, London, Tokyo, Boston, Chicago and Washington D.C. By analyzing data over a 30-day period with comparable climate and average temperatures, we explored differences in BSS usage between weekdays and weekends in those cities using Jensen-Shannon divergence (JSD) and rank distribution analysis. Our findings reveal significant temporal differences in BSS usage that were commonly observed in all cities, with weekday patterns dominated by commute peaks and weekend patterns reflecting recreational activities. Friday emerges as a transitional day, sharing the characteristics of both weekdays and weekends. Meanwhile, docking station usage rank distributions show remarkable consistency between weekdays and weekends for most cities, with London being a unique anomaly. This study highlights the potential of BSS data to uncover urban mobility patterns and the underlying structures of cities. The results suggest that BSS usage reflects both intrinsic user behavior and external influences such as urban planning.</p></details> | 16pages, 5figures |
| **[Crime Hotspot Analysis and Mapping Using Geospatial Technology in Dessie City, Ethiopia](http://arxiv.org/abs/2501.00036v1)** | 2024-12-24 | [papers-cool](https://papers.cool/arxiv/2501.00036v1) | <details><summary>Show</summary><p>Over the past few decades, crime and delinquency rates have increased drastically in many countries; nevertheless, it is important to note that crime trends can differ significantly by geographic region. This study's primary goal was to use geographic technology to map and analyze Dessie City's crime patterns. To investigate the geographic clustering of crime, the researchers used semivariogram modeling and spatial autocorrelation analysis with Moran'sI. The neighborhoods of Hote, Arada, and Segno in Dessie's central city were found to be crime-prone "hot spot" locations, as evidenced by statistically significant high Z-scores ranging from 0.037 to 4.608. On the other hand, low negative Z-scores ranging from -3.231 to -0.116 indicated "cold spot" concentrations of crime in the city's north-central sub-cities of Menafesha and Bounbouwha. With an index of 0.027492 and a Z-score of 3.297616 (p<0.01), the analysis overall showed a substantial positive spatial autocorrelation, suggesting a clustered pattern of crime in Dessie. The majority of crimes showed a north-south directionality, except for murder, which trended from northeast to southwest. The mean center of all crime types was found in the central Hote area. To address the complicated problem of rising crime rates in Dessie and other developing metropolitan areas, more focused and efficient enforcement techniques, and resource deployment can be informed through the knowledge acquired from the geospatial analysis.</p></details> |  |
| **[Adaptive Urban Planning: A Hybrid Framework for Balanced City Development](http://arxiv.org/abs/2412.15349v1)** | 2024-12-19 | [papers-cool](https://papers.cool/arxiv/2412.15349v1) | <details><summary>Show</summary><p>Urban planning faces a critical challenge in balancing city-wide infrastructure needs with localized demographic preferences, particularly in rapidly developing regions. Although existing approaches typically focus on top-down optimization or bottom-up community planning, only some frameworks successfully integrate both perspectives. Our methodology employs a two-tier approach: First, a deterministic solver optimizes basic infrastructure requirements in the city region. Second, four specialized planning agents, each representing distinct sub-regions, propose demographic-specific modifications to a master planner. The master planner then evaluates and integrates these suggestions to ensure cohesive urban development. We validate our framework using a newly created dataset comprising detailed region and sub-region maps from three developing cities in India, focusing on areas undergoing rapid urbanization. The results demonstrate that this hybrid approach enables more nuanced urban development while maintaining overall city functionality.</p></details> |  |

